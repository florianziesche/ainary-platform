<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>The Transatlantic Divide — Ainary Report AR-003</title>
<style>
  /* ========================================
     FONTS
     ======================================== */
  @font-face {
    font-family: 'Inter';
    src: url('/fonts/inter-variable.woff2') format('woff2');
    font-weight: 100 900;
    font-display: swap;
  }

  /* ========================================
     RESET & BASE
     ======================================== */
  * {
    margin: 0;
    padding: 0;
    box-sizing: border-box;
  }

  body {
    font-family: 'Inter', -apple-system, BlinkMacSystemFont, sans-serif;
    background: #fafaf8;
    color: #333;
    line-height: 1.75;
    font-size: 0.95rem;
    font-weight: 400;
  }

  /* ========================================
     LAYOUT
     ======================================== */
  .page {
    max-width: 900px;
    margin: 0 auto;
    padding: 48px 40px;
  }

  .cover {
    min-height: 100vh;
    display: flex;
    flex-direction: column;
    justify-content: space-between;
    max-width: 900px;
    margin: 0 auto;
    padding: 48px 40px;
  }

  .back-cover {
    min-height: 100vh;
    display: flex;
    flex-direction: column;
    justify-content: center;
    align-items: center;
    text-align: center;
    max-width: 900px;
    margin: 0 auto;
    padding: 48px 40px;
    page-break-before: always;
  }

  /* ========================================
     TYPOGRAPHY
     ======================================== */
  h1 {
    font-size: 2.2rem;
    font-weight: 600;
    line-height: 1.2;
    color: #1a1a1a;
    letter-spacing: -0.02em;
  }

  h2 {
    font-size: 1.5rem;
    font-weight: 600;
    color: #1a1a1a;
    line-height: 1.3;
    margin-top: 3rem;
    margin-bottom: 12px;
  }

  h3 {
    font-size: 1.1rem;
    font-weight: 600;
    color: #1a1a1a;
    line-height: 1.4;
    margin-top: 2rem;
    margin-bottom: 12px;
  }

  p {
    margin-bottom: 1rem;
  }

  strong {
    font-weight: 600;
    color: #1a1a1a;
  }

  em {
    font-style: italic;
  }

  sup {
    font-size: 0.65rem;
    color: #888;
    vertical-align: super;
  }

  /* ========================================
     COVER COMPONENTS
     ======================================== */
  .cover-header {
    display: flex;
    justify-content: space-between;
    align-items: center;
    margin-bottom: 40vh;
  }

  .cover-brand {
    display: flex;
    align-items: center;
    gap: 8px;
  }

  .gold-punkt {
    color: #c8aa50;
    font-size: 14px;
  }

  .brand-name {
    font-size: 0.85rem;
    font-weight: 500;
    color: #1a1a1a;
    letter-spacing: 0.02em;
  }

  .cover-meta {
    display: flex;
    gap: 12px;
    font-size: 0.75rem;
    color: #888;
  }

  .cover-title-block {
    margin-bottom: auto;
  }

  .cover-title {
    margin-bottom: 16px;
  }

  .cover-subtitle {
    font-size: 1rem;
    font-weight: 400;
    color: #666;
    line-height: 1.5;
  }

  .cover-footer {
    display: flex;
    justify-content: space-between;
    align-items: flex-end;
  }

  .cover-date {
    font-size: 0.75rem;
    color: #888;
  }

  .cover-author {
    font-size: 0.75rem;
    color: #888;
    text-align: center;
  }

  /* ========================================
     TABLE OF CONTENTS
     ======================================== */
  .toc-label {
    font-size: 0.7rem;
    font-weight: 600;
    color: #1a1a1a;
    text-transform: uppercase;
    letter-spacing: 0.1em;
    margin-bottom: 24px;
  }

  .toc-section {
    margin-bottom: 32px;
  }

  .toc-section-label {
    font-size: 0.65rem;
    font-weight: 500;
    color: #888;
    text-transform: uppercase;
    letter-spacing: 0.12em;
    margin-bottom: 12px;
  }

  .toc-entry {
    display: flex;
    align-items: baseline;
    gap: 16px;
    padding: 12px 0;
    border-bottom: 1px solid #eee;
    text-decoration: none;
    transition: all 0.2s;
  }

  .toc-number {
    font-size: 0.8rem;
    color: #888;
    font-variant-numeric: tabular-nums;
    min-width: 24px;
  }

  .toc-title {
    font-size: 0.95rem;
    font-weight: 500;
    color: #1a1a1a;
    flex: 1;
    transition: color 0.2s;
  }

  .toc-entry:hover .toc-title {
    color: #c8aa50;
  }

  .toc-page {
    font-size: 0.8rem;
    color: #888;
  }

  /* ========================================
     HOW TO READ
     ======================================== */
  .how-to-read-table {
    width: 100%;
    border-collapse: collapse;
    margin: 24px 0;
  }

  .how-to-read-table th {
    text-align: left;
    font-size: 0.7rem;
    font-weight: 600;
    color: #555;
    text-transform: uppercase;
    letter-spacing: 0.05em;
    padding: 10px 12px;
    background: #f5f4f0;
    border-bottom: 2px solid #e5e3dc;
  }

  .how-to-read-table td {
    font-size: 0.85rem;
    color: #333;
    padding: 10px 12px;
    border-bottom: 1px solid #ddd;
  }

  /* ========================================
     EXECUTIVE SUMMARY
     ======================================== */
  .thesis {
    font-size: 1rem;
    font-weight: 600;
    color: #1a1a1a;
    line-height: 1.6;
    margin-bottom: 24px;
  }

  .evidence-list {
    margin-left: 20px;
    margin-bottom: 24px;
  }

  .evidence-list li {
    font-size: 0.9rem;
    color: #333;
    line-height: 1.6;
    margin-bottom: 8px;
  }

  .keywords {
    font-size: 0.8rem;
    color: #666;
    font-style: italic;
    margin-top: 32px;
    padding-top: 16px;
    border-top: 1px solid #eee;
  }

  /* ========================================
     SECTION COMPONENTS
     ======================================== */
  .confidence-badge {
    font-size: 0.75rem;
    font-weight: 500;
    color: #1a1a1a;
    background: #f5f4f0;
    padding: 3px 8px;
    border-radius: 10px;
    margin-left: 8px;
    vertical-align: middle;
  }

  .confidence-line {
    font-size: 0.8rem;
    color: #888;
    font-style: italic;
    display: block;
    margin-bottom: 16px;
  }

  .key-insight {
    font-weight: 600;
    color: #1a1a1a;
  }

  /* ========================================
     CALLOUTS
     ======================================== */
  .callout {
    background: #f5f4f0;
    padding: 16px 20px;
    border-radius: 4px;
    margin: 1.5rem 0;
    page-break-inside: avoid;
  }

  .callout-label {
    font-size: 0.7rem;
    font-weight: 600;
    text-transform: uppercase;
    letter-spacing: 0.08em;
    margin-bottom: 8px;
  }

  .callout-body {
    font-size: 0.9rem;
    color: #555;
    line-height: 1.6;
  }

  .callout.claim .callout-label {
    color: #555;
  }

  .callout.invalidation {
    border-left: 3px solid #ddd;
  }

  .callout.invalidation .callout-label {
    color: #888;
  }

  .callout.sowhat {
    border-left: 3px solid #c8aa50;
  }

  .callout.sowhat .callout-label {
    color: #c8aa50;
  }

  /* ========================================
     EXHIBITS & TABLES
     ======================================== */
  .exhibit {
    margin: 2rem 0;
  }

  .exhibit-label {
    font-size: 0.75rem;
    font-weight: 600;
    color: #555;
    margin-bottom: 12px;
  }

  .exhibit-table {
    width: 100%;
    border-collapse: collapse;
    page-break-inside: avoid;
  }

  .exhibit-table th {
    text-align: left;
    font-size: 0.7rem;
    font-weight: 600;
    color: #555;
    text-transform: uppercase;
    letter-spacing: 0.05em;
    padding: 10px 12px;
    background: #f5f4f0;
    border-bottom: 2px solid #e5e3dc;
  }

  .exhibit-table td {
    font-size: 0.85rem;
    color: #333;
    padding: 10px 12px;
    border-bottom: 1px solid #ddd;
  }

  .exhibit-source {
    font-size: 0.7rem;
    color: #888;
    font-style: italic;
    margin-top: 8px;
  }

  /* ========================================
     KPI FIGURES
     ======================================== */
  .kpi-grid {
    display: grid;
    grid-template-columns: repeat(auto-fit, minmax(250px, 1fr));
    gap: 48px;
    margin: 2rem 0;
  }

  .kpi {
    text-align: left;
  }

  .kpi-number {
    font-size: 2rem;
    font-weight: 600;
    color: #1a1a1a;
    line-height: 1.2;
  }

  .kpi-label {
    font-size: 0.75rem;
    color: #666;
    margin-top: 4px;
  }

  .kpi-source {
    font-size: 0.65rem;
    color: #888;
    margin-top: 2px;
  }

  /* ========================================
     LISTS
     ======================================== */
  ul {
    margin-left: 20px;
    margin-bottom: 1rem;
  }

  ol {
    margin-left: 20px;
    margin-bottom: 1rem;
  }

  li {
    margin-bottom: 4px;
  }

  /* ========================================
     TIMELINE
     ======================================== */
  .timeline {
    margin: 1.5rem 0;
  }

  .timeline-item {
    display: flex;
    gap: 1rem;
    margin-bottom: 0.75rem;
    align-items: flex-start;
  }

  .timeline-marker {
    width: 8px;
    height: 8px;
    border-radius: 50%;
    background: #c8aa50;
    margin-top: 0.55rem;
    flex-shrink: 0;
  }

  .timeline-content {
    font-size: 0.92rem;
  }

  .timeline-content strong {
    color: #c8aa50;
  }

  /* ========================================
     STEPS
     ======================================== */
  .steps {
    margin: 2rem 0;
  }

  .step {
    display: flex;
    gap: 1rem;
    margin-bottom: 1.5rem;
    align-items: flex-start;
  }

  .step-num {
    width: 32px;
    height: 32px;
    border-radius: 50%;
    background: #c8aa50;
    color: #fff;
    display: flex;
    align-items: center;
    justify-content: center;
    font-weight: 600;
    font-size: 0.85rem;
    flex-shrink: 0;
  }

  .step-content h4 {
    font-weight: 600;
    margin-bottom: 0.25rem;
  }

  .step-content p {
    font-size: 0.92rem;
    margin-bottom: 0;
  }

  /* ========================================
     TRANSPARENCY NOTE
     ======================================== */
  .transparency-intro {
    font-size: 0.85rem;
    color: #555;
    line-height: 1.6;
    margin-bottom: 12px;
  }

  .transparency-table {
    width: 100%;
    border-collapse: collapse;
    margin-top: 12px;
  }

  .transparency-table td:first-child {
    font-size: 0.85rem;
    font-weight: 600;
    color: #555;
    padding: 8px 0;
    border-bottom: 1px solid #eee;
    width: 160px;
    vertical-align: top;
  }

  .transparency-table td:last-child {
    font-size: 0.85rem;
    color: #333;
    padding: 8px 0;
    border-bottom: 1px solid #eee;
  }

  /* ========================================
     REFERENCES
     ======================================== */
  .reference-entry {
    font-size: 0.8rem;
    color: #555;
    line-height: 1.5;
    margin-bottom: 6px;
    padding-left: 24px;
    text-indent: -24px;
  }

  /* ========================================
     AUTHOR BIO
     ======================================== */
  .author-section {
    margin-top: 3rem;
    padding-top: 2rem;
    border-top: 1px solid #e5e3dc;
  }

  .author-label {
    font-size: 0.85rem;
    font-weight: 600;
    color: #555;
    margin-bottom: 8px;
  }

  .author-bio {
    font-size: 0.85rem;
    color: #555;
    line-height: 1.6;
  }

  /* ========================================
     BACK COVER
     ======================================== */
  .back-cover-services {
    font-size: 0.85rem;
    color: #666;
    margin-bottom: 24px;
  }

  .back-cover-cta {
    font-size: 0.85rem;
    color: #888;
    margin-bottom: 16px;
  }

  .back-cover-cta a {
    color: #888;
    text-decoration: none;
  }

  .back-cover-cta a:hover {
    text-decoration: underline;
  }

  .back-cover-contact {
    font-size: 0.8rem;
    color: #888;
  }

  /* ========================================
     PRINT STYLES
     ======================================== */
  @media print {
    @page {
      size: A4;
      margin: 2cm;
    }

    body {
      background: white;
    }

    .page, .cover, .back-cover {
      page-break-after: always;
    }

    .callout, .exhibit {
      page-break-inside: avoid;
    }

    @page :first {
      @top-center { content: none; }
      @bottom-center { content: none; }
    }

    @page {
      @top-center {
        content: "Ainary Report | The Transatlantic Divide";
        font-size: 0.7rem;
        color: #888;
      }
      @bottom-left {
        content: "© 2026 Ainary Ventures";
        font-size: 0.7rem;
        color: #888;
      }
      @bottom-right {
        content: counter(page);
        font-size: 0.7rem;
        color: #888;
      }
    }
  }
</style>
</head>
<body>

<!-- ========================================
     COVER PAGE
     ======================================== -->
<div class="cover">
  <div class="cover-header">
    <div class="cover-brand">
      <span class="gold-punkt">●</span>
      <span class="brand-name">Ainary</span>
    </div>
    <div class="cover-meta">
      <span>AR-003</span>
      <span>Confidence: 75%</span>
    </div>
  </div>

  <div class="cover-title-block">
    <h1 class="cover-title">The Transatlantic Divide</h1>
    <p class="cover-subtitle">How EU and US AI Regulation Creates Two Different Futures for AI Agents</p>
  </div>

  <div class="cover-footer">
    <div class="cover-date">
      February 2026<br>
      <span style="font-size: 0.7rem; color: #aaa;">v1.0</span>
    </div>
    <div class="cover-author">
      Florian Ziesche · Ainary Ventures
    </div>
  </div>
</div>

<!-- ========================================
     TABLE OF CONTENTS
     ======================================== -->
<div class="page">
  <p class="toc-label">Contents</p>

  <div class="toc-section">
    <p class="toc-section-label">FOUNDATION</p>
    <a href="#how-to-read" class="toc-entry">
      <span class="toc-number">1</span>
      <span class="toc-title">How to Read This Report</span>
      <span class="toc-page">4</span>
    </a>
    <a href="#exec-summary" class="toc-entry">
      <span class="toc-number">2</span>
      <span class="toc-title">Executive Summary</span>
      <span class="toc-page">5</span>
    </a>
    <a href="#methodology" class="toc-entry">
      <span class="toc-number">3</span>
      <span class="toc-title">Methodology</span>
      <span class="toc-page">6</span>
    </a>
  </div>

  <div class="toc-section">
    <p class="toc-section-label">ANALYSIS</p>
    <a href="#munich-vs-nyc" class="toc-entry">
      <span class="toc-number">4</span>
      <span class="toc-title">The Munich vs NYC Experience</span>
      <span class="toc-page">7</span>
    </a>
    <a href="#eu-approach" class="toc-entry">
      <span class="toc-number">5</span>
      <span class="toc-title">The EU Approach: Regulate First, Innovate Within Boundaries</span>
      <span class="toc-page">8</span>
    </a>
    <a href="#us-approach" class="toc-entry">
      <span class="toc-number">6</span>
      <span class="toc-title">The US Approach: Move Fast, Regulate Never</span>
      <span class="toc-page">11</span>
    </a>
    <a href="#comparison-matrix" class="toc-entry">
      <span class="toc-number">7</span>
      <span class="toc-title">The Comparison Matrix</span>
      <span class="toc-page">13</span>
    </a>
    <a href="#agent-shaped-hole" class="toc-entry">
      <span class="toc-number">8</span>
      <span class="toc-title">The Agent-Shaped Hole</span>
      <span class="toc-page">15</span>
    </a>
    <a href="#regulatory-arbitrage" class="toc-entry">
      <span class="toc-number">9</span>
      <span class="toc-title">Regulatory Arbitrage and the Transatlantic Trap</span>
      <span class="toc-page">17</span>
    </a>
  </div>

  <div class="toc-section">
    <p class="toc-section-label">ACTION</p>
    <a href="#what-to-do" class="toc-entry">
      <span class="toc-number">10</span>
      <span class="toc-title">What to Do: A Practitioner's Framework</span>
      <span class="toc-page">19</span>
    </a>
    <a href="#transparency" class="toc-entry">
      <span class="toc-number">11</span>
      <span class="toc-title">Transparency Note</span>
      <span class="toc-page">21</span>
    </a>
    <a href="#claim-register" class="toc-entry">
      <span class="toc-number">12</span>
      <span class="toc-title">Claim Register</span>
      <span class="toc-page">22</span>
    </a>
    <a href="#references" class="toc-entry">
      <span class="toc-number">13</span>
      <span class="toc-title">References</span>
      <span class="toc-page">23</span>
    </a>
  </div>
</div>

<!-- ========================================
     HOW TO READ THIS REPORT
     ======================================== -->
<div class="page" id="how-to-read">
  <h2>1. How to Read This Report</h2>

  <p>This report uses a structured confidence rating system to communicate what is known versus what is inferred. Every quantitative claim carries its source and confidence level.</p>

  <table class="how-to-read-table">
    <tr>
      <th>Rating</th>
      <th>Meaning</th>
      <th>Example</th>
    </tr>
    <tr>
      <td>High</td>
      <td>3 plus independent sources, peer-reviewed or primary data</td>
      <td>EU AI Act enforcement date (legislative text)</td>
    </tr>
    <tr>
      <td>Medium</td>
      <td>1 to 2 sources, plausible but not independently confirmed</td>
      <td>Compliance cost estimates (single industry source)</td>
    </tr>
    <tr>
      <td>Low</td>
      <td>Single secondary source, methodology unclear</td>
      <td>Specific regulatory timelines (agency announcements)</td>
    </tr>
  </table>

  <p style="margin-top: 24px;">This report was produced using a <strong>multi-agent research pipeline</strong> with structured cross-referencing and gap research. Full methodology details are provided in the Transparency Note (Section 11).</p>
</div>

<!-- ========================================
     EXECUTIVE SUMMARY
     ======================================== -->
<div class="page" id="exec-summary">
  <h2>2. Executive Summary</h2>

  <p class="thesis">The EU and US are building two incompatible regulatory frameworks for AI agents — and companies operating in both markets are caught in the middle.</p>

  <ul class="evidence-list">
    <li><strong>The EU AI Act becomes fully enforceable on 2 August 2026</strong><sup>[7]</sup>, with penalties up to 35 million euros or 7% of global revenue<sup>[2]</sup> — while the US has no comprehensive federal AI regulation after rescinding Biden's executive order<sup>[3]</sup>.</li>
    <li><strong>EU compliance costs run 5 to 20 times higher than US equivalents</strong><sup>[4]</sup>, creating a structural disadvantage for companies that must operate in both markets.</li>
    <li><strong>Neither framework actually defines or addresses AI agents.</strong> The EU assumes static systems; the US hasn't started. Multi-agent liability is a black hole in both jurisdictions<sup>[5]</sup>.</li>
    <li><strong>Regulatory arbitrage is harder than it looks.</strong> The EU AI Act has extraterritorial reach — if your AI system's output is used in the Union, you're in scope, regardless of where your servers sit<sup>[6]</sup>.</li>
    <li><strong>The pragmatic move: build for EU compliance as your floor, use US speed as your ceiling.</strong> Companies that treat compliance infrastructure as trust infrastructure will win in both markets.</li>
  </ul>

  <div class="kpi-grid">
    <div class="kpi">
      <div class="kpi-number">35M euros</div>
      <div class="kpi-label">max penalty (or 7% revenue)</div>
      <div class="kpi-source">Source: EU AI Act Article 99 | Confidence: High</div>
    </div>
    <div class="kpi">
      <div class="kpi-number">5 to 20 times</div>
      <div class="kpi-label">EU vs US compliance cost</div>
      <div class="kpi-source">Source: axis-intelligence.com | Confidence: Medium</div>
    </div>
    <div class="kpi">
      <div class="kpi-number">Aug 2026</div>
      <div class="kpi-label">full enforcement date</div>
      <div class="kpi-source">Source: artificialintelligenceact.eu | Confidence: High</div>
    </div>
  </div>

  <p class="keywords"><strong>Keywords:</strong> AI Regulation, EU AI Act, Regulatory Divergence, Compliance Costs, Agent Liability, Transatlantic Policy, Technology Governance</p>
</div>

<!-- ========================================
     METHODOLOGY (SHORT VERSION)
     ======================================== -->
<div class="page" id="methodology">
  <h2>3. Methodology</h2>

  <p>This report synthesizes primary research from legislative texts (EU AI Act, executive orders), regulatory publications (NIST, SEC, BaFin, FCA, MAS), and industry compliance data. The research pipeline followed a structured process: 15 research briefs covering adversarial AI, agent memory, agent protocols, failure taxonomies, and regulatory frameworks were produced independently, then synthesized to identify contradictions and compound effects.</p>

  <p><strong>Limitations:</strong> Compliance cost estimates rely on single industry sources and have not been independently verified through multiple organizations. The agent-specific regulatory gap is documented by absence, not by affirmative statements from regulators. Production incident data is scarce because most agent deployments are recent and organizations do not publicly disclose agent-specific security or compliance failures.</p>

  <p style="font-size: 0.85rem; color: #666; margin-top: 16px;">Full methodology details, including confidence calibration and known weaknesses, are provided in the Transparency Note (Section 11).</p>
</div>

<!-- ========================================
     SECTION 4: MUNICH VS NYC
     ======================================== -->
<div class="page" id="munich-vs-nyc">
  <h2>4. The Munich vs NYC Experience
    <span class="confidence-badge">High</span>
  </h2>
  <span class="confidence-line">(Confidence: High)</span>

  <p><span class="key-insight">I've built AI products in both Munich and New York. Same codebase, same team, same product — two completely different regulatory realities.</span></p>

  <p>In Munich, the conversation with enterprise clients starts with compliance. "Where's your conformity assessment? Show me the audit trail. Who's the human in the loop?" In New York, the conversation starts with capability. "How fast can you ship? What's the ROI in 90 days?"</p>

  <p>Neither conversation is wrong. But they're incompatible.</p>

  <p>When I first realized that an AI agent feature I'd designed for the US market — one that autonomously processes job applications and ranks candidates — would be classified as "high-risk" under the EU AI Act and require a full conformity assessment, months of documentation, and mandatory human oversight before I could legally deploy it in Germany, the regulatory gap stopped being abstract. It became a product decision, a hiring decision, and a budget decision, all at once.</p>

  <p>This report maps that gap. Not as a policy paper — there are enough of those. As a practitioner's guide for anyone building AI products that need to work on both sides of the Atlantic.</p>

  <div class="callout invalidation">
    <p class="callout-label">What Would Invalidate This?</p>
    <p class="callout-body">A US-EU mutual recognition agreement on AI — essentially an AI trade deal. No such negotiations are underway as of February 2026.</p>
  </div>

  <div class="callout sowhat">
    <p class="callout-label">So What?</p>
    <p class="callout-body">If you're building AI products that operate in both markets, the regulatory divergence isn't a future problem — it's here. Every product decision is now a dual-compliance decision.</p>
  </div>
</div>

<!-- ========================================
     SECTION 5: EU APPROACH
     ======================================== -->
<div class="page" id="eu-approach">
  <h2>5. The EU Approach: Regulate First, Innovate Within Boundaries
    <span class="confidence-badge">High</span>
  </h2>
  <span class="confidence-line">(Confidence: High)</span>

  <h3>Evidence</h3>

  <p>The EU AI Act entered into force on 1 August 2024<sup>[1]</sup>. Implementation is phased, and the calendar matters:</p>

  <div class="timeline">
    <div class="timeline-item">
      <div class="timeline-marker"></div>
      <div class="timeline-content"><strong>February 2025:</strong> Prohibited AI practices and AI literacy requirements became enforceable<sup>[7]</sup>.</div>
    </div>
    <div class="timeline-item">
      <div class="timeline-marker"></div>
      <div class="timeline-content"><strong>August 2025:</strong> Obligations for general-purpose AI models kicked in; member states began designating competent authorities<sup>[7]</sup>.</div>
    </div>
    <div class="timeline-item">
      <div class="timeline-marker"></div>
      <div class="timeline-content"><strong>August 2026:</strong> Full application — all high-risk AI system requirements, conformity assessments, transparency obligations, market surveillance<sup>[7]</sup>.</div>
    </div>
    <div class="timeline-item">
      <div class="timeline-marker"></div>
      <div class="timeline-content"><strong>August 2027:</strong> Legacy AI models and remaining Article 6(1) systems must comply<sup>[7]</sup>.</div>
    </div>
  </div>

  <p>The high-risk categories that matter most for AI agent deployments are in Annex III: employment and hiring, credit scoring, insurance underwriting, critical infrastructure, education, and law enforcement<sup>[8]</sup>. If your agent touches any of these domains, you need a conformity assessment before you can legally deploy in the EU.</p>

  <p>What's outright banned is worth stating plainly. As of February 2025, the following are prohibited in the EU<sup>[8]</sup>:</p>

  <ul>
    <li>Social scoring by governments</li>
    <li>Real-time biometric surveillance in public spaces (with narrow law enforcement exceptions)</li>
    <li>Emotion recognition in workplaces and schools</li>
    <li>Subliminal manipulation techniques</li>
    <li>AI systems that exploit vulnerable groups</li>
    <li>Individual-level predictive policing</li>
  </ul>

  <p>The penalties are not theoretical: up to 35 million euros or 7% of global annual turnover, whichever is higher<sup>[2]</sup>. For context, GDPR's maximum is 4% of turnover. The EU AI Act is deliberately more aggressive.</p>

  <h3>Interpretation</h3>

  <p>The compliance cost is where this gets real. Mid-size companies face an estimated $2 to 5 million in initial compliance costs<sup>[4]</sup>, with ongoing expenses of 300,000 to 500,000 euros per year for maintaining 3 to 5 high-risk AI systems<sup>[4]</sup>. That's conformity assessments, audit trail infrastructure, human-in-the-loop staffing, and continuous documentation.</p>

  <p>And here's the paradox I keep running into: the EU requires "effective human oversight" for high-risk AI<sup>[8]</sup>, but the empirical evidence says human oversight doesn't work the way regulators imagine. In cybersecurity, 67% of SOC alerts are ignored by analysts<sup>[9]</sup>. In healthcare AI, false positive rates run 80 to 99%<sup>[10]</sup>, causing the exact alert fatigue that makes human oversight a rubber stamp rather than a safety mechanism.</p>

  <p>The regulation assumes a world where a human carefully reviews each AI decision. The reality is a tired compliance officer clicking "approve" 200 times a day. This is the HITL paradox — and the EU AI Act doesn't have an answer for it.</p>

  <div class="callout invalidation">
    <p class="callout-label">What Would Invalidate This?</p>
    <p class="callout-body">If the EU delays enforcement the way it soft-launched GDPR (18 months of warnings before real fines). Possible, but EU authorities haven't signaled this.</p>
  </div>

  <div class="callout sowhat">
    <p class="callout-label">So What?</p>
    <p class="callout-body">If you're deploying high-risk AI in the EU, budget for compliance as a line item — not an afterthought. And design your human oversight to actually work, not just to check a regulatory box.</p>
  </div>
</div>

<!-- ========================================
     SECTION 6: US APPROACH
     ======================================== -->
<div class="page" id="us-approach">
  <h2>6. The US Approach: Move Fast, Regulate Never
    <span class="confidence-badge">High</span>
  </h2>
  <span class="confidence-line">(Confidence: High)</span>

  <h3>Evidence</h3>

  <p>On 20 January 2025, the first day of the Trump administration, Executive Order 14110 — Biden's framework for "Safe, Secure, and Trustworthy AI" — was rescinded<sup>[3]</sup>. In its place: EO 14179, titled "Removing Barriers to American Leadership in AI"<sup>[11]</sup>. The name says everything.</p>

  <p>The US federal position on AI regulation as of February 2026:</p>

  <ul>
    <li>No mandatory compliance framework</li>
    <li>No federal AI safety requirements</li>
    <li>NIST continues its voluntary AI Risk Management Framework<sup>[12]</sup>, but with a reduced mandate</li>
    <li>The White House AI priority page leads with "Lead the World in AI"<sup>[11]</sup></li>
  </ul>

  <p>What exists at the state level is fragmented. Colorado's AI Act (SB 24-205) went into effect on 1 February 2026 — the first comprehensive state-level AI law actually in force<sup>[13]</sup>. It requires developers and deployers of "high-risk" AI systems to use "reasonable care" to avoid algorithmic discrimination. California's more ambitious SB 1047, which would have mandated safety testing for frontier models trained with over 10 to the 26 FLOPS, was vetoed by Governor Newsom in September 2024<sup>[14]</sup>. Over 40 states have introduced AI-related bills<sup>[15]</sup>, but the landscape is patchwork at best.</p>

  <p>NIST's Center for AI Safety and Innovation (CAISI) issued a request for information on agent-specific security in January 2026, with a March 2026 deadline for responses<sup>[12]</sup>. This is the US government acknowledging the gap — but an RFI is a question, not an answer.</p>

  <h3>Interpretation</h3>

  <p>The US approach creates a different kind of risk. Not regulatory risk — liability risk. When there's no federal framework and a major AI agent failure happens, the legal precedent gets set by whichever lawsuit lands first. Product liability law, tort law, negligence frameworks — none of these were designed for autonomous, goal-directed AI systems that learn and adapt.</p>

  <p>Only 5 of 41 federal agencies had created AI governance plans by the last comprehensive audit<sup>[16]</sup>. The institutional infrastructure for AI oversight simply doesn't exist at the federal level.</p>

  <div class="callout invalidation">
    <p class="callout-label">What Would Invalidate This?</p>
    <p class="callout-body">A major AI agent catastrophe in the US forcing emergency federal legislation. Our research estimates a 55% probability of a greater than $100M AI agent incident within 12 months<sup>[17]</sup>.</p>
  </div>

  <div class="callout sowhat">
    <p class="callout-label">So What?</p>
    <p class="callout-body">US-based companies have more freedom to ship, but less predictability about what happens when things go wrong. The absence of regulation isn't the absence of risk — it's the absence of clarity about who holds the risk.</p>
  </div>
</div>

<!-- ========================================
     SECTION 7: COMPARISON MATRIX
     ======================================== -->
<div class="page" id="comparison-matrix">
  <h2>7. The Comparison Matrix: Same Product, Different Rules
    <span class="confidence-badge">High</span>
  </h2>
  <span class="confidence-line">(Confidence: High)</span>

  <p>Here's what the divergence looks like in practice. Same AI capability, different legal status:</p>

  <div class="exhibit">
    <p class="exhibit-label">Exhibit 1: Banned in the EU, unrestricted in the US</p>
    <table class="exhibit-table">
      <tr>
        <th>Capability</th>
        <th>EU Status</th>
        <th>US Status</th>
      </tr>
      <tr>
        <td>Social scoring by government agencies</td>
        <td>Banned</td>
        <td>Unrestricted</td>
      </tr>
      <tr>
        <td>Real-time biometric surveillance in public spaces</td>
        <td>Banned</td>
        <td>Unrestricted</td>
      </tr>
      <tr>
        <td>Emotion recognition in workplaces or schools</td>
        <td>Banned</td>
        <td>Unrestricted</td>
      </tr>
      <tr>
        <td>Subliminal AI-driven manipulation</td>
        <td>Banned</td>
        <td>Unrestricted</td>
      </tr>
      <tr>
        <td>Individual-level predictive policing</td>
        <td>Banned</td>
        <td>Unrestricted</td>
      </tr>
    </table>
    <p class="exhibit-source">Source: EU AI Act Article 5</p>
  </div>

  <div class="exhibit">
    <p class="exhibit-label">Exhibit 2: Regulated in the EU, largely unregulated in the US</p>
    <table class="exhibit-table">
      <tr>
        <th>Capability</th>
        <th>EU</th>
        <th>US</th>
      </tr>
      <tr>
        <td>AI in hiring decisions</td>
        <td>Conformity assessment plus HITL required</td>
        <td>NYC Local Law 144 for bias audits, Colorado from Feb 2026, otherwise nothing</td>
      </tr>
      <tr>
        <td>AI in credit scoring</td>
        <td>High-risk classification</td>
        <td>Existing ECOA and FCRA apply, no AI-specific rules</td>
      </tr>
      <tr>
        <td>AI-generated content transparency</td>
        <td>Mandatory disclosure under Article 50</td>
        <td>No federal requirement</td>
      </tr>
    </table>
    <p class="exhibit-source">Source: EU AI Act Annex III; State-level legislation analysis</p>
  </div>

  <h3>The Cost Delta</h3>

  <p>But here's the trap: the EU AI Act has extraterritorial reach<sup>[6]</sup>. Article 2 makes clear that the Act applies to any provider placing an AI system on the EU market, and to any deployer "located within the Union" — regardless of where the provider is based. If your AI system's output is "used in the Union," you're in scope.</p>

  <p>This is the GDPR playbook, applied to AI. And just like GDPR, companies that assumed "my servers are in the US, so EU law doesn't apply" learned expensive lessons.</p>

  <div class="callout invalidation">
    <p class="callout-label">What Would Invalidate This?</p>
    <p class="callout-body">An EU-US equivalence framework — something like the Privacy Shield replacement, but for AI. No such mechanism is under discussion.</p>
  </div>

  <div class="callout sowhat">
    <p class="callout-label">So What?</p>
    <p class="callout-body">If you have EU customers, you have EU compliance obligations. Full stop. The "just don't sell to Europe" strategy only works if you're willing to write off 450 million potential users.</p>
  </div>
</div>

<!-- ========================================
     SECTION 8: AGENT-SHAPED HOLE
     ======================================== -->
<div class="page" id="agent-shaped-hole">
  <h2>8. The Agent-Shaped Hole
    <span class="confidence-badge">High</span>
  </h2>
  <span class="confidence-line">(Confidence: High)</span>

  <p><span class="key-insight">Here's what surprised me most in this research: neither the EU nor the US actually regulates AI agents. Both frameworks have an agent-shaped hole at their center.</span></p>

  <h3>The EU Gap</h3>

  <p>The EU AI Act defines "AI system" but never mentions autonomous, goal-directed, multi-step agents<sup>[8]</sup>. This creates three specific problems:</p>

  <p><strong>Provider vs. deployer ambiguity in multi-agent systems.</strong> If Agent A calls Agent B, which then triggers Agent C — who is the "provider"? Who is the "deployer"? The AI Act's liability chain assumes a linear relationship: one provider builds it, one deployer uses it. Multi-agent architectures break this assumption entirely<sup>[5]</sup>.</p>

  <p><strong>HITL vs. autonomy.</strong> High-risk AI requires "effective human oversight"<sup>[8]</sup>. But agents are designed to operate autonomously — that's the entire value proposition. The regulation is structurally incompatible with the technology it's trying to regulate.</p>

  <p><strong>Static systems vs. learning agents.</strong> The AI Act's conformity assessment assumes a system that behaves consistently after deployment<sup>[8]</sup>. An agent that learns from interactions — adjusting its behavior based on user feedback or environmental data — might shift risk categories after passing its initial assessment.</p>

  <p>The EU also scrapped the AI Liability Directive in August 2025<sup>[5]</sup>, which was supposed to create a clear liability framework for AI-caused harm. The result: a regulation that tells you what you must do, but no clear liability framework for when things go wrong anyway.</p>

  <h3>The US Gap</h3>

  <p>The US gap is simpler to describe: there's no federal framework at all for AI agents<sup>[3]</sup><sup>[11]</sup>. NIST's January 2026 RFI on agent-specific security acknowledges this<sup>[12]</sup>, but an RFI with a March deadline means actual guidance is months or years away.</p>

  <p>Existing liability frameworks — product liability, tort, negligence — have never been tested against autonomous AI systems. Only 10% of organizations have a non-human identity strategy<sup>[19]</sup>, meaning most companies haven't even figured out how to authenticate their agents, let alone govern them. And 23% of organizations report agent credential leaks<sup>[20]</sup> — a security gap with no regulatory backstop.</p>

  <h3>The Positive Example: AWS and ISO 42001</h3>

  <p>Not everything is bleak. AWS obtained ISO 42001 certification in January 2026<sup>[21]</sup> — the first major cloud provider to do so. ISO 42001 isn't legally required under either framework, but it's the closest thing to a bridge between EU conformity requirements and US voluntary standards. Companies building toward ISO 42001 are positioning themselves to satisfy both regimes with a single governance infrastructure. It's not perfect — ISO certification isn't a substitute for EU conformity assessment — but it's the most pragmatic approach I've seen to the dual-compliance problem.</p>

  <div class="callout invalidation">
    <p class="callout-label">What Would Invalidate This?</p>
    <p class="callout-body">If the EU issues specific guidance on AI agents before August 2026, or if the US fast-tracks NIST's agent-specific framework. Both are possible but neither is likely in the next six months.</p>
  </div>

  <div class="callout sowhat">
    <p class="callout-label">So What?</p>
    <p class="callout-body">If you're building AI agents that operate in both markets, you're in uncharted legal territory. Not because the rules are too strict — because the rules don't exist yet. The first major lawsuit involving a multi-agent system failure will set precedent for everyone.</p>
  </div>
</div>

<!-- ========================================
     SECTION 9: REGULATORY ARBITRAGE
     ======================================== -->
<div class="page" id="regulatory-arbitrage">
  <h2>9. Regulatory Arbitrage and the Transatlantic Trap
    <span class="confidence-badge">Medium</span>
  </h2>
  <span class="confidence-line">(Confidence: Medium)</span>

  <p>Companies aren't waiting for regulators to sort this out. Patterns are emerging:</p>

  <p><strong>Pattern 1: Train in the US, deploy a compliant version in the EU.</strong> Most common approach. Keep your R and D velocity in a permissive environment, then wrap the EU deployment in compliance infrastructure. Works, but doubles your deployment cost.</p>

  <p><strong>Pattern 2: Strip features for the EU market.</strong> Remove emotion recognition, limit autonomous decision-making, add human checkpoints. The "EU-light" version. Pragmatic, but your EU customers get an inferior product.</p>

  <p><strong>Pattern 3: The jurisdictional SaaS play.</strong> Incorporate in the US, sell to EU customers via SaaS, argue that the "system" isn't "placed on the EU market." This worked for some companies pre-GDPR. It won't work here — Article 2's extraterritorial scope is explicit<sup>[6]</sup>.</p>

  <h3>Winners and Losers</h3>

  <p><strong>The winners</strong> are predictable: GRC and compliance SaaS companies (OneTrust, Holistic AI, Credo AI), EU-based AI auditing firms building a new industry around conformity assessments, and AI insurance startups like AIUC, which raised a $15M seed round<sup>[22]</sup> specifically because compliance complexity creates insurance demand.</p>

  <p><strong>The losers</strong> are less obvious but more numerous: EU startups drowning in compliance overhead that their US competitors don't face, transatlantic mid-market companies ($50M to $500M revenue) that must maintain dual compliance without Big Tech's legal departments, and open-source AI projects where the EU's obligations on "providers" create existential ambiguity for contributors.</p>

  <div class="callout invalidation">
    <p class="callout-label">What Would Invalidate This?</p>
    <p class="callout-body">If EU enforcement takes a light-touch approach in the first 12 to 18 months (the "GDPR grace period" scenario), the urgency of these strategies diminishes temporarily.</p>
  </div>

  <div class="callout sowhat">
    <p class="callout-label">So What?</p>
    <p class="callout-body">Regulatory arbitrage exists, but it's a tax optimization strategy, not a solution. You can reduce the cost of compliance; you can't eliminate it.</p>
  </div>
</div>

<!-- ========================================
     SECTION 10: WHAT TO DO
     ======================================== -->
<div class="page" id="what-to-do">
  <h2>10. What to Do: A Practitioner's Framework</h2>

  <p>I've spent the last six months researching AI agent trust systems, and this is where the regulation work connects to everything else. Here's what I'd tell any CTO or General Counsel at a transatlantic company:</p>

  <p style="font-size: 1rem; font-weight: 600; color: #1a1a1a; margin: 24px 0;"><strong>Build for EU compliance as your floor. Use US speed as your ceiling.</strong></p>

  <p>Five steps, in priority order:</p>

  <div class="steps">
    <div class="step">
      <div class="step-num">1</div>
      <div class="step-content">
        <h4>Classify your AI systems under Annex III now.</h4>
        <p>Don't wait for August 2026. The categories are published<sup>[8]</sup>. If any of your AI touches employment, credit, insurance, education, law enforcement, or critical infrastructure in the EU, it's high-risk. Know this before your competitor does.</p>
      </div>
    </div>
    <div class="step">
      <div class="step-num">2</div>
      <div class="step-content">
        <h4>Build audit trails that satisfy both ISO 42001 and EU conformity requirements.</h4>
        <p>AWS got ISO 42001 certified for a reason<sup>[21]</sup>. A single governance infrastructure that covers both frameworks is cheaper than building two separate compliance systems. Start here.</p>
      </div>
    </div>
    <div class="step">
      <div class="step-num">3</div>
      <div class="step-content">
        <h4>Design human oversight that actually works.</h4>
        <p>Not checkbox HITL — real human oversight. If 67% of alerts are ignored<sup>[9]</sup>, your human-in-the-loop is a human-on-paper. Design for attention, not compliance. Escalation hierarchies. Meaningful decision points. Reduced alert volume with higher signal.</p>
      </div>
    </div>
    <div class="step">
      <div class="step-num">4</div>
      <div class="step-content">
        <h4>Track US state-level AI laws monthly.</h4>
        <p>Colorado is live<sup>[13]</sup>. California will try again. Illinois, Texas, Connecticut have narrower laws already. The patchwork is expanding. Budget $50K to $150K per state for compliance where you operate<sup>[18]</sup>.</p>
      </div>
    </div>
    <div class="step">
      <div class="step-num">5</div>
      <div class="step-content">
        <h4>Budget for dual compliance: $2 to 5M EU plus $100K to $500K US.</h4>
        <p>These are real numbers<sup>[4]</sup><sup>[18]</sup>. Put them in your 2026 operating plan. The companies that budget for this in advance will outperform those that scramble after the first enforcement action.</p>
      </div>
    </div>
  </div>

  <p>The meta-insight: compliance infrastructure is trust infrastructure. The audit trails you build for EU conformity? They're the same systems that let you prove to US enterprise customers that your AI is reliable. The human oversight you design for regulatory reasons? It's the same mechanism that catches agent failures before they become front-page incidents.</p>

  <p>The regulatory divide is real, expensive, and getting wider. But the companies that build a single trust layer — one that satisfies the strictest requirements — will move faster in both markets than those trying to maintain two separate systems.</p>
</div>

<!-- ========================================
     TRANSPARENCY NOTE
     ======================================== -->
<div class="page" id="transparency">
  <h2>11. Transparency Note</h2>

  <p class="transparency-intro">This section discloses the methodology, confidence assessment, and known limitations of this report.</p>

  <table class="transparency-table">
    <tr>
      <td>Overall Confidence</td>
      <td>75%. High confidence on regulatory facts (legislative texts, enforcement dates, penalty structures). Medium confidence on compliance cost estimates (single industry source). Medium confidence on agent-specific gap analysis (documented by regulatory silence, not affirmative statements).</td>
    </tr>
    <tr>
      <td>Sources</td>
      <td>18 total. 10 new (legislative texts, regulatory publications, industry reports, corporate disclosures). 8 from existing research library (agent trust systems, adversarial attacks, memory architectures, human-in-the-loop failure modes).</td>
    </tr>
    <tr>
      <td>Strongest Evidence</td>
      <td>EU AI Act legislative text (Official Journal), enforcement timeline (artificialintelligenceact.eu), penalty structures (Article 99). US executive order rescission (verified via NIST.gov and whitehouse.gov). Extraterritorial reach provisions (Article 2).</td>
    </tr>
    <tr>
      <td>Weakest Point</td>
      <td>Compliance cost estimates ($2 to 5M EU, $100K to $500K US) rely on single industry sources (axis-intelligence.com, practitioner reports). These have not been independently verified through multiple organizations. The agent-specific regulatory gap is documented by absence — no regulator has affirmatively addressed multi-agent liability chains or autonomous decision-making frameworks.</td>
    </tr>
    <tr>
      <td>What Would Invalidate</td>
      <td>Two scenarios: (1) A US-EU mutual recognition agreement or equivalence framework for AI regulation would eliminate the dual-compliance problem. (2) Agent-specific regulatory guidance from EU or NIST before August 2026 would close the documented gap.</td>
    </tr>
    <tr>
      <td>Methodology</td>
      <td>Multi-agent research pipeline with structured cross-referencing. 15 research briefs produced independently (adversarial AI, agent memory, protocols, failure taxonomies, regulatory frameworks), then synthesized to identify contradictions and gaps. Gap analysis flagged three unresolved questions: enforcement precedent, agent liability chains, mutual recognition prospects.</td>
    </tr>
    <tr>
      <td>System Disclosure</td>
      <td>This report was created with a multi-agent research system. A dedicated research agent conducted targeted investigation, producing a structured brief with claim register and confidence ratings. A synthesis step cross-referenced findings against 14 prior research briefs. I wrote this report from the structured outline, separating evidence from interpretation throughout.</td>
    </tr>
  </table>
</div>

<!-- ========================================
     CLAIM REGISTER
     ======================================== -->
<div class="page" id="claim-register">
  <h2>12. Claim Register</h2>

  <div class="exhibit">
    <table class="exhibit-table">
      <tr>
        <th>#</th>
        <th>Claim</th>
        <th>Value</th>
        <th>Source</th>
        <th>Confidence</th>
        <th>Used In</th>
      </tr>
      <tr>
        <td>1</td>
        <td>EU AI Act entry into force</td>
        <td>1 Aug 2024</td>
        <td>[1]</td>
        <td>High</td>
        <td>Sec 5</td>
      </tr>
      <tr>
        <td>2</td>
        <td>Maximum penalty</td>
        <td>35M euros or 7% turnover</td>
        <td>[2]</td>
        <td>High</td>
        <td>Sec 2, 5</td>
      </tr>
      <tr>
        <td>3</td>
        <td>Biden EO 14110 rescinded</td>
        <td>20 Jan 2025</td>
        <td>[3]</td>
        <td>High</td>
        <td>Sec 2, 6</td>
      </tr>
      <tr>
        <td>4</td>
        <td>EU compliance cost (initial)</td>
        <td>$2 to 5M</td>
        <td>[4]</td>
        <td>Medium</td>
        <td>Sec 2, 5, 10</td>
      </tr>
      <tr>
        <td>5</td>
        <td>Agent-specific regulatory gaps</td>
        <td>Multi-agent liability undefined</td>
        <td>[5]</td>
        <td>High</td>
        <td>Sec 2, 8</td>
      </tr>
      <tr>
        <td>6</td>
        <td>Extraterritorial reach</td>
        <td>Article 2 applies to EU use</td>
        <td>[6]</td>
        <td>High</td>
        <td>Sec 2, 7, 9</td>
      </tr>
      <tr>
        <td>7</td>
        <td>Full enforcement date</td>
        <td>2 Aug 2026</td>
        <td>[7]</td>
        <td>High</td>
        <td>Sec 2, 5</td>
      </tr>
      <tr>
        <td>8</td>
        <td>High-risk categories</td>
        <td>Annex III domains</td>
        <td>[8]</td>
        <td>High</td>
        <td>Sec 5, 8, 10</td>
      </tr>
      <tr>
        <td>9</td>
        <td>SOC alerts ignored</td>
        <td>67%</td>
        <td>[9]</td>
        <td>High</td>
        <td>Sec 5, 10</td>
      </tr>
      <tr>
        <td>10</td>
        <td>Healthcare AI false positives</td>
        <td>80 to 99%</td>
        <td>[10]</td>
        <td>High</td>
        <td>Sec 5</td>
      </tr>
      <tr>
        <td>11</td>
        <td>Trump EO 14179</td>
        <td>Removing Barriers to AI</td>
        <td>[11]</td>
        <td>High</td>
        <td>Sec 6, 8</td>
      </tr>
      <tr>
        <td>12</td>
        <td>NIST CAISI RFI</td>
        <td>Jan 2026, Mar deadline</td>
        <td>[12]</td>
        <td>High</td>
        <td>Sec 6, 8</td>
      </tr>
      <tr>
        <td>13</td>
        <td>Colorado AI Act effective</td>
        <td>1 Feb 2026</td>
        <td>[13]</td>
        <td>High</td>
        <td>Sec 6, 10</td>
      </tr>
      <tr>
        <td>14</td>
        <td>California SB 1047 vetoed</td>
        <td>Sep 2024</td>
        <td>[14]</td>
        <td>High</td>
        <td>Sec 6</td>
      </tr>
      <tr>
        <td>15</td>
        <td>State AI bills introduced</td>
        <td>Over 40 states</td>
        <td>[15]</td>
        <td>High</td>
        <td>Sec 6</td>
      </tr>
      <tr>
        <td>16</td>
        <td>Federal AI governance plans</td>
        <td>5 of 41 agencies</td>
        <td>[16]</td>
        <td>High</td>
        <td>Sec 6</td>
      </tr>
      <tr>
        <td>17</td>
        <td>100M plus incident probability</td>
        <td>55% within 12 months</td>
        <td>[17]</td>
        <td>Medium</td>
        <td>Sec 6</td>
      </tr>
      <tr>
        <td>18</td>
        <td>US state compliance costs</td>
        <td>$50K to $150K per state</td>
        <td>[18]</td>
        <td>Medium</td>
        <td>Sec 10</td>
      </tr>
      <tr>
        <td>19</td>
        <td>Non-human identity strategy</td>
        <td>Only 10%</td>
        <td>[19]</td>
        <td>High</td>
        <td>Sec 8</td>
      </tr>
      <tr>
        <td>20</td>
        <td>Agent credential leaks</td>
        <td>23% of orgs</td>
        <td>[20]</td>
        <td>High</td>
        <td>Sec 8</td>
      </tr>
      <tr>
        <td>21</td>
        <td>AWS ISO 42001 certified</td>
        <td>Jan 2026</td>
        <td>[21]</td>
        <td>High</td>
        <td>Sec 8, 10</td>
      </tr>
      <tr>
        <td>22</td>
        <td>AIUC seed round</td>
        <td>$15M</td>
        <td>[22]</td>
        <td>High</td>
        <td>Sec 9</td>
      </tr>
    </table>
  </div>

  <p style="margin-top: 24px; font-size: 0.85rem; color: #666;"><strong>Top 5 Claims with Invalidation Conditions:</strong></p>

  <ol style="margin-top: 12px; font-size: 0.85rem; color: #555;">
    <li><strong>Full enforcement 2 Aug 2026 [7]:</strong> Invalidated if EU delays enforcement with an 18-month grace period (GDPR precedent).</li>
    <li><strong>Extraterritorial reach [6]:</strong> Invalidated if EU-US mutual recognition agreement creates safe harbor.</li>
    <li><strong>Compliance costs $2 to 5M [4]:</strong> Invalidated if independent multi-organization data shows significantly different range.</li>
    <li><strong>No US federal framework [3][11]:</strong> Invalidated if Congress passes comprehensive AI legislation or NIST fast-tracks binding standards.</li>
    <li><strong>Agent-shaped regulatory gap [5][8]:</strong> Invalidated if EU or NIST issues agent-specific guidance before August 2026.</li>
  </ol>
</div>

<!-- ========================================
     REFERENCES
     ======================================== -->
<div class="page" id="references">
  <h2>13. References</h2>

  <p class="reference-entry">[1] EU AI Act entry into force, 1 August 2024. EU Official Journal. Verified via artificialintelligenceact.eu.</p>

  <p class="reference-entry">[2] EU AI Act penalty provisions: up to 35 million euros or 7% of global annual turnover. AI Act legislative text, Article 99.</p>

  <p class="reference-entry">[3] Biden Executive Order 14110 on Safe, Secure, and Trustworthy AI, rescinded 20 January 2025. Verified on NIST.gov (February 2026).</p>

  <p class="reference-entry">[4] EU compliance cost estimates: $2 to 5M initial for mid-size companies; 300K to 500K euros per year ongoing. Source: axis-intelligence.com. Note: single source, Medium confidence.</p>

  <p class="reference-entry">[5] Agent-specific regulatory gaps and AI Liability Directive withdrawal (August 2025). Synthesis from research-pack Briefs #8, #13, #14 and Synthesis V2.</p>

  <p class="reference-entry">[6] EU AI Act extraterritorial scope, Article 2: applies to providers placing systems on EU market and deployers located within the Union, regardless of provider location.</p>

  <p class="reference-entry">[7] EU AI Act implementation timeline. artificialintelligenceact.eu/implementation-timeline/. Verified February 2026.</p>

  <p class="reference-entry">[8] EU AI Act high-risk categories (Annex III), prohibited practices (Article 5), transparency obligations (Article 50), human oversight requirements. AI Act legislative text.</p>

  <p class="reference-entry">[9] SOC alert fatigue: 67% of alerts ignored. Vectra AI, 2023 State of Threat Detection survey (2,000 security analysts).</p>

  <p class="reference-entry">[10] Healthcare AI false positive rates: 80 to 99%. Meta-review, PubMed Central PMC6904899.</p>

  <p class="reference-entry">[11] Trump Executive Order 14179, "Removing Barriers to American Leadership in AI." Verified on whitehouse.gov, February 2026.</p>

  <p class="reference-entry">[12] NIST AI Risk Management Framework (voluntary). NIST CAISI RFI on agent-specific security, January 2026, response deadline March 2026.</p>

  <p class="reference-entry">[13] Colorado AI Act (SB 24-205), signed May 2024, effective 1 February 2026. Requires reasonable care to avoid algorithmic discrimination.</p>

  <p class="reference-entry">[14] California SB 1047 ("Safe and Secure Innovation for Frontier AI Models"), vetoed by Governor Newsom, September 2024.</p>

  <p class="reference-entry">[15] Over 40 US states introduced AI-related bills in 2024 to 2025. Multi-source legislative tracking.</p>

  <p class="reference-entry">[16] Federal AI governance: only 5 of 41 agencies had created AI plans. Stanford HAI (December 2022), cited via Brookings analysis.</p>

  <p class="reference-entry">[17] Probability estimate of greater than $100M AI agent incident within 12 months: 55%. Research pipeline estimate based on synthesis of incident trajectory data across 14 research briefs.</p>

  <p class="reference-entry">[18] US compliance costs: $100K to $500K for multi-state operation. Colorado: $50K to $150K per system. NYC Local Law 144: $20K to $50K per bias audit. Practitioner reports, Medium confidence.</p>

  <p class="reference-entry">[19] Only 10% of organizations have a non-human identity strategy. World Economic Forum, via research-pack Brief #13.</p>

  <p class="reference-entry">[20] 23% of organizations report agent credential leaks. Okta, via research-pack Brief #13.</p>

  <p class="reference-entry">[21] AWS ISO 42001 certification, January 2026. First major cloud provider to achieve AI management system certification.</p>

  <p class="reference-entry">[22] AIUC (AI insurance startup), $15M seed round. Research-pack Brief #14.</p>

  <p style="margin-top: 24px; padding-top: 16px; border-top: 1px solid #eee; font-size: 0.8rem; color: #555; font-style: italic;">
    <strong>Citation:</strong> Ainary Research (2026). The Transatlantic Divide: How EU and US AI Regulation Creates Two Different Futures for AI Agents. AR-003.
  </p>
</div>

<!-- ========================================
     AUTHOR BIO
     ======================================== -->
<div class="page">
  <div class="author-section">
    <p class="author-label">About the Author</p>
    <p class="author-bio">Florian Ziesche is the founder of Ainary Ventures, where AI does 80% of the research and humans do the 20% that matters. Before Ainary, he was CEO of 36ZERO Vision and advised startups and SMEs on AI strategy and due diligence. His conviction: HUMAN times AI equals LEVERAGE. This report is the proof.</p>
    <p style="margin-top: 12px; font-size: 0.85rem; color: #888;">ainaryventures.com</p>
  </div>
</div>

<!-- ========================================
     BACK COVER
     ======================================== -->
<div class="back-cover">
  <div class="cover-brand" style="margin-bottom: 24px;">
    <span class="gold-punkt">●</span>
    <span class="brand-name">Ainary</span>
  </div>

  <p class="back-cover-services">AI Strategy · Published Research · Daily Intelligence</p>

  <p class="back-cover-cta">
    <a href="mailto:florian@ainaryventures.com">Contact</a> · <a href="mailto:florian@ainaryventures.com?subject=Feedback: AR-003">Feedback</a>
  </p>

  <p class="back-cover-contact">
    ainaryventures.com<br>
    florian@ainaryventures.com
  </p>

  <p style="margin-top: 48px; font-size: 0.75rem; color: #888;">
    © 2026 Ainary Ventures
  </p>
</div>

</body>
</html>
