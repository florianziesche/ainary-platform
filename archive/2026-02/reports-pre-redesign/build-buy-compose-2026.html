<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>Build vs Buy vs Compose — Ainary Report AR-017</title>
<style>
  /* ========================================
     FONTS
     ======================================== */
  @font-face {
    font-family: 'Inter';
    src: url('/fonts/inter-variable.woff2') format('woff2');
    font-weight: 100 900;
    font-display: swap;
  }

  /* ========================================
     RESET & BASE
     ======================================== */
  * {
    margin: 0;
    padding: 0;
    box-sizing: border-box;
  }

  body {
    font-family: 'Inter', -apple-system, BlinkMacSystemFont, sans-serif;
    background: #fafaf8;
    color: #333;
    line-height: 1.75;
    font-size: 0.95rem;
    font-weight: 400;
  }

  /* ========================================
     LAYOUT
     ======================================== */
  .page {
    max-width: 900px;
    margin: 0 auto;
    padding: 48px 40px;
  }

  .cover {
    min-height: 100vh;
    display: flex;
    flex-direction: column;
    justify-content: space-between;
    max-width: 900px;
    margin: 0 auto;
    padding: 48px 40px;
  }

  .back-cover {
    min-height: 100vh;
    display: flex;
    flex-direction: column;
    justify-content: center;
    align-items: center;
    text-align: center;
    max-width: 900px;
    margin: 0 auto;
    padding: 48px 40px;
    page-break-before: always;
  }

  /* ========================================
     TYPOGRAPHY
     ======================================== */
  h1 {
    font-size: 2.2rem;
    font-weight: 600;
    line-height: 1.2;
    color: #1a1a1a;
    letter-spacing: -0.02em;
  }

  h2 {
    font-size: 1.5rem;
    font-weight: 600;
    color: #1a1a1a;
    line-height: 1.3;
    margin-top: 3rem;
    margin-bottom: 12px;
  }

  h3 {
    font-size: 1.1rem;
    font-weight: 600;
    color: #1a1a1a;
    line-height: 1.4;
    margin-top: 2rem;
    margin-bottom: 12px;
  }

  p {
    margin-bottom: 1rem;
  }

  strong {
    font-weight: 600;
    color: #1a1a1a;
  }

  em {
    font-style: italic;
  }

  sup {
    font-size: 0.65rem;
    color: #888;
    vertical-align: super;
  }

  /* ========================================
     COVER COMPONENTS
     ======================================== */
  .cover-header {
    display: flex;
    justify-content: space-between;
    align-items: center;
    margin-bottom: 40vh;
  }

  .cover-brand {
    display: flex;
    align-items: center;
    gap: 8px;
  }

  .gold-punkt {
    color: #c8aa50;
    font-size: 14px;
  }

  .brand-name {
    font-size: 0.85rem;
    font-weight: 500;
    color: #1a1a1a;
    letter-spacing: 0.02em;
  }

  .cover-meta {
    display: flex;
    gap: 12px;
    font-size: 0.75rem;
    color: #888;
  }

  .cover-title-block {
    margin-bottom: auto;
  }

  .cover-title {
    margin-bottom: 16px;
  }

  .cover-subtitle {
    font-size: 1rem;
    font-weight: 400;
    color: #666;
    line-height: 1.5;
  }

  .cover-footer {
    display: flex;
    justify-content: space-between;
    align-items: flex-end;
  }

  .cover-date {
    font-size: 0.75rem;
    color: #888;
  }

  .cover-author {
    font-size: 0.75rem;
    color: #888;
    text-align: center;
  }

  /* ========================================
     TABLE OF CONTENTS
     ======================================== */
  .toc-label {
    font-size: 0.7rem;
    font-weight: 600;
    color: #1a1a1a;
    text-transform: uppercase;
    letter-spacing: 0.1em;
    margin-bottom: 24px;
  }

  .toc-section {
    margin-bottom: 32px;
  }

  .toc-section-label {
    font-size: 0.65rem;
    font-weight: 500;
    color: #888;
    text-transform: uppercase;
    letter-spacing: 0.12em;
    margin-bottom: 12px;
  }

  .toc-entry {
    display: flex;
    align-items: baseline;
    gap: 16px;
    padding: 12px 0;
    border-bottom: 1px solid #eee;
    text-decoration: none;
    transition: all 0.2s;
  }

  .toc-number {
    font-size: 0.8rem;
    color: #888;
    font-variant-numeric: tabular-nums;
    min-width: 24px;
  }

  .toc-title {
    font-size: 0.95rem;
    font-weight: 500;
    color: #1a1a1a;
    flex: 1;
    transition: color 0.2s;
  }

  .toc-entry:hover .toc-title {
    color: #c8aa50;
  }

  .toc-page {
    font-size: 0.8rem;
    color: #888;
  }

  /* ========================================
     HOW TO READ
     ======================================== */
  .how-to-read-table {
    width: 100%;
    border-collapse: collapse;
    margin: 24px 0;
  }

  .how-to-read-table th {
    text-align: left;
    font-size: 0.7rem;
    font-weight: 600;
    color: #555;
    text-transform: uppercase;
    letter-spacing: 0.05em;
    padding: 10px 12px;
    background: #f5f4f0;
    border-bottom: 2px solid #e5e3dc;
  }

  .how-to-read-table td {
    font-size: 0.85rem;
    color: #333;
    padding: 10px 12px;
    border-bottom: 1px solid #ddd;
  }

  /* ========================================
     EXECUTIVE SUMMARY
     ======================================== */
  .thesis {
    font-size: 1rem;
    font-weight: 600;
    color: #1a1a1a;
    line-height: 1.6;
    margin-bottom: 24px;
  }

  .evidence-list {
    margin-left: 20px;
    margin-bottom: 24px;
  }

  .evidence-list li {
    font-size: 0.9rem;
    color: #333;
    line-height: 1.6;
    margin-bottom: 8px;
  }

  .keywords {
    font-size: 0.8rem;
    color: #666;
    font-style: italic;
    margin-top: 32px;
    padding-top: 16px;
    border-top: 1px solid #eee;
  }

  /* ========================================
     SECTION COMPONENTS
     ======================================== */
  .confidence-badge {
    font-size: 0.75rem;
    font-weight: 500;
    color: #1a1a1a;
    background: #f5f4f0;
    padding: 3px 8px;
    border-radius: 10px;
    margin-left: 8px;
    vertical-align: middle;
  }

  .confidence-line {
    font-size: 0.8rem;
    color: #888;
    font-style: italic;
    display: block;
    margin-bottom: 16px;
  }

  .key-insight {
    font-weight: 600;
    color: #1a1a1a;
  }

  /* ========================================
     CALLOUTS
     ======================================== */
  .callout {
    background: #f5f4f0;
    padding: 16px 20px;
    border-radius: 4px;
    margin: 1.5rem 0;
    page-break-inside: avoid;
  }

  .callout-label {
    font-size: 0.7rem;
    font-weight: 600;
    text-transform: uppercase;
    letter-spacing: 0.08em;
    margin-bottom: 8px;
  }

  .callout-body {
    font-size: 0.9rem;
    color: #555;
    line-height: 1.6;
  }

  .callout.claim .callout-label {
    color: #555;
  }

  .callout.invalidation {
    border-left: 3px solid #ddd;
  }

  .callout.invalidation .callout-label {
    color: #888;
  }

  .callout.sowhat {
    border-left: 3px solid #c8aa50;
  }

  .callout.sowhat .callout-label {
    color: #c8aa50;
  }

  /* ========================================
     EXHIBITS & TABLES
     ======================================== */
  .exhibit {
    margin: 2rem 0;
  }

  .exhibit-label {
    font-size: 0.75rem;
    font-weight: 600;
    color: #555;
    margin-bottom: 12px;
  }

  .exhibit-table {
    width: 100%;
    border-collapse: collapse;
    page-break-inside: avoid;
  }

  .exhibit-table th {
    text-align: left;
    font-size: 0.7rem;
    font-weight: 600;
    color: #555;
    text-transform: uppercase;
    letter-spacing: 0.05em;
    padding: 10px 12px;
    background: #f5f4f0;
    border-bottom: 2px solid #e5e3dc;
  }

  .exhibit-table td {
    font-size: 0.85rem;
    color: #333;
    padding: 10px 12px;
    border-bottom: 1px solid #ddd;
  }

  .exhibit-source {
    font-size: 0.7rem;
    color: #888;
    font-style: italic;
    margin-top: 8px;
  }

  /* ========================================
     KPI FIGURES
     ======================================== */
  .kpi-grid {
    display: grid;
    grid-template-columns: repeat(auto-fit, minmax(250px, 1fr));
    gap: 48px;
    margin: 2rem 0;
  }

  .kpi {
    text-align: left;
  }

  .kpi-number {
    font-size: 2rem;
    font-weight: 600;
    color: #1a1a1a;
    line-height: 1.2;
  }

  .kpi-number.gold {
    color: #c8aa50;
  }

  .kpi-label {
    font-size: 0.75rem;
    color: #666;
    margin-top: 4px;
  }

  .kpi-source {
    font-size: 0.65rem;
    color: #888;
    margin-top: 2px;
  }

  /* ========================================
     LISTS
     ======================================== */
  ul {
    margin-left: 20px;
    margin-bottom: 1rem;
  }

  ol {
    margin-left: 20px;
    margin-bottom: 1rem;
  }

  li {
    margin-bottom: 4px;
  }

  /* ========================================
     INLINE SOURCE
     ======================================== */
  .source-line {
    font-size: 0.8rem;
    color: #888;
    font-style: italic;
    line-height: 1.5;
    border-top: 1px solid #eee;
    padding-top: 8px;
    margin-top: 8px;
  }

  /* ========================================
     TRANSPARENCY NOTE
     ======================================== */
  .transparency-intro {
    font-size: 0.85rem;
    color: #555;
    line-height: 1.6;
    margin-bottom: 12px;
  }

  .transparency-table {
    width: 100%;
    border-collapse: collapse;
    margin-top: 12px;
  }

  .transparency-table td:first-child {
    font-size: 0.85rem;
    font-weight: 600;
    color: #555;
    padding: 8px 0;
    border-bottom: 1px solid #eee;
    width: 160px;
    vertical-align: top;
  }

  .transparency-table td:last-child {
    font-size: 0.85rem;
    color: #333;
    padding: 8px 0;
    border-bottom: 1px solid #eee;
  }

  /* ========================================
     REFERENCES
     ======================================== */
  .reference-entry {
    font-size: 0.8rem;
    color: #555;
    line-height: 1.5;
    margin-bottom: 6px;
    padding-left: 24px;
    text-indent: -24px;
  }

  /* ========================================
     AUTHOR BIO
     ======================================== */
  .author-section {
    margin-top: 3rem;
    padding-top: 2rem;
    border-top: 1px solid #e5e3dc;
  }

  .author-label {
    font-size: 0.85rem;
    font-weight: 600;
    color: #555;
    margin-bottom: 16px;
  }

  .author-content {
    display: flex;
    gap: 16px;
    align-items: flex-start;
  }

  .author-initials {
    width: 48px;
    height: 48px;
    background: #e5e3dc;
    border-radius: 50%;
    display: flex;
    align-items: center;
    justify-content: center;
    font-size: 1rem;
    font-weight: 600;
    color: #1a1a1a;
    flex-shrink: 0;
  }

  .author-bio-text {
    flex: 1;
  }

  .author-name {
    font-size: 0.9rem;
    font-weight: 600;
    color: #1a1a1a;
    margin-bottom: 8px;
  }

  .author-bio {
    font-size: 0.85rem;
    color: #555;
    line-height: 1.6;
    margin-bottom: 8px;
  }

  .author-link {
    font-size: 0.8rem;
    color: #888;
    text-decoration: none;
  }

  .author-link:hover {
    color: #c8aa50;
  }

  /* ========================================
     BACK COVER
     ======================================== */
  .back-cover-brand {
    display: flex;
    align-items: center;
    gap: 8px;
    justify-content: center;
    margin-bottom: 32px;
  }

  .back-cover-services {
    font-size: 0.85rem;
    color: #666;
    margin-bottom: 24px;
  }

  .back-cover-cta {
    font-size: 0.85rem;
    color: #888;
    margin-bottom: 32px;
  }

  .back-cover-cta a {
    color: #888;
    text-decoration: none;
    margin: 0 4px;
  }

  .back-cover-cta a:hover {
    color: #1a1a1a;
  }

  .back-cover-contact {
    font-size: 0.8rem;
    color: #888;
    margin-bottom: 16px;
  }

  .back-cover-copyright {
    font-size: 0.75rem;
    color: #aaa;
  }

  /* ========================================
     PRINT STYLES
     ======================================== */
  @media print {
    @page {
      size: A4;
      margin: 2cm;
    }

    body {
      background: white;
    }

    .page, .cover, .back-cover {
      page-break-after: always;
    }

    .callout, .exhibit {
      page-break-inside: avoid;
    }

    @page :first {
      @top-center { content: none; }
      @bottom-center { content: none; }
    }

    @page {
      @top-center {
        content: "Ainary Report | Build vs Buy vs Compose";
        font-size: 0.7rem;
        color: #888;
      }
      @bottom-left {
        content: "© 2026 Ainary Ventures";
        font-size: 0.7rem;
        color: #888;
      }
      @bottom-right {
        content: counter(page);
        font-size: 0.7rem;
        color: #888;
      }
    }
  }
</style>
</head>
<body>

<!-- ========================================
     COVER PAGE
     ======================================== -->
<div class="cover">
  <div class="cover-header">
    <div class="cover-brand">
      <span class="gold-punkt">●</span>
      <span class="brand-name">Ainary</span>
    </div>
    <div class="cover-meta">
      <span>AR-017</span>
      <span>Confidence: 78%</span>
    </div>
  </div>

  <div class="cover-title-block">
    <h1 class="cover-title">Build vs Buy vs Compose</h1>
    <p class="cover-subtitle">The AI Agent Stack Decision Framework</p>
  </div>

  <div class="cover-footer">
    <div class="cover-date">
      February 2026<br>
      <span style="font-size: 0.7rem; color: #aaa;">v1.0</span>
    </div>
    <div class="cover-author">
      Florian Ziesche · Ainary Ventures
    </div>
  </div>
</div>

<!-- ========================================
     TABLE OF CONTENTS
     ======================================== -->
<div class="page">
  <p class="toc-label">Contents</p>

  <div class="toc-section">
    <p class="toc-section-label">FOUNDATION</p>
    <a href="#how-to-read" class="toc-entry">
      <span class="toc-number">1</span>
      <span class="toc-title">How to Read This Report</span>
      <span class="toc-page">3</span>
    </a>
    <a href="#exec-summary" class="toc-entry">
      <span class="toc-number">2</span>
      <span class="toc-title">Executive Summary</span>
      <span class="toc-page">4</span>
    </a>
    <a href="#methodology" class="toc-entry">
      <span class="toc-number">3</span>
      <span class="toc-title">Methodology</span>
      <span class="toc-page">5</span>
    </a>
  </div>

  <div class="toc-section">
    <p class="toc-section-label">ANALYSIS</p>
    <a href="#landscape" class="toc-entry">
      <span class="toc-number">4</span>
      <span class="toc-title">The Framework Landscape</span>
      <span class="toc-page">6</span>
    </a>
    <a href="#three-layers" class="toc-entry">
      <span class="toc-number">5</span>
      <span class="toc-title">The Three-Layer Agent Stack</span>
      <span class="toc-page">8</span>
    </a>
    <a href="#decision-framework" class="toc-entry">
      <span class="toc-number">6</span>
      <span class="toc-title">Build vs Buy vs Compose Decision Framework</span>
      <span class="toc-page">10</span>
    </a>
    <a href="#vendor-lockin" class="toc-entry">
      <span class="toc-number">7</span>
      <span class="toc-title">The Vendor Lock-In Trap</span>
      <span class="toc-page">12</span>
    </a>
    <a href="#compose-pattern" class="toc-entry">
      <span class="toc-number">8</span>
      <span class="toc-title">The Compose Pattern: Best of All Worlds</span>
      <span class="toc-page">14</span>
    </a>
  </div>

  <div class="toc-section">
    <p class="toc-section-label">ACTION</p>
    <a href="#recommendations" class="toc-entry">
      <span class="toc-number">9</span>
      <span class="toc-title">Recommendations</span>
      <span class="toc-page">16</span>
    </a>
    <a href="#transparency" class="toc-entry">
      <span class="toc-number">10</span>
      <span class="toc-title">Transparency Note</span>
      <span class="toc-page">17</span>
    </a>
    <a href="#claim-register" class="toc-entry">
      <span class="toc-number">11</span>
      <span class="toc-title">Claim Register</span>
      <span class="toc-page">18</span>
    </a>
    <a href="#references" class="toc-entry">
      <span class="toc-number">12</span>
      <span class="toc-title">References</span>
      <span class="toc-page">19</span>
    </a>
  </div>
</div>

<!-- ========================================
     HOW TO READ THIS REPORT
     ======================================== -->
<div class="page" id="how-to-read">
  <h2>1. How to Read This Report</h2>

  <p>This report uses a structured confidence rating system to communicate what is known versus what is inferred. Every quantitative claim carries its source and confidence level.</p>

  <table class="how-to-read-table">
    <tr>
      <th>Rating</th>
      <th>Meaning</th>
      <th>Example</th>
    </tr>
    <tr>
      <td>High</td>
      <td>3+ independent sources, peer-reviewed or primary data</td>
      <td>GitHub stars for LangGraph/CrewAI/AutoGen (public data)</td>
    </tr>
    <tr>
      <td>Medium</td>
      <td>1–2 sources, plausible but not independently confirmed</td>
      <td>Framework adoption estimates (practitioner surveys)</td>
    </tr>
    <tr>
      <td>Low</td>
      <td>Single secondary source, methodology unclear</td>
      <td>Vendor-reported metrics without independent validation</td>
    </tr>
  </table>

  <p style="margin-top: 24px;">This report was produced using a <strong>multi-agent research pipeline</strong> with structured cross-referencing against internal research briefs (AR-007, AR-012, AR-013) and external framework documentation. Full methodology details are provided in the Transparency Note (Section 10).</p>
</div>

<!-- ========================================
     EXECUTIVE SUMMARY
     ======================================== -->
<div class="page" id="exec-summary">
  <h2>2. Executive Summary</h2>

  <p class="thesis">The question is not "build or buy" anymore. It is "which layer do you build, which do you buy, and which do you compose?" Most companies get this wrong because they treat agent frameworks as all-or-nothing decisions.</p>

  <ul class="evidence-list">
    <li><strong>Three frameworks dominate:</strong> LangGraph, CrewAI, and AutoGen — each with ~30k GitHub stars and distinct architectural philosophies (graph vs role-based vs conversational)<sup>[1]</sup></li>
    <li><strong>The agent stack has three layers:</strong> Orchestration, Trust Infrastructure, and Application Logic — you can build/buy/compose independently at each layer<sup>[2]</sup></li>
    <li><strong>Trust infrastructure has zero commercial adoption:</strong> No production framework ships with provenance tracking, confidence scoring, or error correction by default<sup>[3]</sup></li>
    <li><strong>Vendor lock-in happens at the orchestration layer:</strong> Switching from LangGraph to CrewAI requires rewriting 60-80% of coordination logic<sup>[4]</sup></li>
    <li><strong>The compose pattern is underutilized:</strong> Use LangGraph for orchestration + custom trust layer + OpenAI for models — mixing frameworks reduces lock-in and leverages best-of-breed<sup>[5]</sup></li>
    <li><strong>Developer experience drives adoption faster than capabilities:</strong> LangChain grew 0→100k GitHub stars in ~12 months despite technical limitations because DX was superior<sup>[6]</sup></li>
  </ul>

  <p class="keywords"><strong>Keywords:</strong> AI Agent Frameworks, Build vs Buy, LangGraph, CrewAI, AutoGen, Vendor Lock-In, Composability, Trust Infrastructure</p>
</div>

<!-- ========================================
     METHODOLOGY (SHORT VERSION)
     ======================================== -->
<div class="page" id="methodology">
  <h2>3. Methodology</h2>

  <p>This report synthesizes three data sources: (1) internal research briefs on orchestration patterns (AR-007), developer adoption (AR-013), and trust as competitive moat (AR-012), (2) framework documentation and GitHub metrics for LangGraph, CrewAI, and AutoGen, and (3) practitioner surveys on agent deployment patterns. Framework comparison data comes from independently verified public metrics (GitHub stars, downloads, documentation analysis).</p>

  <p><strong>Limitations:</strong> Adoption metrics rely on self-reported survey data which may over-report successful deployments. The agent framework market is moving fast — specific version capabilities and pricing may change within 3-6 months. Vendor lock-in analysis is based on code migration estimates, not measured migrations.</p>

  <p style="font-size: 0.85rem; color: #666; margin-top: 16px;">Full methodology details, including confidence calibration and known weaknesses, are provided in the Transparency Note (Section 10).</p>
</div>

<!-- ========================================
     SECTION 4: LANDSCAPE
     ======================================== -->
<div class="page" id="landscape">
  <h2>4. The Framework Landscape
    <span class="confidence-badge">82%</span>
  </h2>
  <span class="confidence-line">(Confidence: High)</span>

  <p><span class="key-insight">Three open-source frameworks have emerged as the market leaders: LangGraph (graph-based), CrewAI (role-based), and AutoGen (conversational). Each embodies a different philosophy of how agents should coordinate.</span></p>

  <h3>The Big Three</h3>

  <div class="exhibit">
    <p class="exhibit-label">Exhibit 1: Framework Comparison — LangGraph vs CrewAI vs AutoGen</p>
    <table class="exhibit-table">
      <tr>
        <th>Framework</th>
        <th>Stars</th>
        <th>Downloads/Month</th>
        <th>Orchestration</th>
        <th>Best For</th>
        <th>Weakness</th>
      </tr>
      <tr>
        <td>LangGraph</td>
        <td>Part of LangChain (~100k total)</td>
        <td>~70M (ecosystem)</td>
        <td>Graph-based (DAG)</td>
        <td>Maximum control, production-ready</td>
        <td>Steep learning curve</td>
      </tr>
      <tr>
        <td>CrewAI</td>
        <td>~30k</td>
        <td>~1M</td>
        <td>Role-based, hierarchical</td>
        <td>Fastest setup, YAML config</td>
        <td>Less customization at scale</td>
      </tr>
      <tr>
        <td>AutoGen</td>
        <td>~30k</td>
        <td>Not disclosed</td>
        <td>Conversational, async</td>
        <td>Research, collaborative reasoning</td>
        <td>Not enterprise-ready</td>
      </tr>
    </table>
    <p class="exhibit-source"><em>Source: GitHub metrics (Feb 2026), Python in Plain English framework comparison, Langfuse analysis</em></p>
  </div>

  <h3>Architectural Philosophies</h3>

  <p><strong>LangGraph:</strong> Agents are nodes in a directed acyclic graph (DAG). You define state transitions explicitly. Maximum flexibility but requires understanding graph theory. Production-grade debugging and state inspection.</p>

  <p><strong>CrewAI:</strong> Agents have roles (Researcher, Writer, Critic) and work in predefined patterns (sequential, hierarchical, parallel). YAML configuration makes setup fast. Best for teams that want "just works" over "maximum control."</p>

  <p><strong>AutoGen:</strong> Agents debate via message passing until consensus or timeout. Research-oriented. Executes LLM-generated code by default — any prompt injection becomes code execution. Not recommended for production without sandboxing.</p>

  <h3>Market Positioning</h3>

  <p>LangGraph dominates <strong>production deployments</strong>. CrewAI dominates <strong>prototyping and SMB use cases</strong>. AutoGen dominates <strong>academic research</strong>. This is not speculation — it is reflected in documentation focus, community patterns, and vendor messaging.</p>

  <p>The LangChain ecosystem (which includes LangGraph) has <strong>70 million downloads per month</strong><sup>[1]</sup>. This is 70× larger than CrewAI's 1 million. The network effects are real: more tutorials, more integrations, more Stack Overflow answers.</p>

  <h3>What Is Missing?</h3>

  <p>All three frameworks focus on <strong>orchestration</strong> — how agents coordinate. None focus on <strong>trust infrastructure</strong> — how you know agents are working correctly. Key gaps:</p>

  <ul>
    <li>No built-in confidence scoring per agent action</li>
    <li>No provenance tracking (which agent made which decision)</li>
    <li>No error correction loops (detect → diagnose → fix)</li>
    <li>No cryptographic logging (audit trails are append-only text files)</li>
  </ul>

  <p>This is documented in AR-012 (Trust as Competitive Moat): trust infrastructure is the <strong>#1 reason 94% of agent projects fail</strong><sup>[7]</sup>. Frameworks solve the easy problem (coordination) and ignore the hard problem (trust).</p>

  <div class="callout invalidation">
    <p class="callout-label">What Would Invalidate This?</p>
    <p class="callout-body">If any major framework shipped trust infrastructure by default (confidence scoring, provenance, error correction), the market dynamics would shift. The framework that solves trust first wins enterprise adoption. None have done this yet.</p>
  </div>

  <div class="callout sowhat">
    <p class="callout-label">So What?</p>
    <p class="callout-body">Choose your orchestration framework based on team skill and use case (LangGraph for control, CrewAI for speed, AutoGen for research). But do not assume the framework solves trust. You will build that layer yourself — which means you should design for composability from day one.</p>
  </div>
</div>

<!-- ========================================
     SECTION 5: THREE LAYERS
     ======================================== -->
<div class="page" id="three-layers">
  <h2>5. The Three-Layer Agent Stack
    <span class="confidence-badge">75%</span>
  </h2>
  <span class="confidence-line">(Confidence: High)</span>

  <p><span class="key-insight">The agent stack has three distinct layers: Orchestration (how agents coordinate), Trust Infrastructure (how you know they work), and Application Logic (what they do). You can build/buy/compose independently at each layer.</span></p>

  <h3>Layer 1: Orchestration</h3>

  <p><strong>What it does:</strong> Coordinates agent interactions — sequential, parallel, hierarchical, or graph-based workflows.</p>

  <p><strong>Build or Buy?</strong> <strong>Buy.</strong> LangGraph, CrewAI, and AutoGen solve this well. Building custom orchestration is a 6-12 month engineering project with no competitive advantage. Unless you have unique coordination requirements that no framework supports, buy here.</p>

  <p><strong>Risk:</strong> Vendor lock-in. Switching orchestration frameworks requires rewriting 60-80% of coordination logic.</p>

  <h3>Layer 2: Trust Infrastructure</h3>

  <p><strong>What it does:</strong> Confidence scoring, provenance tracking, error detection, human-in-the-loop workflows, audit logging.</p>

  <p><strong>Build or Buy?</strong> <strong>Build.</strong> No commercial framework ships this. Observability tools (LangSmith, Langfuse) provide logging and tracing but not trust primitives. You need:</p>

  <ul>
    <li>Confidence scoring per agent output</li>
    <li>Provenance metadata (source, timestamp, agent ID)</li>
    <li>Error correction loops (detect anomalies, trigger review)</li>
    <li>Cryptographic logging (tamper-proof audit trails)</li>
  </ul>

  <p>Our deployment (documented in TRUST-LEDGER) implements this with ~5,000 lines of custom code. This is the <strong>competitive moat</strong> — orchestration is commoditized, trust is not.</p>

  <p><strong>Risk:</strong> Underestimating complexity. Trust infrastructure is 30-50% of total engineering effort for production agents.</p>

  <h3>Layer 3: Application Logic</h3>

  <p><strong>What it does:</strong> Domain-specific behavior — research synthesis, customer support, code review, financial analysis.</p>

  <p><strong>Build or Buy?</strong> <strong>Build.</strong> This is your unique value. No off-the-shelf solution understands your business logic, data models, or quality criteria.</p>

  <p><strong>Risk:</strong> Over-engineering. Keep application logic thin — delegate complexity to orchestration and trust layers when possible.</p>

  <div class="exhibit">
    <p class="exhibit-label">Exhibit 2: The Three-Layer Stack Decision Matrix</p>
    <table class="exhibit-table">
      <tr>
        <th>Layer</th>
        <th>Build</th>
        <th>Buy</th>
        <th>Compose</th>
        <th>Recommendation</th>
      </tr>
      <tr>
        <td>Orchestration</td>
        <td>6-12 months</td>
        <td>LangGraph, CrewAI, AutoGen</td>
        <td>Mix frameworks per use case</td>
        <td><strong>Buy or Compose</strong></td>
      </tr>
      <tr>
        <td>Trust Infrastructure</td>
        <td>3-6 months</td>
        <td>Not available</td>
        <td>Build + observability tools</td>
        <td><strong>Build</strong></td>
      </tr>
      <tr>
        <td>Application Logic</td>
        <td>Ongoing</td>
        <td>Vertical SaaS (if exists)</td>
        <td>Hybrid (buy connectors, build logic)</td>
        <td><strong>Build or Hybrid</strong></td>
      </tr>
    </table>
    <p class="exhibit-source"><em>Source: Author analysis based on AR-007, AR-012, AR-013</em></p>
  </div>

  <h3>Why This Matters</h3>

  <p>Teams that treat agent deployment as a single "build or buy" decision fail because they couple all three layers. Example failure pattern:</p>

  <ol>
    <li>Choose LangGraph for orchestration (good)</li>
    <li>Assume LangGraph includes trust infrastructure (wrong)</li>
    <li>Deploy to production without confidence scoring or error detection</li>
    <li>Agents hallucinate, humans lose trust, project fails</li>
  </ol>

  <p>This is the <strong>#1 reason 94% of agent projects fail</strong> (AR-012<sup>[7]</sup>). Not capabilities — trust.</p>

  <div class="callout invalidation">
    <p class="callout-label">What Would Invalidate This?</p>
    <p class="callout-body">If a framework vendor acquired or built trust infrastructure and bundled it with orchestration, the "build trust" recommendation would change. This has not happened yet but is strategically obvious for LangChain/CrewAI/Microsoft.</p>
  </div>

  <div class="callout sowhat">
    <p class="callout-label">So What?</p>
    <p class="callout-body">Architect your agent system as three independent layers from day one. Use interfaces (not direct framework coupling) so you can swap orchestration without touching trust or application logic. Invest 30-50% of engineering time on trust infrastructure — it is the difference between PoC and production.</p>
  </div>
</div>

<!-- ========================================
     SECTION 6: DECISION FRAMEWORK
     ======================================== -->
<div class="page" id="decision-framework">
  <h2>6. Build vs Buy vs Compose Decision Framework
    <span class="confidence-badge">70%</span>
  </h2>
  <span class="confidence-line">(Confidence: Medium)</span>

  <p><span class="key-insight">The decision is not binary. It is a function of (1) engineering capacity, (2) time to market, (3) differentiation needs, and (4) vendor lock-in tolerance.</span></p>

  <h3>The Decision Tree</h3>

  <p><strong>Question 1: Do you have 6+ months and 3+ senior engineers?</strong></p>

  <ul>
    <li><strong>No → Buy everything possible.</strong> Use CrewAI (fastest setup), observability tools (LangSmith/Langfuse), and focus engineering time on trust primitives only.</li>
    <li><strong>Yes → Continue to Question 2.</strong></li>
  </ul>

  <p><strong>Question 2: Is agent orchestration your competitive advantage?</strong></p>

  <ul>
    <li><strong>No → Buy orchestration.</strong> LangGraph for production, CrewAI for prototyping. Build trust infrastructure, compose application logic.</li>
    <li><strong>Yes → Build custom orchestration.</strong> Only if your coordination requirements are unique (e.g., real-time multi-agent negotiation, safety-critical systems, novel coordination patterns).</li>
  </ul>

  <p><strong>Question 3: Can you tolerate vendor lock-in?</strong></p>

  <ul>
    <li><strong>Yes → Buy single-vendor stack.</strong> LangChain ecosystem (LangGraph + LangSmith + LangServe) is the most integrated.</li>
    <li><strong>No → Compose.</strong> Use framework-agnostic interfaces. Example: Agent2Agent (A2A) protocol for inter-agent communication, OpenTelemetry for observability.</li>
  </ul>

  <h3>Real-World Patterns</h3>

  <div class="exhibit">
    <p class="exhibit-label">Exhibit 3: Build/Buy/Compose Patterns by Company Stage</p>
    <table class="exhibit-table">
      <tr>
        <th>Stage</th>
        <th>Orchestration</th>
        <th>Trust Infrastructure</th>
        <th>Application Logic</th>
        <th>Rationale</th>
      </tr>
      <tr>
        <td>Startup (0-10 eng)</td>
        <td>Buy (CrewAI)</td>
        <td>Build (minimal)</td>
        <td>Build</td>
        <td>Speed over control</td>
      </tr>
      <tr>
        <td>Growth (10-50 eng)</td>
        <td>Buy (LangGraph)</td>
        <td>Build (full)</td>
        <td>Build</td>
        <td>Production-ready orchestration + custom trust</td>
      </tr>
      <tr>
        <td>Enterprise (50+ eng)</td>
        <td>Compose (mix)</td>
        <td>Build (enterprise-grade)</td>
        <td>Build</td>
        <td>Avoid lock-in, internal platform</td>
      </tr>
      <tr>
        <td>Regulated (any size)</td>
        <td>Build or audit-friendly buy</td>
        <td>Build (compliance-first)</td>
        <td>Build</td>
        <td>Auditability and control requirements</td>
      </tr>
    </table>
    <p class="exhibit-source"><em>Source: Author synthesis from AR-012 (Trust Moat), AR-013 (Developer Gap), practitioner patterns</em></p>
  </div>

  <h3>When to Build Custom Orchestration</h3>

  <p>Build only if you answer "yes" to 2+ of these:</p>

  <ol>
    <li>Your coordination requirements are unsupported by all frameworks (e.g., real-time negotiation, probabilistic coordination)</li>
    <li>Agent orchestration is your core IP (e.g., you are building an agent platform)</li>
    <li>You have 6+ months and 3+ senior engineers who understand distributed systems</li>
    <li>Vendor lock-in risk exceeds engineering cost (e.g., you are a framework vendor yourself)</li>
  </ol>

  <p>Our deployment (research agent system): <strong>Buy orchestration</strong> (file-based, hierarchical King→Sub-Agent pattern), <strong>Build trust</strong> (TRUST-LEDGER, confidence scoring, corrections tracking), <strong>Build application logic</strong> (research synthesis, report generation).</p>

  <h3>The Compose Sweet Spot</h3>

  <p>Most teams should <strong>compose</strong>:</p>

  <ul>
    <li><strong>Orchestration:</strong> LangGraph (or CrewAI for simpler use cases)</li>
    <li><strong>Observability:</strong> LangSmith or Langfuse (logging/tracing)</li>
    <li><strong>Trust primitives:</strong> Custom-built (confidence, provenance, error correction)</li>
    <li><strong>Models:</strong> Best-of-breed per task (Sonnet-4 for structured, Opus-4 for novel)</li>
  </ul>

  <p>This maximizes leverage (buy commodity layers) while preserving control (build differentiated layers).</p>

  <div class="callout invalidation">
    <p class="callout-label">What Would Invalidate This?</p>
    <p class="callout-body">If agent orchestration became 10× easier (e.g., no-code orchestration that actually works for complex patterns), the "buy orchestration" recommendation would strengthen further. Alternatively, if orchestration became a true commodity with zero switching cost (via standards like A2A), custom builds would make even less sense.</p>
  </div>

  <div class="callout sowhat">
    <p class="callout-label">So What?</p>
    <p class="callout-body">Use the decision tree explicitly. Do not default to "build everything" (wastes 6-12 months) or "buy everything" (locks you in and misses trust infrastructure). Compose is the pragmatic default for most teams: buy orchestration, build trust, hybrid on application logic.</p>
  </div>
</div>

<!-- ========================================
     SECTION 7: VENDOR LOCK-IN
     ======================================== -->
<div class="page" id="vendor-lockin">
  <h2>7. The Vendor Lock-In Trap
    <span class="confidence-badge">68%</span>
  </h2>
  <span class="confidence-line">(Confidence: Medium)</span>

  <p><span class="key-insight">Vendor lock-in happens at the orchestration layer, not the model layer. Switching from LangGraph to CrewAI requires rewriting 60-80% of coordination logic even though both use the same underlying models.</span></p>

  <h3>Where Lock-In Happens</h3>

  <div class="exhibit">
    <p class="exhibit-label">Exhibit 4: Vendor Lock-In Risk by Layer</p>
    <table class="exhibit-table">
      <tr>
        <th>Layer</th>
        <th>Lock-In Risk</th>
        <th>Switching Cost</th>
        <th>Mitigation</th>
      </tr>
      <tr>
        <td>Model Provider (OpenAI, Anthropic)</td>
        <td>Low</td>
        <td>Prompt rewriting (1-2 weeks)</td>
        <td>Use framework abstractions</td>
      </tr>
      <tr>
        <td>Orchestration (LangGraph, CrewAI)</td>
        <td>High</td>
        <td>60-80% rewrite (2-4 months)</td>
        <td>Interface-based design, A2A protocol</td>
      </tr>
      <tr>
        <td>Observability (LangSmith, Langfuse)</td>
        <td>Medium</td>
        <td>Re-instrumentation (2-4 weeks)</td>
        <td>OpenTelemetry standard</td>
      </tr>
      <tr>
        <td>Vector Database (Pinecone, Weaviate)</td>
        <td>Medium</td>
        <td>Data migration (1-4 weeks)</td>
        <td>Abstraction layer, LangChain VectorStore</td>
      </tr>
      <tr>
        <td>Custom Trust Infrastructure</td>
        <td>None (you own it)</td>
        <td>Zero</td>
        <td>N/A — already portable</td>
      </tr>
    </table>
    <p class="exhibit-source"><em>Source: Author estimates based on code migration complexity analysis</em></p>
  </div>

  <h3>The LangChain Ecosystem Advantage</h3>

  <p>LangChain reduces lock-in risk at the <strong>model</strong> and <strong>vector database</strong> layers via abstraction:</p>

  <ul>
    <li>Switch from OpenAI to Anthropic: change 1 line of code (model provider config)</li>
    <li>Switch from Pinecone to Weaviate: change 1 line of code (VectorStore class)</li>
  </ul>

  <p>But LangChain <strong>increases</strong> lock-in risk at the <strong>orchestration</strong> layer:</p>

  <ul>
    <li>LangGraph state management is unique to LangGraph</li>
    <li>LCEL (LangChain Expression Language) is proprietary syntax</li>
    <li>Switching to CrewAI or AutoGen requires architectural rewrite</li>
  </ul>

  <p>This is intentional. LangChain commoditizes models and databases to lock you into orchestration — the layer with highest switching cost.</p>

  <h3>The A2A Protocol Promise</h3>

  <p>Google's Agent2Agent (A2A) protocol aims to solve orchestration lock-in by standardizing inter-agent communication<sup>[8]</sup>. Agents publish capabilities via "Agent Cards" (JSON), communicate via HTTP/JSON, authenticate via OAuth/OpenID.</p>

  <p><strong>In theory:</strong> Write agents once, coordinate across frameworks (LangGraph agents talk to CrewAI agents).</p>

  <p><strong>In practice:</strong> Adoption is early. A critical analysis from fka.dev questions whether A2A has real traction<sup>[9]</sup>. No major framework has full A2A support yet.</p>

  <p>If A2A succeeds, it reduces orchestration lock-in from "high" to "medium." If it fails, lock-in remains the dominant risk.</p>

  <h3>Developer Experience as Lock-In</h3>

  <p>AR-013 (Developer Trust Gap) documents how <strong>developer experience drives adoption faster than capabilities</strong><sup>[6]</sup>. LangChain grew 0→100k GitHub stars in ~12 months not because it was technically superior but because:</p>

  <ul>
    <li>Documentation was excellent</li>
    <li>Quickstart worked in <5 minutes</li>
    <li>Abstractions hid complexity</li>
    <li>Community support was fast</li>
  </ul>

  <p>This creates <strong>psychological lock-in</strong> — switching frameworks means re-learning, slower development, and loss of community support. The cost is not just code rewrite — it is productivity loss during transition.</p>

  <div class="callout claim">
    <p class="callout-label">Claim</p>
    <p class="callout-body">Developer experience creates lock-in as powerful as technical lock-in. Teams stay with inferior frameworks because the switching cost (re-learning + productivity loss) exceeds the technical benefit.</p>
  </div>

  <div class="callout invalidation">
    <p class="callout-label">What Would Invalidate This?</p>
    <p class="callout-body">If A2A protocol achieved universal adoption and frameworks implemented full interoperability, orchestration lock-in would drop significantly. Alternatively, if a new framework emerged with 10× better DX, teams would tolerate switching costs to migrate. Neither has happened yet.</p>
  </div>

  <div class="callout sowhat">
    <p class="callout-label">So What?</p>
    <p class="callout-body">Accept orchestration lock-in as inevitable — but design to minimize it. Use interface-based patterns, avoid framework-specific syntax in business logic, and keep orchestration code isolated. Invest in trust infrastructure that is framework-agnostic — it is your portable moat.</p>
  </div>
</div>

<!-- ========================================
     SECTION 8: COMPOSE PATTERN
     ======================================== -->
<div class="page" id="compose-pattern">
  <h2>8. The Compose Pattern: Best of All Worlds
    <span class="confidence-badge">72%</span>
  </h2>
  <span class="confidence-line">(Confidence: Medium)</span>

  <p><span class="key-insight">The compose pattern — mixing frameworks and custom code at different layers — is underutilized. Most teams go all-in on one framework. Composing gives you best-of-breed at each layer with lower lock-in risk.</span></p>

  <h3>What Composing Looks Like</h3>

  <p><strong>Example 1: Enterprise Production Stack</strong></p>

  <ul>
    <li><strong>Orchestration:</strong> LangGraph (maximum control, production-ready debugging)</li>
    <li><strong>Observability:</strong> Langfuse (open-source, self-hosted)</li>
    <li><strong>Trust Infrastructure:</strong> Custom-built (confidence scoring, provenance, error correction)</li>
    <li><strong>Models:</strong> Anthropic Claude for reasoning, OpenAI for vision, Cohere for embeddings</li>
    <li><strong>Vector DB:</strong> Weaviate (self-hosted, GDPR-compliant)</li>
  </ul>

  <p>Lock-in: Medium (LangGraph orchestration) but trust infrastructure is portable.</p>

  <p><strong>Example 2: Startup Prototyping Stack</strong></p>

  <ul>
    <li><strong>Orchestration:</strong> CrewAI (fast setup, YAML config)</li>
    <li><strong>Observability:</strong> LangSmith (managed, zero-setup)</li>
    <li><strong>Trust Infrastructure:</strong> Minimal (manual review + basic logging)</li>
    <li><strong>Models:</strong> Sonnet-4 (best cost/performance ratio)</li>
    <li><strong>Vector DB:</strong> Pinecone (managed, fast time-to-value)</li>
  </ul>

  <p>Lock-in: Low (everything is swappable except CrewAI orchestration). Optimized for speed.</p>

  <p><strong>Example 3: Our Research Agent Stack</strong></p>

  <ul>
    <li><strong>Orchestration:</strong> File-based, hierarchical (custom-built, simple)</li>
    <li><strong>Observability:</strong> File-based logging + TRUST-LEDGER (cryptographic chain)</li>
    <li><strong>Trust Infrastructure:</strong> Custom (confidence scoring, corrections tracking, QA pipeline)</li>
    <li><strong>Models:</strong> Sonnet-4 default, Opus-4 for complex reasoning</li>
    <li><strong>Vector DB:</strong> None (file-based knowledge retrieval)</li>
  </ul>

  <p>Lock-in: Zero (we own everything). Optimized for trust and transparency.</p>

  <h3>When to Compose</h3>

  <p>Compose when:</p>

  <ol>
    <li><strong>No single framework meets all needs.</strong> Example: LangGraph has best orchestration but worst observability → use LangGraph + Langfuse.</li>
    <li><strong>You need vendor diversity for compliance.</strong> Regulated industries cannot depend on single vendor for critical infrastructure.</li>
    <li><strong>You want best-of-breed per layer.</strong> Best orchestration (LangGraph) + best embeddings (Cohere) + best vision (OpenAI GPT-4V).</li>
    <li><strong>Lock-in risk exceeds integration cost.</strong> Composing adds complexity but reduces switching cost long-term.</li>
  </ol>

  <h3>Integration Tax</h3>

  <p>Composing is not free. Costs:</p>

  <ul>
    <li><strong>Integration complexity:</strong> Each interface between frameworks is a potential failure point</li>
    <li><strong>Version management:</strong> Framework A updates, breaks integration with Framework B</li>
    <li><strong>Support fragmentation:</strong> When something breaks, who do you ask? LangGraph blames Langfuse, Langfuse blames LangGraph</li>
    <li><strong>Learning curve:</strong> Team must master multiple frameworks instead of one</li>
  </ul>

  <p>Estimated integration tax: <strong>20-30% additional engineering time</strong> vs. single-framework stack. This is acceptable if lock-in risk justifies the cost.</p>

  <h3>The Best-of-Breed Approach</h3>

  <div class="exhibit">
    <p class="exhibit-label">Exhibit 5: Best-of-Breed Component Selection</p>
    <table class="exhibit-table">
      <tr>
        <th>Layer</th>
        <th>Best-of-Breed</th>
        <th>Why</th>
        <th>Alternative</th>
      </tr>
      <tr>
        <td>Orchestration (Production)</td>
        <td>LangGraph</td>
        <td>Best debugging, state management, production-ready</td>
        <td>CrewAI (simpler), AutoGen (research)</td>
      </tr>
      <tr>
        <td>Orchestration (Prototyping)</td>
        <td>CrewAI</td>
        <td>Fastest setup, YAML config, lowest learning curve</td>
        <td>LangGraph (overkill for PoC)</td>
      </tr>
      <tr>
        <td>Observability (Managed)</td>
        <td>LangSmith</td>
        <td>Deepest LangChain integration, zero-setup</td>
        <td>Langfuse (self-hosted)</td>
      </tr>
      <tr>
        <td>Observability (Self-Hosted)</td>
        <td>Langfuse</td>
        <td>Open-source, GDPR-compliant, extensible</td>
        <td>LangSmith (vendor lock-in)</td>
      </tr>
      <tr>
        <td>Trust Infrastructure</td>
        <td>Custom-built</td>
        <td>No commercial solution exists</td>
        <td>None</td>
      </tr>
      <tr>
        <td>Models (Reasoning)</td>
        <td>Claude Sonnet-4</td>
        <td>Best cost/performance for structured tasks</td>
        <td>Opus-4 (complex), GPT-4 (vendor diversity)</td>
      </tr>
      <tr>
        <td>Models (Vision)</td>
        <td>GPT-4V</td>
        <td>Best vision capabilities as of Feb 2026</td>
        <td>Claude 3.5 Sonnet (comparable)</td>
      </tr>
      <tr>
        <td>Embeddings</td>
        <td>Cohere Embed v3</td>
        <td>Best multilingual, compression-friendly</td>
        <td>OpenAI text-embedding-3 (simpler)</td>
      </tr>
    </table>
    <p class="exhibit-source"><em>Source: Author analysis based on Feb 2026 capabilities and pricing</em></p>
  </div>

  <div class="callout invalidation">
    <p class="callout-label">What Would Invalidate This?</p>
    <p class="callout-body">If a single framework achieved best-in-class across all layers (orchestration + observability + trust + models), the compose pattern would become unnecessary. This has not happened and is strategically unlikely — no vendor wants to commoditize their differentiation.</p>
  </div>

  <div class="callout sowhat">
    <p class="callout-label">So What?</p>
    <p class="callout-body">Do not treat frameworks as all-or-nothing. Compose strategically: use LangGraph for orchestration, Langfuse for observability, custom code for trust, and best-of-breed models per task. Accept 20-30% integration tax in exchange for lower lock-in and better capabilities.</p>
  </div>
</div>

<!-- ========================================
     SECTION 9: RECOMMENDATIONS
     ======================================== -->
<div class="page" id="recommendations">
  <h2>9. Recommendations</h2>

  <p><span class="key-insight">The build/buy/compose decision is not one-time. It evolves as your team grows, use case matures, and market changes. Start simple, compose strategically, build only what differentiates.</span></p>

  <p style="font-size: 0.85rem; color: #666; margin-bottom: 24px;"><strong>Scope:</strong> These recommendations apply to teams deploying production AI agents. Prototyping and research use cases have different trade-offs.</p>

  <h3>By Company Stage</h3>

  <p><strong>Startup (0-10 engineers):</strong></p>

  <ol>
    <li>Buy orchestration (CrewAI for speed)</li>
    <li>Buy observability (LangSmith for zero-setup)</li>
    <li>Build minimal trust infrastructure (logging + manual review)</li>
    <li>Use single model provider (Anthropic Sonnet-4 for cost/performance)</li>
    <li>Defer vector databases until you have >10k documents</li>
  </ol>

  <p><strong>Growth (10-50 engineers):</strong></p>

  <ol>
    <li>Migrate to production orchestration (LangGraph)</li>
    <li>Build full trust infrastructure (confidence scoring, provenance, error correction)</li>
    <li>Compose observability (Langfuse self-hosted + custom metrics)</li>
    <li>Add model routing (Sonnet-4 default, Opus-4 for complex tasks)</li>
    <li>Isolate orchestration from business logic via interfaces</li>
  </ol>

  <p><strong>Enterprise (50+ engineers):</strong></p>

  <ol>
    <li>Compose orchestration (mix LangGraph and custom patterns)</li>
    <li>Build enterprise-grade trust infrastructure (compliance-ready, auditable)</li>
    <li>Use OpenTelemetry for observability (vendor-agnostic)</li>
    <li>Implement A2A protocol for inter-agent communication (future-proof)</li>
    <li>Build internal agent platform team (orchestration as internal service)</li>
  </ol>

  <h3>Decision Checklist</h3>

  <p>Before choosing a framework, answer these:</p>

  <ul>
    <li>Do you have 6+ months and 3+ senior engineers? (If no → buy everything)</li>
    <li>Is orchestration your competitive advantage? (If no → buy orchestration)</li>
    <li>Can you tolerate vendor lock-in? (If yes → LangChain ecosystem; if no → compose)</li>
    <li>Do you have compliance requirements? (If yes → build trust infrastructure first)</li>
    <li>Is this production or prototype? (Prototype → CrewAI; Production → LangGraph)</li>
  </ul>

  <h3>The Trust-First Architecture</h3>

  <p>Regardless of build/buy/compose decisions, <strong>design for trust from day one</strong>:</p>

  <ol>
    <li>Every agent action gets a confidence score</li>
    <li>Every output includes provenance (which agent, when, based on what)</li>
    <li>Error detection runs continuously (confidence drift, anomaly patterns)</li>
    <li>Human-in-the-loop is scoped and sustainable (<10 escalations/day)</li>
    <li>Audit logs are cryptographically verifiable (TRUST-LEDGER pattern)</li>
  </ol>

  <p>This is the architecture that enables the other 6% to succeed (AR-012<sup>[7]</sup>).</p>
</div>

<!-- ========================================
     SECTION 10: TRANSPARENCY NOTE
     ======================================== -->
<div class="page" id="transparency">
  <h2>10. Transparency Note</h2>

  <p class="transparency-intro">This section documents the methodology, confidence calibration, and known limitations of this report. It is provided to enable independent validation and replication.</p>

  <table class="transparency-table">
    <tr>
      <td>Overall Confidence</td>
      <td>78% — High confidence in framework comparison data (public metrics), medium confidence in adoption patterns (survey-based), low confidence on lock-in cost estimates (not empirically measured)</td>
    </tr>
    <tr>
      <td>Sources</td>
      <td>Primary: GitHub metrics (stars, downloads), framework documentation<br>
      Secondary: AR-007 (Orchestration), AR-012 (Trust Moat), AR-013 (Developer Gap), multi-agent framework research brief<br>
      Tertiary: Practitioner surveys on framework adoption (Langfuse, Python in Plain English)</td>
    </tr>
    <tr>
      <td>Strongest Evidence</td>
      <td>Framework comparison (Exhibit 1) — based on independently verifiable GitHub metrics and documentation analysis</td>
    </tr>
    <tr>
      <td>Weakest Point</td>
      <td>Vendor lock-in switching cost estimates (60-80% rewrite for orchestration) are author estimates based on code complexity analysis, not measured migrations. Real switching costs could be higher or lower.</td>
    </tr>
    <tr>
      <td>What Would Invalidate</td>
      <td>If A2A protocol achieved universal adoption and zero-cost framework switching, the entire lock-in thesis collapses. If a framework vendor shipped production-grade trust infrastructure, the "build trust" recommendation changes.</td>
    </tr>
    <tr>
      <td>Methodology</td>
      <td>Three-tier synthesis: (1) Public data (GitHub, docs) for framework comparison, (2) Internal research (AR-007/012/013) for architectural patterns, (3) Decision framework derived from first principles and validated against practitioner patterns. All quantitative claims cite sources or are labeled as estimates.</td>
    </tr>
    <tr>
      <td>System Disclosure</td>
      <td>This report was created with a multi-agent research system using Claude Sonnet-4. The system synthesized three internal research reports plus external framework analysis. Human review (Florian Ziesche) validated framework comparison and architectural claims.</td>
    </tr>
  </table>
</div>

<!-- ========================================
     SECTION 11: CLAIM REGISTER
     ======================================== -->
<div class="page" id="claim-register">
  <h2>11. Claim Register</h2>

  <p style="font-size: 0.85rem; color: #666; margin-bottom: 24px;">This register documents all quantitative and high-impact claims in this report with source attribution and confidence scoring.</p>

  <div class="exhibit">
    <table class="exhibit-table">
      <tr>
        <th>#</th>
        <th>Claim</th>
        <th>Value</th>
        <th>Source</th>
        <th>Confidence</th>
        <th>Used In</th>
      </tr>
      <tr>
        <td>1</td>
        <td>LangChain ecosystem downloads per month</td>
        <td>70M</td>
        <td>Python in Plain English (Feb 2026)</td>
        <td>High (public)</td>
        <td>Sec 2, 4</td>
      </tr>
      <tr>
        <td>2</td>
        <td>CrewAI GitHub stars</td>
        <td>~30k</td>
        <td>GitHub (Feb 2026)</td>
        <td>High (public)</td>
        <td>Sec 2, 4</td>
      </tr>
      <tr>
        <td>3</td>
        <td>AutoGen GitHub stars</td>
        <td>~30k</td>
        <td>GitHub (Feb 2026)</td>
        <td>High (public)</td>
        <td>Sec 2, 4</td>
      </tr>
      <tr>
        <td>4</td>
        <td>Trust infrastructure commercial availability</td>
        <td>Zero frameworks ship it</td>
        <td>Framework docs analysis</td>
        <td>High (verified)</td>
        <td>Sec 2, 4, 5</td>
      </tr>
      <tr>
        <td>5</td>
        <td>Orchestration switching cost (code rewrite)</td>
        <td>60-80%</td>
        <td>Author estimate</td>
        <td>Low (estimated)</td>
        <td>Sec 2, 7</td>
      </tr>
      <tr>
        <td>6</td>
        <td>LangChain growth rate</td>
        <td>0→100k stars in ~12 months</td>
        <td>AR-013, GitHub history</td>
        <td>Medium (approximated)</td>
        <td>Sec 2, 7</td>
      </tr>
      <tr>
        <td>7</td>
        <td>Agent project failure rate</td>
        <td>94%</td>
        <td>AR-012 synthesis</td>
        <td>Medium (derived)</td>
        <td>Sec 2, 4, 5, 9</td>
      </tr>
      <tr>
        <td>8</td>
        <td>A2A protocol status</td>
        <td>Google → Linux Foundation (June 2025)</td>
        <td>Linux Foundation press release</td>
        <td>High (official)</td>
        <td>Sec 7</td>
      </tr>
      <tr>
        <td>9</td>
        <td>Trust infrastructure engineering effort</td>
        <td>30-50% of total</td>
        <td>Author analysis (our deployment)</td>
        <td>Medium (measured)</td>
        <td>Sec 5</td>
      </tr>
      <tr>
        <td>10</td>
        <td>Integration tax for composing</td>
        <td>20-30% additional time</td>
        <td>Author estimate</td>
        <td>Low (estimated)</td>
        <td>Sec 8</td>
      </tr>
    </table>
  </div>

  <p style="margin-top: 24px; font-size: 0.85rem; color: #666;"><strong>Top 5 Claims — Invalidation Conditions:</strong></p>

  <ol style="margin-left: 20px; font-size: 0.85rem; color: #666;">
    <li><strong>70M LangChain downloads:</strong> Invalidated if methodology changes (e.g., bot traffic excluded) or if ecosystem fragments.</li>
    <li><strong>Zero trust infrastructure frameworks:</strong> Invalidated if LangChain, CrewAI, or a new entrant ships confidence scoring + provenance by default.</li>
    <li><strong>60-80% orchestration rewrite cost:</strong> Invalidated by measured migrations showing higher or lower costs, or by A2A protocol achieving zero-cost switching.</li>
    <li><strong>94% failure rate:</strong> Invalidated if trust infrastructure becomes commoditized and failure rate drops below 50%.</li>
    <li><strong>20-30% integration tax:</strong> Invalidated if frameworks converge on standards (A2A, OpenTelemetry) reducing integration complexity by 10×.</li>
  </ol>
</div>

<!-- ========================================
     SECTION 12: REFERENCES
     ======================================== -->
<div class="page" id="references">
  <h2>12. References</h2>

  <p class="reference-entry">[1] Python in Plain English (2026). "Autogen vs CrewAI vs LangGraph 2026 Comparison Guide." https://python.plainenglish.io/autogen-vs-crewai-vs-langgraph-2026-comparison-guide-fd8490397977 (accessed Feb 15, 2026).</p>

  <p class="reference-entry">[2] Author analysis based on framework documentation and architectural patterns (2026).</p>

  <p class="reference-entry">[3] Framework documentation analysis: LangGraph, CrewAI, AutoGen — none implement provenance tracking or confidence scoring (Feb 2026).</p>

  <p class="reference-entry">[4] Author estimate based on code complexity analysis (2026).</p>

  <p class="reference-entry">[5] Author architectural recommendation based on AR-007, AR-012, AR-013 synthesis (2026).</p>

  <p class="reference-entry">[6] Ainary Research (2026). The Developer Trust Gap: Why Trust Tools Have Zero Adoption. AR-013.</p>

  <p class="reference-entry">[7] Ainary Research (2026). Trust as Competitive Moat: Why 94% of Agent Projects Fail. AR-012.</p>

  <p class="reference-entry">[8] Google Developers Blog (2025). "A2A: A New Era of Agent Interoperability." https://developers.googleblog.com/en/a2a-a-new-era-of-agent-interoperability/ (accessed Feb 15, 2026).</p>

  <p class="reference-entry">[9] fka.dev (2025). "What Happened to Google's A2A?" https://blog.fka.dev/blog/2025-09-11-what-happened-to-googles-a2a/ (accessed Feb 15, 2026).</p>

  <p style="margin-top: 32px; padding-top: 16px; border-top: 1px solid #e5e3dc; font-size: 0.8rem; color: #888;">
    <strong>Cite this report:</strong> Ainary Research (2026). Build vs Buy vs Compose — The AI Agent Stack Decision Framework. AR-017.
  </p>

  <!-- Author Bio -->
  <div class="author-section">
    <p class="author-label">About the Author</p>
    <div class="author-content">
      <div class="author-initials">FZ</div>
      <div class="author-bio-text">
        <p class="author-name">Florian Ziesche</p>
        <p class="author-bio">Florian Ziesche is the founder of Ainary Ventures, where AI does 80% of the research and humans do the 20% that matters. Before Ainary, he was CEO of 36ZERO Vision and advised startups and SMEs on AI strategy and due diligence. His conviction: HUMAN × AI = LEVERAGE. This report is the proof.</p>
        <a href="https://ainaryventures.com" class="author-link">ainaryventures.com</a>
      </div>
    </div>
  </div>
</div>

<!-- ========================================
     BACK COVER
     ======================================== -->
<div class="back-cover">
  <div class="back-cover-brand">
    <span class="gold-punkt" style="font-size: 18px;">●</span>
    <span class="brand-name" style="font-size: 1.2rem;">Ainary</span>
  </div>

  <p class="back-cover-services">AI Strategy · Published Research · Daily Intelligence</p>

  <p class="back-cover-cta">
    <a href="mailto:florian@ainaryventures.com">Contact</a> ·
    <a href="mailto:florian@ainaryventures.com?subject=Feedback: AR-017">Feedback</a>
  </p>

  <p class="back-cover-contact">
    ainaryventures.com<br>
    florian@ainaryventures.com
  </p>

  <p class="back-cover-copyright">© 2026 Ainary Ventures</p>
</div>

</body>
</html>
