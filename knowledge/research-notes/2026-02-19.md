---
tier: OPERATIONAL
expires: 2026-08-20
---
# SOTA Paper Research ‚Äî 19.02.2026

## Scan Summary
- **Quellen:** arxiv.org, GitHub (Awesome-Agent-Papers, VoltAgent/2026), HuggingFace Papers
- **Fokus:** Agentic [[AI]] Architectures, Multi-Agent, Memory, Planning, RAG, Governance
- **Neue Papers seit letztem Scan:** ~60+ papers (Jan-Feb 2026)
- **Top-Themen:** Memory Systems, Multi-Agent Coordination, Production Governance, Reasoning + RL

---

## üî• TOP PAPERS (Highest Relevance f√ºr Florian)

### 1. Memory-R1: Enhancing LLM Agents via Reinforcement Learning
**Link:** https://arxiv.org/abs/2508.19828  
**Autoren:** Sikuan Yan et al. (13 authors, TU Munich, Univ. of Edinburgh, Siemens)  
**Datum:** Aug 2025, updated Jan 2026  
**Status:** Accepted (venue TBD)

**3-Satz Summary:**
- LLMs sind stateless und limitiert durch Context Windows ‚Üí externes Memory n√∂tig, aber bisherige Ans√§tze sind statisch/heuristisch.
- **Memory-R1** nutzt RL (PPO + GRPO) um zwei Agents zu trainieren: Memory Manager (ADD/UPDATE/DELETE/NOOP) + Answer Agent (retrieval + reasoning).
- Mit nur 152 Training QA-Pairs outperformt es Baselines √ºber 3 Benchmarks (LoCoMo, MSC, LongMemEval) und generalisiert √ºber Modellgr√∂√üen (3B-14B).

**Relevanz f√ºr uns:** ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê (5/5)
- **Warum:** Direkt anwendbar f√ºr Agentic Memory. RL-based memory management ist state-of-the-art. Demonstriert: wenige Training Samples reichen (152 QA pairs).
- **Anwendbarkeit:** Kann direkt in OpenClaw/Mia integriert werden. Memory Manager als separater Agent. Outcome-driven RL f√ºr adaptive Memory-Ops.
- **Fokusbereich:** Agentic [[AI]] (Memory), RL-Training, Production Readiness

---

### 2. Memory in the Age of [[AI]] Agents (Survey)
**Link:** https://arxiv.org/abs/2512.13564  
**Autoren:** Yuyang Hu et al. (40+ authors, Fudan, Oxford, RUC, AIWaves)  
**Datum:** Dec 2025, updated Jan 2026  
**Status:** Survey

**3-Satz Summary:**
- Umfassende Survey √ºber Agent Memory: unterscheidet Memory von RAG, Context Engineering, [[LLM]] Memory.
- Taxonomie nach **Forms** (token-level, parametric, latent), **Functions** (factual, experiential, working), **Dynamics** (formation, evolution, retrieval).
- Identifiziert Research Frontiers: Memory Automation, RL Integration, Multimodal Memory, Multi-Agent Memory, Trustworthiness.

**Relevanz f√ºr uns:** ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê (5/5)
- **Warum:** Konzeptionelle Foundation f√ºr Agent Memory Design. Klare Taxonomie. Benchmark-√úbersicht.
- **Anwendbarkeit:** Als Referenz f√ºr Memory-Architektur in [[Ainary]]/Mia. Token vs. Parametric vs. Latent Memory Choices dokumentieren.
- **Fokusbereich:** Agentic [[AI]] (Memory), Multi-Agent Memory, Trustworthiness

---

### 3. Reinforce [[LLM]] Reasoning through Multi-Agent Reflection
**Link:** https://arxiv.org/abs/2506.08379  
**Autoren:** Yurun Yuan et al.  
**Datum:** Jun 2025  
**Status:** ICML 2025

**3-Satz Summary:**
- Multi-turn Refinement als MDP modelliert ‚Üí DPSDP (Direct Policy Search by Dynamic Programming) Algorithmus f√ºr Actor-Critic [[LLM]] System.
- Trainiert via Direct Preference Learning auf self-generated data (keine manuellen Labels n√∂tig).
- MATH 500 Benchmark: 58.2% ‚Üí 63.2% Accuracy (5 refinement steps), zeigt Multi-Agent Collaboration Benefits.

**Relevanz f√ºr uns:** ‚≠ê‚≠ê‚≠ê‚≠ê (4/5)
- **Warum:** State-of-the-art f√ºr Multi-Agent Reasoning + RL. Self-generated training data = skalierbar. Accepted at ICML = peer-reviewed quality.
- **Anwendbarkeit:** Verify-and-improve Paradigma f√ºr complex reasoning tasks (z.B. investment thesis analysis). Self-play training f√ºr Agent Improvement.
- **Fokusbereich:** Multi-Agent Coordination, RL-Training, Reasoning

---

## üìä WEITERE RELEVANTE PAPERS

### Agent Architecture & Governance

#### Engineering [[AI]] Agents for Clinical Workflows (Production Architecture)
**Link:** https://arxiv.org/abs/2602.00751  
**Datum:** Feb 2026  
**Summary:** Reference architecture f√ºr production [[AI]] agents: Clean Architecture + Event-driven design + per-agent MLOps + human-in-the-loop governance. Direkt nutzbar f√ºr Enterprise Deployments.  
**Relevanz:** ‚≠ê‚≠ê‚≠ê‚≠ê (4/5) ‚Äî Production Best Practices, MLOps  
**Anwendbar:** Governance Model f√ºr [[Ainary]] Fund Agents

---

#### Agentic [[AI]] Governance and Lifecycle Management in Healthcare
**Link:** https://arxiv.org/abs/2601.15630  
**Datum:** Jan 2026  
**Summary:** Unified Agent Lifecycle Management mit 5 Control-Plane Layers: Identity Registry, Orchestration, Runtime Policy Enforcement. F√ºr Healthcare, aber generalisierbar.  
**Relevanz:** ‚≠ê‚≠ê‚≠ê‚≠ê (4/5) ‚Äî [[AI]] Governance Focus  
**Anwendbar:** Lifecycle Management f√ºr Multi-Agent Systems in [[VC]]/Investment Context

---

#### Agentic Design Patterns: A System-Theoretic Framework
**Link:** https://arxiv.org/abs/2601.19752  
**Datum:** Jan 2026  
**Summary:** Dekomposition von Agentic [[AI]] in 5 Functional Subsystems ‚Üí 12 reusable Design Patterns. System-theoretic approach.  
**Relevanz:** ‚≠ê‚≠ê‚≠ê‚≠ê (4/5) ‚Äî Agent Architecture  
**Anwendbar:** Pattern Catalog f√ºr Agent Design

---

### Multi-Agent Coordination

#### Large Language Model Agent: A Survey (329 Papers)
**Link:** https://arxiv.org/abs/2503.21460  
**Datum:** Mar 2025  
**Summary:** Comprehensive Survey: Agent Construction, Collaboration, Evolution. Methodology-centered taxonomy. 329 papers. GitHub: luo-junyu/Awesome-Agent-Papers.  
**Relevanz:** ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê (5/5) ‚Äî Survey, Multi-Agent  
**Anwendbar:** Als Referenz f√ºr Agent Research, keep updated

---

#### TraceCoder: Trace-Driven Multi-Agent Framework for Automated Debugging
**Link:** https://arxiv.org/abs/2602.06875  
**Datum:** Feb 2026  
**Summary:** Multi-agent observe-analyze-repair loop nutzt runtime traces f√ºr automated debugging in [[LLM]]-generated code.  
**Relevanz:** ‚≠ê‚≠ê‚≠ê (3/5) ‚Äî Multi-Agent, Debugging  
**Anwendbar:** F√ºr Code-generierung in [[Ainary]]/[[VC]] Tools

---

### Memory & Context

#### SemanticALLI: Caching Reasoning, Not Just Responses
**Link:** https://arxiv.org/abs/2601.16286  
**Datum:** Jan 2026  
**Summary:** Pipeline-aware caching architecture ‚Üí cached structured intermediate reasoning (nicht nur final responses). Reduziert redundante [[LLM]] calls.  
**Relevanz:** ‚≠ê‚≠ê‚≠ê‚≠ê (4/5) ‚Äî Efficiency, Memory  
**Anwendbar:** Cost Reduction f√ºr Agentic Systems (OpenClaw)

---

#### AutoRefine: From Trajectories to Reusable Expertise
**Link:** https://arxiv.org/abs/2601.22758  
**Datum:** Jan 2026  
**Summary:** Extrahiert dual-form reusable expertise aus Agent Execution Histories: Specialized Sub-agents (procedural) + Skill Patterns (static knowledge). Continuous pruning/merging.  
**Relevanz:** ‚≠ê‚≠ê‚≠ê‚≠ê (4/5) ‚Äî Continual Learning, Memory  
**Anwendbar:** Learning from Experience f√ºr Mia

---

### Planning & Reasoning

#### ProAct: Agentic Lookahead in Interactive Environments
**Link:** https://arxiv.org/abs/2602.05327  
**Datum:** Feb 2026  
**Summary:** Training agents to think ahead ‚Üí distills environment search into causal reasoning chains.  
**Relevanz:** ‚≠ê‚≠ê‚≠ê (3/5) ‚Äî Planning  
**Anwendbar:** Long-horizon planning in interactive tasks

---

#### Why Reasoning Fails to Plan: Planning-Centric Analysis
**Link:** https://arxiv.org/abs/2601.22311  
**Datum:** Jan 2026  
**Summary:** Analysiert warum step-wise reasoning bei long-horizon planning versagt ‚Üí schl√§gt future-aware lookahead mit reward estimation vor.  
**Relevanz:** ‚≠ê‚≠ê‚≠ê‚≠ê (4/5) ‚Äî Planning, Long-Horizon  
**Anwendbar:** Investment Planning (multi-step due diligence)

---

### Tool Use & Efficiency

#### Optimizing Agentic Workflows using Meta-tools
**Link:** https://arxiv.org/abs/2601.22037  
**Datum:** Jan 2026  
**Summary:** B√ºndelt recurring sequences of tool calls in deterministic meta-tools ‚Üí skippt unn√∂tige intermediate [[LLM]] reasoning steps, cut failures.  
**Relevanz:** ‚≠ê‚≠ê‚≠ê‚≠ê (4/5) ‚Äî Efficiency, Tool Use  
**Anwendbar:** Workflow Optimization f√ºr repetitive Agent Tasks

---

#### Think-Augmented Function Calling
**Link:** https://arxiv.org/abs/2601.18282  
**Datum:** Jan 2026  
**Summary:** Embeds explicit reasoning bei function + parameter level ‚Üí dynamic complexity scoring trigger granular justification f√ºr critical decisions.  
**Relevanz:** ‚≠ê‚≠ê‚≠ê (3/5) ‚Äî Tool Use, Reasoning  
**Anwendbar:** Transparent Tool Calling

---

### Safety & Uncertainty

#### Agentic Uncertainty Quantification
**Link:** https://arxiv.org/abs/2601.15703  
**Datum:** Jan 2026  
**Summary:** Dual-Process Framework: verbalized uncertainty ‚Üí bi-directional control signals f√ºr agent memory + reflection ‚Üí verhindert cascading hallucination errors.  
**Relevanz:** ‚≠ê‚≠ê‚≠ê‚≠ê (4/5) ‚Äî Safety, Trustworthiness  
**Anwendbar:** Critical f√ºr Investment Decision Agents

---

### RL & Training

#### From Self-Evolving Synthetic Data to Verifiable-Reward RL
**Link:** https://arxiv.org/abs/2601.22607  
**Datum:** Jan 2026  
**Summary:** Framework combining self-evolving multi-agent data engine + verifier-based RL f√ºr training multi-turn interactive tool-using agents.  
**Relevanz:** ‚≠ê‚≠ê‚≠ê (3/5) ‚Äî RL, Training  
**Anwendbar:** Training Data Generation

---

#### JitRL: Just-In-Time Reinforcement Learning
**Link:** https://arxiv.org/abs/2601.18510  
**Datum:** Jan 2026  
**Summary:** Training-free continual learning: retrieves past experiences + modulates output logits at test time (ohne gradient updates).  
**Relevanz:** ‚≠ê‚≠ê‚≠ê (3/5) ‚Äî RL, Continual Learning  
**Anwendbar:** Test-time adaptation ohne retraining

---

### Software Engineering & Coding

#### SWE-Replay: Efficient Test-Time Scaling for Software Engineering Agents
**Link:** https://arxiv.org/abs/2601.22129  
**Datum:** Jan 2026  
**Summary:** Test-time scaling method: recycelt prior trajectories + branches at critical intermediate steps (nicht resampling from scratch).  
**Relevanz:** ‚≠ê‚≠ê‚≠ê (3/5) ‚Äî SWE, Efficiency  
**Anwendbar:** Code Generation Agents

---

#### SWE-Pruner: Self-Adaptive Context Pruning for Coding Agents
**Link:** https://arxiv.org/abs/2601.16746  
**Datum:** Jan 2026  
**Summary:** Task-aware context pruning: lightweight neural skimmer ‚Üí selectively retains relevant code lines based on explicit goals.  
**Relevanz:** ‚≠ê‚≠ê‚≠ê (3/5) ‚Äî SWE, Efficiency  
**Anwendbar:** Large Codebase Navigation

---

### Industrial [[AI]] / Domain-Specific

*(Wenige direkte Papers f√ºr Manufacturing [[AI]] in diesem Scan ‚Äî focus war mehr auf general agentic [[AI]])*

#### World Models as Intermediary between Agents and Real World
**Link:** https://arxiv.org/abs/2602.00785  
**Datum:** Feb 2026  
**Summary:** World models als bridge zwischen agents + high-cost real-world environments (robotics, ML engineering).  
**Relevanz:** ‚≠ê‚≠ê‚≠ê (3/5) ‚Äî Robotics, Industrial  
**Anwendbar:** Manufacturing/Robotics Use Cases

---

### RAG & Retrieval

*(Weniger neue breakthrough RAG papers in diesem Scan ‚Äî RAG ist zunehmend embedded in Agent Memory/Tool Use)*

#### Structured Context Engineering for File-Native Agentic Systems
**Link:** https://arxiv.org/abs/2602.05447  
**Datum:** Feb 2026  
**Summary:** Tests wie context format (YAML, JSON, Markdown) agent accuracy beeinflusst (9,649 experiments).  
**Relevanz:** ‚≠ê‚≠ê‚≠ê (3/5) ‚Äî RAG, Context Engineering  
**Anwendbar:** Prompt Engineering for File-based Systems

---

## üìà TRENDS & INSIGHTS

### Haupttrends Feb 2026:
1. **Memory Systems:** Shift von statischem RAG zu RL-based adaptive memory (Memory-R1, AutoRefine, SemanticALLI)
2. **Production Governance:** Mehr Focus auf Lifecycle Management, Policy Enforcement, MLOps f√ºr Agents (nicht nur Prototyping)
3. **Multi-Agent Coordination:** Weniger "mehr agents = besser", mehr "wie orchestrieren wir agents effizient" (Meta-tools, SemanticALLI caching)
4. **Reasoning + RL:** Direct Preference Learning + self-generated data f√ºr reasoning agents (DPSDP, verifiable-reward RL)
5. **Efficiency:** Test-time scaling, context pruning, meta-tools ‚Üí reduce redundant [[LLM]] calls
6. **Safety/UQ:** Mehr Papers √ºber uncertainty quantification + cascading error prevention

### Was fehlt noch:
- **GraphRAG:** Wenig Neues zu GraphRAG (existing methods mature, weniger research novelty?)
- **Industrial [[AI]]:** Kaum neue papers zu Manufacturing/CNC [[AI]] (domain-specific = weniger arxiv presence?)
- **Human-[[AI]] Collab:** Weniger explizit (embedded in governance/safety papers)

---

## üéØ ACTIONABLE TAKEAWAYS F√úR FLORIAN

1. **Memory-R1 paper lesen + implementieren:** RL-based memory management ist state-of-the-art, direkt anwendbar f√ºr Mia.
2. **Memory Survey als Referenz nutzen:** Beim Design von Agent Memory Architectures ‚Üí Token vs. Parametric vs. Latent Memory tradeoffs dokumentieren.
3. **Governance Frameworks studieren:** "Engineering [[AI]] Agents for Clinical Workflows" + "Agentic [[AI]] Governance" ‚Üí apply to [[Ainary]] Fund Agents (Lifecycle Management, Policy Enforcement).
4. **Multi-Agent Efficiency:** Meta-tools + SemanticALLI caching ‚Üí reduce costs in OpenClaw/Mia by bundling recurring workflows.
5. **Uncertainty Quantification:** "Agentic Uncertainty Quantification" paper ‚Üí critical f√ºr investment decision agents (prevent hallucination cascades).

---

## üìö RESOURCES

### Paper Collections:
- **Awesome-Agent-Papers:** https://github.com/luo-junyu/Awesome-Agent-Papers (329 papers, updated weekly)
- **VoltAgent 2026 Collection:** https://github.com/VoltAgent/awesome-ai-agent-papers (2026-only papers)
- **AGI-Edgerunners:** https://github.com/AGI-Edgerunners/LLM-Agents-Papers

### Benchmarks (aus Memory Survey):
- **LoCoMo, MSC, LongMemEval** (Memory)
- **MATH 500** (Reasoning)
- **TravelPlanner** (Planning)

---

**Next Scan:** 2026-02-26 (weekly rhythm)
