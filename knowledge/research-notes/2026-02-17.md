---
tier: OPERATIONAL
expires: 2026-08-20
---
# SOTA [[AI]] Agent Research - 2026-02-17

## Scan Summary
**Quellen:** Awesome-Agent-Papers (GitHub), [[LLM]]-Agents-Papers (GitHub), arXiv direct search, Web search
**Focus:** Agentic [[AI]], Multi-Agent Systems, Memory, Planning, Tool Use
**Relevanz-Filter:** Applied to Florian's expertise areas

---

## üî• Top Papers (Highest Relevance)

### 1. **SkillRL: Evolving Agents via Recursive Skill-Augmented Reinforcement Learning**
- **Link:** https://arxiv.org/abs/2602.08234
- **Datum:** Feb 9, 2026
- **Autoren:** Peng Xia et al. (13 authors)
- **Summary:** Proposes recursive skill augmentation for agent evolution through RL. Agents learn hierarchical skills that compound over time. Novel approach to continuous agent improvement without human intervention.
- **Relevanz:** 5/5 (Agent Evolution + Self-Improvement)
- **Anwendbarkeit:** HOCH - Relevant f√ºr Ainary's agent evolution frameworks und continuous learning systems. Could inform how we build self-improving [[VC]] research agents.

---

### 2. **Rethinking Memory Mechanisms of Foundation Agents in the Second Half: A Survey**
- **Link:** https://arxiv.org/abs/2602.06052
- **Datum:** Feb 6, 2026
- **Autoren:** Wei-Chieh Huang et al. (60 authors)
- **Summary:** Comprehensive survey of memory architectures in foundation agents. Covers working memory, episodic memory, semantic memory trade-offs. Reviews 100+ papers on memory mechanisms.
- **Relevanz:** 5/5 (Memory Architecture)
- **Anwendbarkeit:** SEHR HOCH - Essential reading for understanding state-of-the-art in agent memory. Direct application to building better context-aware agents.

---

### 3. **Agent World Model: Infinity Synthetic Environments for Agentic Reinforcement Learning**
- **Link:** https://arxiv.org/abs/2602.10090
- **Datum:** Feb 10, 2026
- **Autoren:** Zhaoyang Wang et al.
- **Summary:** World model framework that generates infinite synthetic environments for training agentic RL systems. Enables massive parallel training without manual environment design.
- **Relevanz:** 4/5 (Training Infrastructure)
- **Anwendbarkeit:** MITTEL - Mehr Research als direkt anwendbar, aber relevant f√ºr Verst√§ndnis von Agent-Training at Scale.

---

### 4. **AIRS-Bench: A Suite of Tasks for Frontier [[AI]] Research Science Agents**
- **Link:** https://arxiv.org/abs/2602.06855
- **Datum:** Feb 6, 2026
- **Autoren:** Alberto Pepe, Alisia Lupidi et al.
- **Summary:** Benchmark suite for scientific research agents. Tests paper reading, hypothesis generation, experimental design, result interpretation. First comprehensive eval for research automation.
- **Relevanz:** 5/5 (Scientific Agents + Evaluation)
- **Anwendbarkeit:** SEHR HOCH - Perfect for evaluating [[AI]] research assistants. Could benchmark our own research agent capabilities against frontier systems.

---

### 5. **Auditing Multi-Agent [[LLM]] Reasoning Trees Outperforms Majority Vote and [[LLM]]-as-Judge**
- **Link:** https://arxiv.org/abs/2602.09341
- **Datum:** Feb 10, 2026
- **Autoren:** Wei Yang et al. (6 authors)
- **Summary:** Proposes AgentAuditor framework for evaluating multi-agent reasoning. Shows that auditing full reasoning trees yields 5% accuracy improvement over majority vote, 3% over [[LLM]]-as-Judge.
- **Relevanz:** 4/5 (Multi-Agent Orchestration + Quality)
- **Anwendbarkeit:** HOCH - Direct application to multi-agent systems. Better evaluation = better agent selection and orchestration.

---

### 6. **MIRIX: Multi-Agent Memory System for [[LLM]]-Based Agents**
- **Link:** https://arxiv.org/abs/2507.07957
- **Datum:** Jul 10, 2025 (recent from GitHub list)
- **Autoren:** TBD
- **Summary:** Multi-agent memory system enabling shared knowledge bases across agent teams. Implements hierarchical memory with access control and conflict resolution.
- **Relevanz:** 5/5 (Memory + Multi-Agent)
- **Anwendbarkeit:** SEHR HOCH - Critical for building agent teams that share context. Could dramatically improve multi-agent workflows.

---

### 7. **Memory-R1: Enhancing Large Language Model Agents to Manage and Utilize Memories via Reinforcement Learning**
- **Link:** https://arxiv.org/abs/2508.19828
- **Datum:** Aug 19, 2025
- **Summary:** RL framework with two agents (memory manager + task executor) for active memory management. Agents learn *when* to store, retrieve, and update memories via reward signals.
- **Relevanz:** 5/5 (Memory + RL)
- **Anwendbarkeit:** SEHR HOCH - Solves the "when to remember" problem. Could replace static retrieval with learned memory policies.

---

## üìä Additional Notable Papers

### **BudgetThinker: Empowering Budget-aware [[LLM]] Reasoning with Control Tokens**
- **Link:** https://arxiv.org/abs/2508.17196
- **Datum:** Aug 17, 2025
- **Summary:** Framework for budget-aware reasoning. Inserts control tokens to guide compute allocation. Two-stage training for efficient, controllable reasoning.
- **Relevanz:** 4/5 (Efficiency + Reasoning)
- **Anwendbarkeit:** HOCH - Cost optimization for production agents. Important for scaling agent systems economically.

---

### **AIDev: Studying [[AI]] Coding Agents on GitHub**
- **Link:** https://arxiv.org/abs/2602.09185
- **Datum:** Feb 9, 2026
- **Summary:** Empirical study of [[AI]] coding agents in production. Analyzes behavior patterns, success rates, failure modes on real GitHub repositories.
- **Relevanz:** 3/5 (Coding Agents)
- **Anwendbarkeit:** MITTEL - Interessant f√ºr Verst√§ndnis realer Agent-Behavior, weniger direkt anwendbar.

---

### **Exploring Silicon-Based Societies: An Early Study of the Moltbook Agent Community**
- **Link:** https://arxiv.org/abs/2602.02613
- **Datum:** Feb 2, 2026
- **Autoren:** Yu-Zheng Lin et al. (8 authors)
- **Summary:** Study of emergent behaviors in large-scale agent communities. Documents social patterns, communication protocols, collective decision-making in 1000+ agent society.
- **Relevanz:** 3/5 (Emergent Behavior)
- **Anwendbarkeit:** NIEDRIG f√ºr direkte Anwendung, aber faszinierend f√ºr Verst√§ndnis von Multi-Agent Emergence.

---

## üî¨ Research Trends (Feb 2026)

1. **Memory is the new frontier** - 4 of top 10 papers focus on memory architectures
2. **RL for Agent Optimization** - Shift from pure prompting to learned behaviors
3. **Scientific Research Agents** - Growing focus on automating research workflows
4. **Multi-Agent Evaluation** - Better methods for assessing collaborative reasoning
5. **Synthetic Training Environments** - World models for scalable agent training

---

## üéØ Direct Applicability f√ºr [[Ainary]]/[[VC]]-Work

**Sofort umsetzbar:**
- AIRS-Bench f√ºr Research Agent Evaluation
- AgentAuditor f√ºr Multi-Agent Quality Control
- Memory-R1 Konzepte f√ºr bessere Context-Retention in Deal Flow Analysis

**Mittelfristig relevant:**
- SkillRL f√ºr selbst-verbessernde Research Agents
- MIRIX f√ºr Shared Knowledge Bases zwischen Agent-Teams
- BudgetThinker f√ºr Cost-Optimized Agent Deployments

**Strategisch wichtig:**
- Memory Architecture Survey ‚Üí Informiert langfristige Agent-Infrastruktur
- World Models ‚Üí Relevant f√ºr Simulation-basierte Investment Scenarios

---

## üìå N√§chste Schritte

1. **Deep Dive:** AIRS-Bench + Memory Survey lesen (beide essentiell)
2. **Prototype:** AgentAuditor-Konzept f√ºr unsere Multi-Agent Pipelines testen
3. **Monitor:** Memory-R1 + MIRIX Implementations sobald Code verf√ºgbar

---

*Scan completed: 2026-02-17 00:54 CET*
*Sources: 2 GitHub repos, arXiv, web search*
*Papers reviewed: 150+ from lists, 10 deeply analyzed*
