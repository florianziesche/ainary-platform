---
type: knowledge
last_verified: 2026-02-15
status: evergreen
created: 2025-03-19
tier: KNOWLEDGE
expires: 2027-02-19
---

# ğŸ”¬ SOTA Research Brief â€” 5. Februar 2026

*Weekly State-of-the-Art [[AI]] Research & Industry Tracking*

---

## ğŸ”¥ Top Stories Dieser Woche

### 1. Sequoia erklÃ¤rt: "This is AGI" â€” Und wo sie falsch liegen

**Was:** Sequoia Capital verÃ¶ffentlicht Essay "2026: This is AGI" â€” die bisher prominenteste Behauptung, dass AGI da ist.

**Ihre Definition:** AGI = "the ability to figure things out." Drei Zutaten:
- Pre-Training (Wissen)
- Inference-Time Compute (Reasoning)
- Long-Horizon Agents (Iteration Ã¼ber Stunden)

**Key Data:**
- METR-Benchmark: [[AI]]-Task-Horizonte verdoppeln sich alle ~7 Monate
- [[Claude]] Opus 4.5: LÃ¤ngster 50%-Horizont bei **4h49m** (= lÃ¶st ~50% der Tasks die Menschen 5h brauchen)
- Prognose: Ganztages-Tasks bis 2028, Jahres-Tasks bis 2034
- Sarah Guo (Conviction): "Soon you'll be able to hire an agent" als AGI-Litmustest

**Die LÃ¼cke â€” Streaming Input:**
> Scientific American (Jan 2026): "In neither case does the [[AI]] hold a clearly defined model of the world that it continuously updates to make more informed decisions."

Sequoias "AGI" arbeitet auf **Snapshots** â€” statische Context Windows. Kein Agent hat heute kontinuierliche Wahrnehmung. Sie sind brillante Batch-Prozessoren, keine kontinuierlichen Denker. Der echte Frontier: **Streaming Input** â€” WeltverstÃ¤ndnis das sich in Echtzeit aktualisiert.

**Relevanz fÃ¼r Thesis:** â­â­â­
- **LinkedIn Post Goldmine:** Sequoia-Artikel reposten + Streaming-Input als Contrarian Take
- Investment-Angle: Startups die World Models + Continuous Perception bauen
- Conviction (Sarah Guo) = Florians Target Fund, direkt zitiert im Artikel

**Quellen:**
- [Sequoia: 2026 This is AGI](https://sequoiacap.com/article/2026-this-is-agi/)
- [Scientific American: World Models](https://www.scientificamerican.com/article/world-models-could-unlock-the-next-revolution-in-artificial-intelligence/)
- [METR Benchmark Tracking](https://metr.org/blog/2025-03-19-measuring-ai-ability-to-complete-long-tasks/)
- [Kritik am METR-Graph](https://arachnemag.substack.com/p/the-metr-graph-is-hot-garbage)

---

### 2. Die groÃŸe Modell-Konsolidierung

**Was:** OpenAI retiriert am 13. Februar 2026 gleich 6 Modelle:
- GPT-4o, GPT-4.1, GPT-4.1 mini
- o4-mini
- GPT-5 (Instant und Thinking)

Alle User werden auf **GPT-5.2** migriert. BegrÃ¼ndung: "Low usage."

**Warum wichtig:**
- Signal: Der Markt konsolidiert. Weniger Modelle, hÃ¶here QualitÃ¤t.
- GPT-5.2 ist jetzt der Baseline â€” wer dagegen baut muss besser sein
- [[API]]-User mÃ¼ssen bis 13. Feb migrieren

**Gleichzeitig: Open-Source explodiert:**
- **Kimi K2.5** (Moonshot [[AI]]): 1 Trillion Parameter MoE, 32B aktive Parameter, 15T mixed tokens, open-source
- **Step 3.5 Flash** (StepFun): 196B MoE, 11B aktiv, 256K Context, "Think-and-Act" Architektur
- **Qwen3-Coder-Next** (Alibaba): 80B Parameter, ultra-sparse, 262K Context, 10Ã— Throughput, Apache 2.0

**Key Insight:** ProprietÃ¤re Modelle konsolidieren, Open-Source fragmentiert und spezialisiert. Beide Trends validieren Vertical [[AI]].

**Relevanz fÃ¼r Thesis:** â­â­â­
- Specialized + Open-Source = Moat-Opportunity fÃ¼r Startups
- Gartner-Prediction (50% spezialisierte Modelle bis 2028) bestÃ¤tigt sich weiter
- Investment-Angle: Infra-Layer die Model-Switching ermÃ¶glicht

**Quellen:**
- [Bleeping Computer: OpenAI retiring GPT-4o](https://www.bleepingcomputer.com/news/artificial-intelligence/openai-is-retiring-famous-gpt-4o-model-says-gpt-52-is-good-enough/)
- [SiliconANGLE: Kimi K2.5](https://siliconangle.com/2026/01/27/moonshot-ai-releases-open-source-kimi-k2-5-model-1t-parameters/)
- [StepFun: Step 3.5 Flash](https://static.stepfun.com/blog/step-3.5-flash/)
- [VentureBeat: Qwen3-Coder-Next](https://venturebeat.com/technology/qwen3-coder-next-offers-vibe-coders-a-powerful-open-source-ultra-sparse)

---

### 3. Apple Ã— [[Google]]: Die grÃ¶ÃŸte [[AI]]-Plattform-Partnerschaft

**Was:** Apple und [[Google]] geben Multi-Year-Deal bekannt: **Gemini powert die nÃ¤chste Generation Siri.**
- AngekÃ¼ndigt: 12. Januar 2026
- Unveiling: Ende Februar 2026
- Public Release: MÃ¤rz/April 2026

**Details:**
- Apple Intelligence Suite (Siri, Writing Tools, Genmoji) lÃ¤uft weiterhin auf Apple-GerÃ¤ten + Apple Private Cloud
- Gemini liefert das Foundation Model fÃ¼r die "conversational" Siri
- Tim Cook: "most capable foundation for Apple Foundation Models"

**Warum das RIESIG ist:**
- ~2 Milliarden Apple-GerÃ¤te bekommen Gemini-powered [[AI]]
- [[Google]] gewinnt den [[AI]]-Verteilungskampf Ã¼ber Hardware die ihnen nicht gehÃ¶rt
- Anthropic/OpenAI verlieren den grÃ¶ÃŸten mÃ¶glichen Consumer-Distributionspartner

**Relevanz fÃ¼r Thesis:** â­â­
- Distribution > Model Quality ([[Google]]'s Strategie)
- Apple gibt de facto zu: Eigene [[AI]]-Modelle reichen nicht
- FÃ¼r VCs: Foundation Model â‰  Endgame. Distribution + Integration = Moat

**Quellen:**
- [MacRumors: Gemini-Powered Siri](https://www.macrumors.com/2026/01/30/apple-explains-how-gemini-powered-siri-will-work/)
- [CNBC: Google Earnings + Siri Deal](https://www.cnbc.com/2026/02/03/in-google-earnings-analysts-want-answers-on-apples-siri-gemini-deal.html)
- [CNET: Siri Upgrade in February](https://www.cnet.com/tech/services-and-software/apple-will-integrate-google-gemini-ai-with-siri-in-february-report-says/)

---

### 4. Amazon's 16.000 [[AI]]-Displacement â€” Die erste echte Welle

**Was:** Amazon streicht 16.000 Corporate Jobs, ersetzt Middle Management durch Agentic [[AI]].

**Kontext:**
- CEO Andy Jassy's "Flatten the Org" Initiative
- Erste Big-Tech-Firma die explizit [[AI]]-Agents fÃ¼r **Workforce Re-Engineering** nutzt, nicht nur Assistenz
- Muster: Middle Management + Operational Oversight â†’ Agentic [[AI]] Systems

**Aber:** AP News und ABC News relativieren â€” nicht alle Cuts direkt [[AI]]-getrieben. Reorganisation + [[AI]] + Effizienz = Kombination.

**Warum wichtig:**
- Erstes groÃŸes Beispiel von [[AI]]-driven Workforce Restructuring bei einem Trillion-Dollar-Unternehmen
- Signal: "[[AI]] replaces jobs" ist kein Zukunfts-Szenario mehr
- Middle Management besonders exposed (koordiniert, delegiert, berichtet = genau was Agents kÃ¶nnen)

**Relevanz fÃ¼r Thesis:** â­â­â­
- Validiert "One-Person Company" Trend
- Content-Angle: "Amazon just showed us what happens when agents replace managers"
- [[VC]]-Angle: Tools die Middle Management augmentieren (statt eliminieren) = Opportunity

**Quellen:**
- [NBC News: Amazon 16K Job Cuts](https://www.nbcnews.com/business/business-news/amazon-cuts-16000-jobs-artificial-intelligence-rcna256280)
- [AP News: AI + Layoffs Reality Check](https://apnews.com/article/ai-job-impacts-layoffs-amazon-pinterest-dow-7736d042172743301dd7e494813a885d)

---

### 5. Meta's $135 Milliarden [[AI]]-Wette

**Was:** Meta verdoppelt [[AI]]-CapEx auf **$135B fÃ¼r 2026** (vs. $72.2B in 2025). Zuckerberg: "essential for achieving personal superintelligence for our 3.5 billion users."

**"Avocado" Model:** Meta's TBD [[AI]] Unit testet Frontier-Modell als Llama-Nachfolger. Release H1 2026. Hintergrund: Llama 4 Launch war enttÃ¤uschend.

**Relevanz:** â­â­
- $135B = Signal dass [[AI]]-Race kein Hype mehr ist, sondern Infrastruktur-Krieg
- "Personal Superintelligence" als Meta's Framing
- FÃ¼r VCs: Compute-Infra wird commodity â†’ Application Layer gewinnt

---

### 6. Project Genie â€” World Models werden Consumer-Produkt

**Was:** [[Google]] DeepMind rollt **Project Genie** aus â€” Text/Bild-Prompts werden zu **spielbaren 3D-Welten** in Echtzeit.
- VerfÃ¼gbar fÃ¼r [[AI]] Ultra Subscribers in den USA
- Video Game-Aktien fielen nach AnkÃ¼ndigung

**Technisch:** Genie 3 generiert explorable Environments die man in Sekunden erstellt und in Echtzeit navigiert.

**Warum wichtig:** World Models sind nicht mehr Forschungsprojekt â€” sie sind **Consumer-Produkt**. Der Ãœbergang von "Paper" zu "Produkt" passiert gerade.

**Relevanz fÃ¼r Thesis:** â­â­
- World Models = nÃ¤chste Investment-Welle nach [[LLM]]s
- Disruption: Gaming, AR/VR, Simulation, Training
- Verbindung zu Story #1: Continuous world understanding als SchlÃ¼ssel

**Quellen:**
- [Google Blog: Project Genie](https://blog.google/innovation-and-ai/models-and-research/google-deepmind/project-genie/)
- [The Register: Genie](https://www.theregister.com/2026/01/29/googles_project_genie_ai/)

---

### 7. AlphaGenome â€” [[AI]] decodiert DNA

**Was:** DeepMind open-sourced **AlphaGenome** â€” predicts function of DNA sequences. Published in Nature.
- 3.000+ Wissenschaftler nutzen die [[API]]
- ~1 Million Requests pro Tag
- Nachfolger von AlphaFold (Protein-Strukturen, Nobelpreis)

**Relevanz:** â­â­
- [[AI]]-for-Science Trend beschleunigt sich
- DeepMind's Playbook: Breakthrough â†’ Open Source â†’ Ecosystem
- BioTech + [[AI]] = massives [[VC]]-Opportunity

**Quellen:**
- [Nature: AlphaGenome Paper](https://www.nature.com/articles/s41586-025-10014-0)
- [NYT: AlphaGenome](https://www.nytimes.com/2026/01/28/science/alphagenome-ai-deepmind-genetics.html)

---

### 8. Agentic Coding wird Mainstream

**Was:** Apple's **Xcode 26.3 RC** integriert Codex + [[Claude]] Agent via Model Context Protocol (MCP).
- Agents kÃ¶nnen autonom Projekte explorieren, Builds ausfÃ¼hren, Tests durchfÃ¼hren
- Natural Language â†’ Feature Development
- Visuelles Step-by-Step Breakdown aller Code-Ã„nderungen

**Parallel:** StepFun's "Think-and-Act" fÃ¼r Tool-Orchestrierung, Qwen3-Coder-Next fÃ¼r repo-level Engineering.

**Key Insight:** Agentic Coding ist nicht mehr "VS Code + Copilot". Es ist **IDE-native autonome Entwicklung**. Apple's Adoption = Mainstream-Signal.

**Relevanz fÃ¼r Thesis:** â­â­â­
- MCP als emerging Standard fÃ¼r Agent-Tool-Integration
- One-Person Company Trend beschleunigt sich (1 Dev + Agents = Team)
- Investment-Angle: DevTool-Layer die Agent-Orchestrierung enabled

**Quellen:**
- [TechCrunch: Xcode Agentic Coding](https://techcrunch.com/2026/02/03/xcode-moves-into-agentic-coding-with-deeper-openai-and-anthropic-integrations/)

---

## ğŸ“Š Thesis-Implikationen

| Trend | Thesis-Update | Priority |
|-------|---------------|----------|
| Sequoia "This is AGI" | Long-Horizon Agents = investierbar, aber Streaming Input = die echte Frontier | ğŸ”´ High |
| Model Konsolidierung | ProprietÃ¤r konsolidiert, Open-Source fragmentiert â†’ Vertical [[AI]] gewinnt | ğŸ”´ High |
| Apple Ã— [[Google]] Siri | Distribution > Model Quality â€” Integration = Moat | ğŸŸ¡ Medium |
| Amazon [[AI]] Displacement | Middle Management = erstes Opfer. Tools die augmentieren > eliminieren | ğŸ”´ High |
| Meta $135B CapEx | Compute = commodity â†’ Application Layer gewinnt | ğŸŸ¡ Medium |
| Project Genie | World Models von Research â†’ Consumer. NÃ¤chste Welle. | ğŸŸ¡ Medium |
| AlphaGenome | [[AI]]-for-Science beschleunigt. Bio + [[AI]] = massive Opportunity | ğŸŸ¡ Medium |
| Agentic Coding | MCP = Standard. IDE-native Agents = Mainstream | ğŸ”´ High |

---

## ğŸ¯ Talking Points fÃ¼r [[VC]] Interviews

1. **"Sequoia nennt es AGI. Ich nenne es den besten Batch-Prozessor den wir je gebaut haben. Echte AGI braucht Streaming Input â€” kontinuierliches WeltverstÃ¤ndnis, nicht snapshots."**

2. **"OpenAI retiriert 6 Modelle auf einmal. Die Konsolidierungsphase hat begonnen. Die Gewinner sind nicht die mit dem grÃ¶ÃŸten Modell, sondern die mit der besten Vertikalen."**

3. **"Apple hat gerade zugegeben, dass Foundation Models kein Wettbewerbsvorteil sind â€” Distribution schon. Gemini-Siri beweist: Der Wert entsteht im Application Layer."**

4. **"Amazon hat 16.000 Middle Managers durch [[AI]] Agents ersetzt. Das ist nicht Zukunft â€” das ist Februar 2026. Die Frage fÃ¼r VCs: Welche Layer zwischen C-Suite und Execution sind als nÃ¤chstes dran?"**

---

## ğŸ“ Content-Ideen (LinkedIn / Substack)

- [ ] **LinkedIn Repost:** Sequoia "This is AGI" + Streaming-Input Take â† **[[VC Lab]] Aufgabe**
- [ ] Blog: "Amazon just showed us the future of management â€” and it doesn't need managers"
- [ ] LinkedIn: "Apple gave up on [[AI]]. Here's what that means for startups."
- [ ] Thread: "GPT-4o is dead. 6 models retired. What the consolidation wave means."
- [ ] Substack: "The Streaming Input Problem: Why current [[AI]] can't truly understand the world"

---

## ğŸ“š Alle Quellen

| Source | Topic | Date |
|--------|-------|------|
| Sequoia Capital | "2026: This is AGI" | Jan 2026 |
| Scientific American | World Models | Jan 2026 |
| METR | Long-Horizon Task Tracking | Ongoing |
| Bleeping Computer | OpenAI Model Retirement | Feb 1 |
| SiliconANGLE | Kimi K2.5 | Jan 27 |
| StepFun | Step 3.5 Flash | Feb 3 |
| VentureBeat | Qwen3-Coder-Next | Feb 3 |
| MacRumors / CNBC | Apple Ã— [[Google]] Siri | Jan 30 / Feb 3 |
| NBC News / AP News | Amazon 16K Cuts | Jan-Feb 2026 |
| CNBC | Meta $135B CapEx + Avocado | Jan 28 |
| [[Google]] Blog | Project Genie | Jan 30 |
| Nature / NYT | AlphaGenome | Jan 28 |
| TechCrunch | Xcode 26.3 Agentic Coding | Feb 3 |
| Forbes | Physical [[AI]] + World Models | Jan 20 |
| Arachne / Planned Obsolescence | METR Graph Critique + [[AI]] Predictions | Jan 2026 |

---

## Related

- **â†” Pattern:** [[Tech-VC-Trends-2026]] â€” SOTA Research als wÃ¶chentliche Aktualisierung der Tech-VC Trends-Analyse

---

*Compiled: 2026-02-05 04:05 CET by Mia*
*Format Reference: 2026-02-02-SOTA*