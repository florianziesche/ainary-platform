[
  {"id": "S1", "title": "On Calibration of Modern Neural Networks", "authors": "Guo et al.", "venue": "ICML 2017", "tier": 1, "key_finding": "Temperature scaling + ECE metric definition. Gold standard but requires logit access.", "doi": "10.48550/arXiv.1706.04599"},
  {"id": "S2", "title": "Self-Consistency Improves Chain of Thought Reasoning", "authors": "Wang et al.", "venue": "ICLR 2023", "tier": 1, "key_finding": "Self-consistency method foundation. Sample N paths, majority vote.", "doi": "10.48550/arXiv.2203.11171"},
  {"id": "S3", "title": "Can LLMs Express Their Uncertainty?", "authors": "Xiong et al.", "venue": "ICLR 2024", "tier": 1, "key_finding": "Verbalized confidence is biased. Budget-CoCoA: 3 API calls measure agreement.", "doi": "10.48550/arXiv.2306.13063"},
  {"id": "S5", "title": "On the Robustness of Verbal Confidence in Adversarial Attacks", "authors": "NeurIPS 2025", "venue": "NeurIPS 2025", "tier": 1, "key_finding": "Verbalized confidence most adversarially vulnerable. Defense techniques largely ineffective.", "doi": null},
  {"id": "S7", "title": "Taming Overconfidence in LLMs: Reward Calibration in RLHF", "authors": "Wang et al.", "venue": "NeurIPS 2024", "tier": 1, "key_finding": "RLHF systematically damages calibration. Reward models prefer confident responses.", "doi": null},
  {"id": "S8", "title": "Calibration as Measurement of Trustworthiness in Biomedical NLP", "authors": "PMC 2024", "venue": "PMC12249208", "tier": 1, "key_finding": "Consistency ECE 27.3% vs verbalized 42% across 13 datasets. 84% of scenarios show overconfidence. BIOMEDICAL ONLY.", "doi": "PMC12249208", "caveat": "Numbers from biomedical QA, not verified cross-domain"},
  {"id": "S9", "title": "ConU: Conformal Uncertainty in LLMs", "authors": "Li et al.", "venue": "NeurIPS 2024", "tier": 1, "key_finding": "Conformal prediction for LLMs. Needs 200-500 examples. Guarantees do NOT compose for multi-agent.", "doi": null},
  {"id": "S14", "title": "EU AI Act", "authors": "European Parliament", "venue": "Official Journal EU", "tier": 1, "key_finding": "Art 15 requires 'accuracy', NOT 'calibration'. Art 14 requires human oversight. Enforcement Aug 2026.", "doi": "Official"},
  {"id": "S15", "title": "Complacency and Bias in Human Use of Automation", "authors": "Parasuraman & Manzey", "venue": "Human Factors 2010", "tier": 1, "key_finding": "Human vigilance drops 20-50% after 30 min monitoring automated systems.", "doi": "10.1177/0018720810376055"},
  {"id": "S19", "title": "5 Methods for Calibrating LLM Confidence Scores", "authors": "Latitude.so", "venue": "Blog 2025", "tier": 3, "key_finding": "Budget-CoCoA practical cost: $0.0005-$0.015/check depending on model.", "caveat": "Practitioner source, not academic"},
  {"id": "S21", "title": "Agentic Confidence Calibration (HTC)", "authors": "Zhang et al.", "venue": "arXiv Jan 2026", "tier": 2, "key_finding": "Trajectory calibration for agents. GAC achieves lowest ECE on GAIA (out-of-domain). No open-source implementation.", "doi": "arXiv:2601.15778", "caveat": "Preprint, not peer-reviewed"},
  {"id": "S26", "title": "BaseCal", "authors": "Tan et al.", "venue": "arXiv Jan 2026", "tier": 2, "key_finding": "42.9% ECE reduction via hidden state projection to base model space. Recovers calibration WITHOUT losing helpfulness.", "doi": "arXiv:2601.03042", "caveat": "Preprint"},
  {"id": "S27", "title": "SAUP: Situational Awareness Uncertainty Propagation", "authors": "Duan et al.", "venue": "ACL 2025", "tier": 1, "key_finding": "Formalizes intra-chain uncertainty propagation with situational awareness weights.", "doi": null},
  {"id": "S30", "title": "Restoring Calibration for Aligned LLMs", "authors": "ICML 2025", "venue": "ICML 2025", "tier": 1, "key_finding": "Calibratable vs non-calibratable regimes. Some models permanently damaged by RLHF, others recoverable.", "doi": null}
]
