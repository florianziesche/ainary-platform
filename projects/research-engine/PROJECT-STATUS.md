# Research Engine â€” Project Status & Knowledge Base
*Letzte Aktualisierung: 2026-02-12 09:20 CET*
*Zweck: Single Source of Truth fÃ¼r Research Engine â€” Early Warning System fÃ¼r AI/Tech Trends*

---

## ðŸŽ¯ Was ist das?

Ein **FrÃ¼hwarnsystem fÃ¼r bleeding-edge AI/Tech Ideen** â€” scannt 5 Quellen tÃ¤glich/wÃ¶chentlich und generiert einen Intelligence Brief BEVOR Trends Mainstream werden.

**Ziel:** Florian (und spÃ¤ter andere) sehen neue Signale bevor sie in VentureBeat/TechCrunch landen.

---

## ðŸ“ Dateistruktur

```
projects/research-engine/
â”œâ”€â”€ PROJECT-STATUS.md      # DIESE DATEI â€” immer zuerst lesen
â”œâ”€â”€ package.json           # Dependencies: openai, axios, cheerio, rss-parser, xml2js
â”œâ”€â”€ engine.js              # Main Orchestrator (4 Phasen)
â”œâ”€â”€ analyzer.js            # GPT-4o Synthesis
â”œâ”€â”€ renderer.js            # JSON â†’ HTML Renderer
â”œâ”€â”€ template.html          # Dark Mode HTML Template (Emerald Accent)
â”œâ”€â”€ sources/
â”‚   â”œâ”€â”€ arxiv.js           # ArXiv Atom Feed (cs.AI, cs.CL, cs.MA, cs.LG)
â”‚   â”œâ”€â”€ hackernews.js      # HN Firebase API (Top + Show HN, AI/ML filtered)
â”‚   â”œâ”€â”€ reddit.js          # Reddit JSON API (r/MachineLearning, r/LocalLLaMA, r/artificial)
â”‚   â”œâ”€â”€ github.js          # GitHub Trending Scraper (Cheerio)
â”‚   â””â”€â”€ rss.js             # VC Blogs RSS (a16z, Sequoia, Benchmark, NFX, First Round)
â””â”€â”€ output/
    â”œâ”€â”€ research-YYYY-MM-DD.html
    â””â”€â”€ research-YYYY-MM-DD.json
```

---

## ðŸ”§ Technische Details

### Pipeline (4 Phasen)
```
Phase 1: Fetch Data (ALL sources in PARALLEL) â†’ ~5-10s
Phase 2: AI Analysis (GPT-4o Synthesis) â†’ ~15-30s
Phase 3: Render HTML (JSON â†’ Template) â†’ instant
Phase 4: Save + Open â†’ instant
TOTAL: ~20-40s
```

### Data Sources (No Auth Needed!)
| Source | API/Method | Categories | Items/Run |
|--------|-----------|------------|-----------|
| **ArXiv** | Atom Feed | cs.AI, cs.CL, cs.MA, cs.LG | ~20-50 papers |
| **Hacker News** | Firebase API | Top + Show HN (AI/ML keywords) | ~20-30 stories |
| **Reddit** | JSON API | r/MachineLearning, r/LocalLLaMA, r/artificial | ~20-30 posts |
| **GitHub** | HTML Scraping | Trending (daily/weekly) | ~15-20 repos |
| **VC Blogs** | RSS Feeds | a16z, Sequoia, Benchmark, NFX, First Round | ~5-15 posts |

### API Requirements
- **OpenAI Key:** `process.env.OPENAI_API_KEY` (GPT-4o for analysis)
- **No other keys needed** â€” All sources use public APIs or scraping

### CLI Usage
```bash
node engine.js                    # Scan all sources, last 2 days
node engine.js --source arxiv     # Only ArXiv
node engine.js --days 7           # Last 7 days
npm start                         # Alias for node engine.js
npm test                          # Alias for --days=2
```

### Output Format
- **HTML:** `output/research-YYYY-MM-DD.html` (Dark Mode, opens in browser)
- **JSON:** `output/research-YYYY-MM-DD.json` (Raw data + analysis for debugging)

---

## ðŸ“Š Analysis Sections

GPT-4o creates 4 key sections:

1. **Top 5 "Emerging Signals"**
   - What's appearing NOW that most people haven't noticed
   - Signal Strength indicator (1-5)
   - Sources where it appeared

2. **Top 3 "Deep Dives"**
   - Technical breakthroughs worth investigating
   - Products/companies gaining momentum
   - Contrarian takes that might be right

3. **"Contrarian Corner"**
   - What everyone is IGNORING that could matter
   - Unpopular opinions with strong reasoning
   - Risks/limitations nobody talks about

4. **Cross-Source Patterns**
   - Themes appearing in 2+ sources
   - Academic research â†’ startup application
   - VC interest matching GitHub activity

---

## ðŸŽ¨ Design-System

### Colors
- **Background:** #0a0a0f (almost black)
- **Cards:** #12121a (dark grey with Glassmorphism)
- **Primary Accent:** #10b981 (Emerald) â† **DIFFERENTIATOR**
- **Secondary Accent:** #14b8a6 (Teal)
- **Contrarian:** #ef4444 (Red) + #f97316 (Orange)
- **Font:** Inter (Google Fonts)

### Why Emerald?
- Corporate X-Ray: Indigo (#6366f1)
- Startup X-Ray: Purple (#8b5cf6)
- Advisory Board: Gold (#f59e0b)
- **Research Engine: Emerald (#10b981)** â† Unique identity

### UI Components
- **Signal Strength Bar:** 5 vertical bars (like volume indicator)
- **Source Tags:** Pill-shaped tags (arxiv, reddit, github, etc.)
- **Glassmorphism Cards:** Subtle backdrop-blur + border
- **SVG Icons:** Heroicons-style, 24x24 or 32x32

---

## ðŸ§  Entscheidungen & Kontext

**Warum diese Quellen?**
- ArXiv = Academic bleeding edge (papers publish before peer review)
- Hacker News = Builder community (what hackers care about)
- Reddit = Early adopter community (LocalLLaMA catches OSS trends FAST)
- GitHub = Code speaks louder (trending repos = real traction)
- VC Blogs = Strategic money moving (what VCs write â†’ what they fund)

**Warum NICHT Twitter/Discord/Substack (v1)?**
- Twitter: Needs auth + rate limits + noise-to-signal ratio low
- Discord: Hard to scrape + needs auth per server
- Substack: Individual newsletter RSS â€” too fragmented for v1

**Roadmap for v2:**
- Twitter via API (if Florian pays for API access)
- Key Discord servers (Eleuther, LAION, Stability) via webhooks
- Curated Substack list (50-100 key writers)

**Shared Data Layer:**
- RSS feeds shared with blogwatcher (future integration)
- ArXiv papers feed Content X-Ray (future product)
- GitHub repos feed IC Co-Pilot (future product)
â†’ **Compound moat:** Each product makes the data more valuable

**Update Frequency (Recommendation):**
- **Daily:** For fast-moving topics (AI research, OSS releases)
- **Weekly:** For strategic analysis (combine 7 days â†’ bigger patterns)
- **Monthly:** For long-term trend tracking

---

## ðŸ“‹ NÃ¤chste Session â€” Checkliste

Wenn du diese Datei liest, mache ZUERST:

1. [ ] Lies dieses Dokument komplett
2. [ ] Check `output/` â€” gibt es neue Reports?
3. [ ] Lies Florians letzte Telegram-Nachrichten fÃ¼r Feedback
4. [ ] Lies `memory/2026-02-12.md` fÃ¼r Tageskontext
5. [ ] `grep -i "research\|engine" memory/*.md` fÃ¼r historischen Kontext

---

## ðŸš€ Roadmap

| # | Feature | Status | Aufwand | PrioritÃ¤t |
|---|---------|--------|---------|-----------|
| 1 | Core v1 (5 sources) | âœ… GEBAUT | - | DONE |
| 2 | Test-Run + Deploy | ðŸ”¨ IN ARBEIT | 10 Min | NOW |
| 3 | Email/Telegram Delivery | â³ geplant | 1-2h | HIGH |
| 4 | Twitter Source | â³ geplant | 2h | MEDIUM |
| 5 | Discord Source | â³ geplant | 3h | MEDIUM |
| 6 | Cron Job (daily run) | â³ geplant | 30 Min | HIGH |
| 7 | Web UI (historical reports) | â³ geplant | 1 Tag | LOW |
| 8 | Shared DB with blogwatcher | â³ geplant | 2-3h | MEDIUM |

---

## ðŸ› Known Issues

| Issue | Status | Notes |
|-------|--------|-------|
| ArXiv rate limit | âš ï¸  POSSIBLE | Max 1 req/3s â€” implemented delay between categories |
| GitHub scraping fragile | âš ï¸  POSSIBLE | HTML structure can change â€” backup: GitHub API |
| Reddit rate limit | âš ï¸  POSSIBLE | User-Agent header should prevent 429s |
| OpenAI timeout | âš ï¸  POSSIBLE | Large prompts (>100 items) might timeout â†’ batch if needed |

---

## ðŸ“Š Cost Estimation

**Per Run:**
- ArXiv: Free
- Hacker News: Free
- Reddit: Free
- GitHub: Free
- RSS: Free
- **OpenAI (GPT-4o):** ~$0.05-$0.15 per analysis (1 API call, ~3K tokens)

**Daily Run:** ~$0.10/day = ~$3/month
**Weekly Run:** ~$0.10/week = ~$0.50/month

**Conclusion:** Dirt cheap.

---

*Aktualisiere dieses Dokument nach JEDER Ã„nderung am System.*
