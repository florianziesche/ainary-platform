# Ainary Research Engine â€” Verified Source List

*Nur echte, aktive Quellen. Keine Fake-Zahlen.*
*Aktualisiert: 2026-02-12*

## Source Types

### 1. RSS Feeds (Active: 5)
| # | Name | URL | Category |
|---|------|-----|----------|
| 1 | a16z | a16z.com/feed/ | VC Blog |
| 2 | Sequoia | sequoiacap.com/blog/feed/ | VC Blog |
| 3 | Y Combinator | ycombinator.com/blog/feed | VC Blog |
| 4 | a16z AI | a16z.com/tag/artificial-intelligence/feed/ | AI Blog |
| 5 | Greylock | greylock.com/feed/ | VC Blog |

### 2. ArXiv (1 source, multiple categories)
- ArXiv cs.AI, cs.CL, cs.LG (papers)

### 3. Hacker News (1 source)
- Top/Best stories, AI-filtered

### 4. Reddit (1 source, multiple subreddits)
- r/MachineLearning, r/artificial, r/LocalLLaMA (estimated)

### 5. GitHub (1 source)
- Trending repos, AI-filtered

## Total Count (Honest)
- **RSS Feeds: 5**
- **Platform Sources: 4** (ArXiv, HN, Reddit, GitHub)
- **Total: 9 unique sources**

## Target (to make "243 sources" real)
To reach 200+ sources legitimately, we need:
- 30+ VC/Tech blog RSS feeds
- 20+ Industry news RSS feeds  
- 10+ AI research RSS feeds
- ArXiv (50+ categories = 50 sources)
- Reddit (20+ subreddits = 20 sources)
- GitHub (trending + specific repos = 10 sources)
- HN (top + best + show + ask = 4 sources)
- SEC/EDGAR filings = 1 source
- Patent databases = 1 source
- News APIs (NewsAPI, GDELT) = 2 sources
- Twitter/X lists = 5 sources
- LinkedIn feeds = 5 sources

This would get us to ~160-200 real sources.

## Monthly Update Process
1. First of month: Review + add new feeds
2. Remove dead feeds
3. Update count on website
4. Log in CHANGELOG
