<!DOCTYPE html>
<html><head>
<meta charset="utf-8">
<title>mia_synthesis_v3.py — Elite Research Synthesis Engine</title>
<style>
body { font-family: 'SF Mono', 'Fira Code', monospace; background: #1e1e2e; color: #cdd6f4; margin: 0; padding: 0; }
header { background: #181825; padding: 1.5em 2em; border-bottom: 2px solid #f5c2e7; }
header h1 { margin: 0; color: #f5c2e7; font-size: 1.4em; }
header p { margin: 0.3em 0 0; color: #a6adc8; font-size: 0.85em; }
.meta { display: flex; gap: 2em; margin-top: 0.8em; flex-wrap: wrap; }
.meta span { background: #313244; padding: 0.3em 0.8em; border-radius: 6px; font-size: 0.8em; color: #94e2d5; }
pre { padding: 1.5em 2em; margin: 0; overflow-x: auto; line-height: 1.5; font-size: 0.82em; counter-reset: line; }
code { white-space: pre; }
.line { display: block; }
.line::before { counter-increment: line; content: counter(line); display: inline-block; width: 4em; text-align: right; margin-right: 1.5em; color: #585b70; border-right: 1px solid #313244; padding-right: 0.8em; user-select: none; }
</style>
</head><body>
<header>
<h1>mia_synthesis_v3.py</h1>
<p>Elite Research Synthesis Engine — 5-Phase Architecture</p>
<div class="meta">
<span>1,229 LOC</span>
<span>42.5 KB</span>
<span>stdlib only</span>
<span>7 sections × Opus</span>
<span>13 validation checks</span>
</div>
</header>
<pre><code><span class="line">#!/usr/bin/env python3</span><span class="line">&quot;&quot;&quot;</span><span class="line">mia_synthesis_v3.py — Elite Research Synthesis Engine (v3)</span><span class="line"></span><span class="line">5-Phase architecture:</span><span class="line">  A: Retrieval + Outline (1 Opus call)</span><span class="line">  B: Sections (7 Opus calls, sequential)</span><span class="line">  C: Merge (Python, 0 LLM)</span><span class="line">  D: Validate (Python, 0 LLM)</span><span class="line">  E: Grade + Output</span><span class="line"></span><span class="line">Usage:</span><span class="line">    python3 mia_synthesis_v3.py /path/to/pipeline-output/ [--version v5] [--dry-run]</span><span class="line">&quot;&quot;&quot;</span><span class="line"></span><span class="line">from __future__ import annotations</span><span class="line"></span><span class="line">import argparse</span><span class="line">import glob</span><span class="line">import json</span><span class="line">import os</span><span class="line">import re</span><span class="line">import subprocess</span><span class="line">import sys</span><span class="line">import textwrap</span><span class="line">import time</span><span class="line">from datetime import datetime, timezone</span><span class="line">from pathlib import Path</span><span class="line">from typing import Any, Optional</span><span class="line"></span><span class="line"># AgentTrust integration — use the real library, not inline reimplementation</span><span class="line">try:</span><span class="line">    from agenttrust.core.calibration import source_signal_confidence as _at_confidence</span><span class="line">    from agenttrust.core.beipackzettel import Beipackzettel as _AT_Beipackzettel</span><span class="line">    from agenttrust.core.trust_score import TrustScore as _AT_TrustScore</span><span class="line">    USE_AGENTTRUST = True</span><span class="line">except ImportError:</span><span class="line">    USE_AGENTTRUST = False</span><span class="line"></span><span class="line"># ---------------------------------------------------------------------------</span><span class="line"># Constants</span><span class="line"># ---------------------------------------------------------------------------</span><span class="line"></span><span class="line">WORKSPACE = Path(os.path.expanduser(&quot;~/.openclaw/workspace&quot;))</span><span class="line"></span><span class="line">SECTION_ORDER: list[str] = [</span><span class="line">    &quot;beipackzettel&quot;,</span><span class="line">    &quot;executive_summary&quot;,</span><span class="line">    &quot;framework&quot;,</span><span class="line">    &quot;key_findings&quot;,</span><span class="line">    &quot;recommendations&quot;,</span><span class="line">    &quot;risks&quot;,</span><span class="line">    &quot;appendix&quot;,</span><span class="line">]</span><span class="line"></span><span class="line">MIN_WORDS: dict[str, int] = {</span><span class="line">    &quot;beipackzettel&quot;: 300,</span><span class="line">    &quot;executive_summary&quot;: 600,</span><span class="line">    &quot;framework&quot;: 800,</span><span class="line">    &quot;key_findings&quot;: 1500,</span><span class="line">    &quot;recommendations&quot;: 1200,</span><span class="line">    &quot;risks&quot;: 800,</span><span class="line">    &quot;appendix&quot;: 1000,</span><span class="line">}</span><span class="line"></span><span class="line">BANNED_WORDS: list[str] = [</span><span class="line">    &quot;delve&quot;, &quot;dive into&quot;, &quot;it&#x27;s important to note&quot;, &quot;in conclusion&quot;,</span><span class="line">    &quot;game-changer&quot;, &quot;paradigm shift&quot;, &quot;synergy&quot;, &quot;leverage&quot;,</span><span class="line">    &quot;holistic&quot;, &quot;robust&quot;, &quot;cutting-edge&quot;, &quot;best-in-class&quot;,</span><span class="line">    &quot;groundbreaking&quot;, &quot;revolutionary&quot;, &quot;unprecedented&quot;,</span><span class="line">]</span><span class="line"></span><span class="line">ADMIRALTY_MAP: dict[str, float] = {</span><span class="line">    &quot;A1&quot;: 0.95, &quot;A2&quot;: 0.85, &quot;A3&quot;: 0.75,</span><span class="line">    &quot;B1&quot;: 0.80, &quot;B2&quot;: 0.70, &quot;B3&quot;: 0.60,</span><span class="line">    &quot;C1&quot;: 0.60, &quot;C2&quot;: 0.50, &quot;C3&quot;: 0.40,</span><span class="line">    &quot;D1&quot;: 0.40, &quot;D2&quot;: 0.30, &quot;D3&quot;: 0.25, &quot;D4&quot;: 0.20,</span><span class="line">    &quot;E1&quot;: 0.15, &quot;E2&quot;: 0.10, &quot;E3&quot;: 0.05,</span><span class="line">    &quot;F1&quot;: 0.50, &quot;F2&quot;: 0.40, &quot;F3&quot;: 0.30,</span><span class="line">}</span><span class="line"></span><span class="line">EIJA_WEIGHTS: dict[str, float] = {&quot;E&quot;: 0.85, &quot;I&quot;: 0.60, &quot;J&quot;: 0.30, &quot;A&quot;: 0.20}</span><span class="line"></span><span class="line">USE_RAG: bool = False</span><span class="line"></span><span class="line">try:</span><span class="line">    from rag_layer import query as rag_query, query_for_section, ingest  # type: ignore</span><span class="line">    USE_RAG = True</span><span class="line">except ImportError:</span><span class="line">    pass</span><span class="line"></span><span class="line"># ---------------------------------------------------------------------------</span><span class="line"># Utility: OAuth + Opus</span><span class="line"># ---------------------------------------------------------------------------</span><span class="line"></span><span class="line">def _load_oauth_token() -&gt; str:</span><span class="line">    &quot;&quot;&quot;Load OAuth token from auth-profiles.json.&quot;&quot;&quot;</span><span class="line">    auth_path = Path(os.path.expanduser(</span><span class="line">        &quot;~/.openclaw/agents/main/agent/auth-profiles.json&quot;</span><span class="line">    ))</span><span class="line">    if not auth_path.exists():</span><span class="line">        raise RuntimeError(f&quot;No auth file at {auth_path}&quot;)</span><span class="line"></span><span class="line">    auth_data = json.loads(auth_path.read_text())</span><span class="line">    candidates: list[str] = []</span><span class="line"></span><span class="line">    def _extract(obj: Any) -&gt; None:</span><span class="line">        if isinstance(obj, dict):</span><span class="line">            for k, v in obj.items():</span><span class="line">                if k in (&quot;token&quot;, &quot;accessToken&quot;) and isinstance(v, str) and v.startswith(&quot;sk-ant-oat&quot;):</span><span class="line">                    candidates.append(v)</span><span class="line">                elif isinstance(v, (dict, list)):</span><span class="line">                    _extract(v)</span><span class="line">        elif isinstance(obj, list):</span><span class="line">            for item in obj:</span><span class="line">                _extract(item)</span><span class="line"></span><span class="line">    _extract(auth_data)</span><span class="line">    if not candidates:</span><span class="line">        raise RuntimeError(&quot;No sk-ant-oat token found in auth-profiles.json&quot;)</span><span class="line">    return candidates[0]</span><span class="line"></span><span class="line"></span><span class="line">def call_opus(</span><span class="line">    prompt: str,</span><span class="line">    system: str = &quot;&quot;,</span><span class="line">    max_tokens: int = 4096,</span><span class="line">    retry: bool = True,</span><span class="line">) -&gt; str:</span><span class="line">    &quot;&quot;&quot;Call Claude Opus via curl + OAuth. Returns response text.&quot;&quot;&quot;</span><span class="line">    token = _load_oauth_token()</span><span class="line"></span><span class="line">    messages = [{&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: prompt}]</span><span class="line">    payload: dict[str, Any] = {</span><span class="line">        &quot;model&quot;: &quot;claude-opus-4-20250514&quot;,</span><span class="line">        &quot;max_tokens&quot;: max_tokens,</span><span class="line">        &quot;messages&quot;: messages,</span><span class="line">    }</span><span class="line">    if system:</span><span class="line">        payload[&quot;system&quot;] = system</span><span class="line"></span><span class="line">    payload_json = json.dumps(payload)</span><span class="line">    print(f&quot;  [OPUS] Sending {len(prompt)} chars, max_tokens={max_tokens}...&quot;)</span><span class="line"></span><span class="line">    for attempt in range(2 if retry else 1):</span><span class="line">        if attempt &gt; 0:</span><span class="line">            print(&quot;  [OPUS] Retry after 30s...&quot;)</span><span class="line">            time.sleep(30)</span><span class="line"></span><span class="line">        start = time.time()</span><span class="line">        try:</span><span class="line">            result = subprocess.run(</span><span class="line">                [</span><span class="line">                    &quot;curl&quot;, &quot;-s&quot;, &quot;-X&quot;, &quot;POST&quot;,</span><span class="line">                    &quot;https://api.anthropic.com/v1/messages&quot;,</span><span class="line">                    &quot;-H&quot;, f&quot;Authorization: Bearer {token}&quot;,</span><span class="line">                    &quot;-H&quot;, &quot;anthropic-version: 2023-06-01&quot;,</span><span class="line">                    &quot;-H&quot;, &quot;anthropic-beta: oauth-2025-04-20&quot;,</span><span class="line">                    &quot;-H&quot;, &quot;content-type: application/json&quot;,</span><span class="line">                    &quot;-d&quot;, payload_json,</span><span class="line">                ],</span><span class="line">                capture_output=True, text=True, timeout=900,</span><span class="line">            )</span><span class="line">            elapsed = time.time() - start</span><span class="line"></span><span class="line">            if result.returncode != 0:</span><span class="line">                raise RuntimeError(f&quot;curl failed: {result.stderr[:300]}&quot;)</span><span class="line"></span><span class="line">            data = json.loads(result.stdout)</span><span class="line">            if &quot;error&quot; in data:</span><span class="line">                raise RuntimeError(f&quot;API error: {data[&#x27;error&#x27;]}&quot;)</span><span class="line"></span><span class="line">            text = data[&quot;content&quot;][0][&quot;text&quot;]</span><span class="line">            print(f&quot;  [OPUS] Got {len(text)} chars in {elapsed:.0f}s&quot;)</span><span class="line">            return text</span><span class="line"></span><span class="line">        except Exception as e:</span><span class="line">            print(f&quot;  [OPUS] Error (attempt {attempt + 1}): {e}&quot;)</span><span class="line">            if attempt == 0 and retry:</span><span class="line">                continue</span><span class="line">            raise</span><span class="line"></span><span class="line">    return &quot;&quot;  # unreachable</span><span class="line"></span><span class="line"></span><span class="line">def extract_json(text: str) -&gt; Any:</span><span class="line">    &quot;&quot;&quot;Extract JSON from text, handling ```json...``` wrapping.&quot;&quot;&quot;</span><span class="line">    # Try direct parse</span><span class="line">    text = text.strip()</span><span class="line">    if text.startswith(&quot;{&quot;) or text.startswith(&quot;[&quot;):</span><span class="line">        try:</span><span class="line">            return json.loads(text)</span><span class="line">        except json.JSONDecodeError:</span><span class="line">            pass</span><span class="line">    # Try fenced block</span><span class="line">    m = re.search(r&quot;```(?:json)?\s*\n(.*?)```&quot;, text, re.DOTALL)</span><span class="line">    if m:</span><span class="line">        try:</span><span class="line">            return json.loads(m.group(1))</span><span class="line">        except json.JSONDecodeError:</span><span class="line">            pass</span><span class="line">    # Aggressive: find first { to last }</span><span class="line">    start = text.find(&quot;{&quot;)</span><span class="line">    end = text.rfind(&quot;}&quot;)</span><span class="line">    if start != -1 and end != -1 and end &gt; start:</span><span class="line">        try:</span><span class="line">            return json.loads(text[start:end + 1])</span><span class="line">        except json.JSONDecodeError:</span><span class="line">            pass</span><span class="line">    raise ValueError(f&quot;Cannot extract JSON from text ({len(text)} chars)&quot;)</span><span class="line"></span><span class="line"></span><span class="line"># ---------------------------------------------------------------------------</span><span class="line"># Data Loading</span><span class="line"># ---------------------------------------------------------------------------</span><span class="line"></span><span class="line">def load_pipeline_data(pipeline_dir: Path) -&gt; dict[str, Any]:</span><span class="line">    &quot;&quot;&quot;Load all pipeline output files into a dict.&quot;&quot;&quot;</span><span class="line">    data: dict[str, Any] = {}</span><span class="line"></span><span class="line">    # JSON files</span><span class="line">    for name in [&quot;research-brief.json&quot;, &quot;all-claims.json&quot;, &quot;contradictions.json&quot;,</span><span class="line">                  &quot;sub-reviews.json&quot;, &quot;blindspots.json&quot;]:</span><span class="line">        p = pipeline_dir / name</span><span class="line">        if p.exists():</span><span class="line">            data[name] = json.loads(p.read_text())</span><span class="line">            print(f&quot;  Loaded {name} ({p.stat().st_size} bytes)&quot;)</span><span class="line">        else:</span><span class="line">            print(f&quot;  WARNING: {name} not found&quot;)</span><span class="line">            data[name] = {}</span><span class="line"></span><span class="line">    # Sub-reports</span><span class="line">    sub_reports: list[dict[str, str]] = []</span><span class="line">    for md in sorted(pipeline_dir.glob(&quot;sq-*/report.md&quot;)):</span><span class="line">        sub_reports.append({</span><span class="line">            &quot;sq&quot;: md.parent.name,</span><span class="line">            &quot;text&quot;: md.read_text(),</span><span class="line">        })</span><span class="line">    data[&quot;sub_reports&quot;] = sub_reports</span><span class="line">    print(f&quot;  Loaded {len(sub_reports)} sub-reports&quot;)</span><span class="line"></span><span class="line">    return data</span><span class="line"></span><span class="line"></span><span class="line">def load_workspace_data() -&gt; dict[str, Any]:</span><span class="line">    &quot;&quot;&quot;Load workspace-level reference files.&quot;&quot;&quot;</span><span class="line">    data: dict[str, Any] = {}</span><span class="line">    files = {</span><span class="line">        &quot;compounding-truths&quot;: WORKSPACE / &quot;research-base&quot; / &quot;compounding-research-truths.json&quot;,</span><span class="line">        &quot;corrections&quot;: WORKSPACE / &quot;research-base&quot; / &quot;corrections.json&quot;,</span><span class="line">        &quot;reference-library&quot;: WORKSPACE / &quot;research-base&quot; / &quot;reference-library.json&quot;,</span><span class="line">        &quot;prior-report&quot;: WORKSPACE / &quot;research&quot; / &quot;ar-020-agent-trust-calibration&quot; / &quot;ar-020-v5-state-of-agent-trust.md&quot;,</span><span class="line">    }</span><span class="line">    for key, p in files.items():</span><span class="line">        if p.exists():</span><span class="line">            if p.suffix == &quot;.json&quot;:</span><span class="line">                data[key] = json.loads(p.read_text())</span><span class="line">            else:</span><span class="line">                data[key] = p.read_text()</span><span class="line">            print(f&quot;  Loaded {key} ({p.stat().st_size} bytes)&quot;)</span><span class="line">        else:</span><span class="line">            print(f&quot;  WARNING: {key} not found at {p}&quot;)</span><span class="line">            data[key] = {} if p.suffix == &quot;.json&quot; else &quot;&quot;</span><span class="line">    return data</span><span class="line"></span><span class="line"></span><span class="line"># ---------------------------------------------------------------------------</span><span class="line"># Claim Ledger Parser (robust, multi-format)</span><span class="line"># ---------------------------------------------------------------------------</span><span class="line"></span><span class="line">def parse_claim_ledger(text: str) -&gt; list[dict[str, Any]]:</span><span class="line">    &quot;&quot;&quot;Parse claim ledger entries from various formats.</span><span class="line"></span><span class="line">    Handles:</span><span class="line">        CL-01 | RLHF damages calibration | [E] | [S30] | A2 | 0.82</span><span class="line">        CL-01 [E] &quot;RLHF damages calibration&quot; [S30] (A2, 0.82)</span><span class="line">        | CL-01 | RLHF damages calibration | E | S30 | A2 |</span><span class="line">        CL-01: RLHF damages calibration [E] [S30] A2</span><span class="line">    &quot;&quot;&quot;</span><span class="line">    claims: list[dict[str, Any]] = []</span><span class="line">    # Find all CL-## occurrences and parse the line</span><span class="line">    for line in text.split(&quot;\n&quot;):</span><span class="line">        m_cl = re.search(r&quot;CL-(\d+)&quot;, line)</span><span class="line">        if not m_cl:</span><span class="line">            continue</span><span class="line"></span><span class="line">        cl_id = f&quot;CL-{m_cl.group(1)}&quot;</span><span class="line"></span><span class="line">        # Extract E/I/J/A label</span><span class="line">        m_label = re.search(r&quot;\[([EIJA])\]|\b([EIJA])\b(?=\s*\||\s*\]|\s*$|\s+[SA]\d|\s+\[S)&quot;, line)</span><span class="line">        label = &quot;&quot;</span><span class="line">        if m_label:</span><span class="line">            label = m_label.group(1) or m_label.group(2) or &quot;&quot;</span><span class="line"></span><span class="line">        # Extract source references [S##] or S##</span><span class="line">        sources = re.findall(r&quot;\[?S(\d+)\]?&quot;, line)</span><span class="line">        sources = [f&quot;S{s}&quot; for s in sources]</span><span class="line"></span><span class="line">        # Extract admiralty rating (A1-F3 pattern)</span><span class="line">        m_adm = re.search(r&quot;\b([A-F][1-6])\b&quot;, line)</span><span class="line">        admiralty = m_adm.group(1) if m_adm else &quot;&quot;</span><span class="line"></span><span class="line">        # Extract confidence if present</span><span class="line">        m_conf = re.search(r&quot;\b(0\.\d+)\b&quot;, line)</span><span class="line">        conf = float(m_conf.group(1)) if m_conf else None</span><span class="line"></span><span class="line">        # Extract claim text (heuristic: longest segment without brackets)</span><span class="line">        # Remove known tokens to isolate claim text</span><span class="line">        cleaned = line</span><span class="line">        cleaned = re.sub(r&quot;CL-\d+&quot;, &quot;&quot;, cleaned)</span><span class="line">        cleaned = re.sub(r&quot;\[?[EIJA]\]?&quot;, &quot;&quot;, cleaned, count=1)</span><span class="line">        cleaned = re.sub(r&quot;\[?S\d+\]?&quot;, &quot;&quot;, cleaned)</span><span class="line">        cleaned = re.sub(r&quot;\b[A-F][1-6]\b&quot;, &quot;&quot;, cleaned)</span><span class="line">        cleaned = re.sub(r&quot;\b0\.\d+\b&quot;, &quot;&quot;, cleaned)</span><span class="line">        cleaned = re.sub(r&quot;[|:\&quot;()\[\]]&quot;, &quot; &quot;, cleaned)</span><span class="line">        claim_text = &quot; &quot;.join(cleaned.split()).strip(&quot; -,.&quot;)</span><span class="line"></span><span class="line">        claims.append({</span><span class="line">            &quot;id&quot;: cl_id,</span><span class="line">            &quot;label&quot;: label,</span><span class="line">            &quot;text&quot;: claim_text,</span><span class="line">            &quot;sources&quot;: sources,</span><span class="line">            &quot;admiralty&quot;: admiralty,</span><span class="line">            &quot;confidence&quot;: conf,</span><span class="line">            &quot;raw&quot;: line.strip(),</span><span class="line">        })</span><span class="line"></span><span class="line">    return claims</span><span class="line"></span><span class="line"></span><span class="line"># ---------------------------------------------------------------------------</span><span class="line"># Phase A: Retrieval + Outline</span><span class="line"># ---------------------------------------------------------------------------</span><span class="line"></span><span class="line">OUTLINE_SYSTEM = textwrap.dedent(&quot;&quot;&quot;\</span><span class="line">    You are Mia, an elite research synthesis AI. You produce intelligence-grade reports.</span><span class="line"></span><span class="line">    RULES:</span><span class="line">    - Use E/I/J/A epistemic labels for ALL claims</span><span class="line">    - E = Established (≥3 peer-reviewed, converging), I = Informed (2+ credible),</span><span class="line">      J = Judgment (1 source or extrapolation), A = Assumption (no direct evidence)</span><span class="line">    - Every claim gets [S#] source reference</span><span class="line">    - Every section gets &quot;For the decision maker:&quot; callout</span><span class="line">    - Every section gets confidence percentage</span><span class="line">    - BANNED words: &quot;&quot;&quot; + &quot;, &quot;.join(BANNED_WORDS) + &quot;&quot;&quot;</span><span class="line"></span><span class="line">    OUTPUT FORMAT: JSON only, no prose outside JSON.</span><span class="line">&quot;&quot;&quot;)</span><span class="line"></span><span class="line">OUTLINE_USER_TEMPLATE = textwrap.dedent(&quot;&quot;&quot;\</span><span class="line">    Create a detailed outline for a research synthesis report.</span><span class="line"></span><span class="line">    RESEARCH BRIEF:</span><span class="line">    {brief}</span><span class="line"></span><span class="line">    CLAIMS ({n_claims} total):</span><span class="line">    {claims_summary}</span><span class="line"></span><span class="line">    CONTRADICTIONS:</span><span class="line">    {contradictions}</span><span class="line"></span><span class="line">    BLINDSPOTS:</span><span class="line">    {blindspots}</span><span class="line"></span><span class="line">    SUB-REPORTS ({n_subs} total):</span><span class="line">    {sub_summaries}</span><span class="line"></span><span class="line">    {rag_context}</span><span class="line"></span><span class="line">    Return a JSON object with this structure:</span><span class="line">    {{</span><span class="line">      &quot;title&quot;: &quot;...&quot;,</span><span class="line">      &quot;version&quot;: &quot;{version}&quot;,</span><span class="line">      &quot;sections&quot;: [</span><span class="line">        {{</span><span class="line">          &quot;id&quot;: &quot;beipackzettel&quot;,</span><span class="line">          &quot;title&quot;: &quot;Beipackzettel (Information Safety Label)&quot;,</span><span class="line">          &quot;key_points&quot;: [&quot;...&quot;],</span><span class="line">          &quot;claim_assignments&quot;: [&quot;CL-01&quot;, &quot;CL-02&quot;],</span><span class="line">          &quot;source_assignments&quot;: [&quot;S1&quot;, &quot;S2&quot;],</span><span class="line">          &quot;min_words&quot;: 300</span><span class="line">        }},</span><span class="line">        ... (all 7 sections in order: beipackzettel, executive_summary, framework, key_findings, recommendations, risks, appendix)</span><span class="line">      ],</span><span class="line">      &quot;total_claims&quot;: ...,</span><span class="line">      &quot;total_sources&quot;: ...</span><span class="line">    }}</span><span class="line"></span><span class="line">    EVERY claim (CL-##) must be assigned to exactly one section.</span><span class="line">    EVERY source (S##) must be assigned to at least one section.</span><span class="line">    All 7 sections MUST be present.</span><span class="line">&quot;&quot;&quot;)</span><span class="line"></span><span class="line"></span><span class="line">def phase_a_outline(</span><span class="line">    pipeline_data: dict[str, Any],</span><span class="line">    workspace_data: dict[str, Any],</span><span class="line">    version: str,</span><span class="line">    dry_run: bool = False,</span><span class="line">) -&gt; dict[str, Any]:</span><span class="line">    &quot;&quot;&quot;Phase A: Generate outline via Opus.&quot;&quot;&quot;</span><span class="line">    t0 = time.time()</span><span class="line">    print(&quot;\n[PHASE A] Retrieval + Outline&quot;)</span><span class="line"></span><span class="line">    brief = pipeline_data.get(&quot;research-brief.json&quot;, {})</span><span class="line">    brief_str = json.dumps(brief, indent=2)[:3000] if brief else &quot;(no brief)&quot;</span><span class="line"></span><span class="line">    # Claims</span><span class="line">    all_claims = pipeline_data.get(&quot;all-claims.json&quot;, {})</span><span class="line">    if isinstance(all_claims, list):</span><span class="line">        claims_list = all_claims</span><span class="line">    elif isinstance(all_claims, dict):</span><span class="line">        claims_list = all_claims.get(&quot;claims&quot;, [])</span><span class="line">    else:</span><span class="line">        claims_list = []</span><span class="line">    claims_summary = json.dumps(claims_list[:30], indent=1)[:4000] if claims_list else &quot;(no claims)&quot;</span><span class="line"></span><span class="line">    # Contradictions</span><span class="line">    contras = pipeline_data.get(&quot;contradictions.json&quot;, {})</span><span class="line">    contra_str = json.dumps(contras, indent=1)[:2000] if contras else &quot;(none)&quot;</span><span class="line"></span><span class="line">    # Blindspots</span><span class="line">    blinds = pipeline_data.get(&quot;blindspots.json&quot;, {})</span><span class="line">    blind_str = json.dumps(blinds, indent=1)[:2000] if blinds else &quot;(none)&quot;</span><span class="line"></span><span class="line">    # Sub-report summaries</span><span class="line">    sub_reports = pipeline_data.get(&quot;sub_reports&quot;, [])</span><span class="line">    sub_sums: list[str] = []</span><span class="line">    for sr in sub_reports:</span><span class="line">        text = sr[&quot;text&quot;][:500]</span><span class="line">        sub_sums.append(f&quot;### {sr[&#x27;sq&#x27;]}\n{text}...&quot;)</span><span class="line">    sub_str = &quot;\n\n&quot;.join(sub_sums) if sub_sums else &quot;(no sub-reports)&quot;</span><span class="line"></span><span class="line">    # RAG context</span><span class="line">    rag_context = &quot;&quot;</span><span class="line">    if USE_RAG:</span><span class="line">        try:</span><span class="line">            chunks = rag_query(&quot;research synthesis outline&quot;, top_k=50)  # type: ignore</span><span class="line">            rag_context = &quot;RAG CONTEXT (top-50 chunks):\n&quot; + &quot;\n---\n&quot;.join(</span><span class="line">                c.get(&quot;text&quot;, &quot;&quot;)[:300] for c in chunks[:50]</span><span class="line">            )</span><span class="line">        except Exception as e:</span><span class="line">            print(f&quot;  WARNING: RAG query failed: {e}&quot;)</span><span class="line"></span><span class="line">    prompt = OUTLINE_USER_TEMPLATE.format(</span><span class="line">        brief=brief_str,</span><span class="line">        n_claims=len(claims_list),</span><span class="line">        claims_summary=claims_summary,</span><span class="line">        contradictions=contra_str,</span><span class="line">        blindspots=blind_str,</span><span class="line">        n_subs=len(sub_reports),</span><span class="line">        sub_summaries=sub_str,</span><span class="line">        rag_context=rag_context,</span><span class="line">        version=version,</span><span class="line">    )</span><span class="line"></span><span class="line">    if dry_run:</span><span class="line">        print(f&quot;  [DRY RUN] Would send outline prompt ({len(prompt)} chars)&quot;)</span><span class="line">        print(f&quot;  --- PROMPT PREVIEW (first 2000 chars) ---&quot;)</span><span class="line">        print(prompt[:2000])</span><span class="line">        print(f&quot;  --- END PREVIEW ---&quot;)</span><span class="line">        elapsed = time.time() - t0</span><span class="line">        print(f&quot;[PHASE A] Done (dry-run) in {elapsed:.1f}s&quot;)</span><span class="line">        # Return stub outline</span><span class="line">        return {</span><span class="line">            &quot;title&quot;: &quot;DRY RUN&quot;,</span><span class="line">            &quot;version&quot;: version,</span><span class="line">            &quot;sections&quot;: [</span><span class="line">                {&quot;id&quot;: s, &quot;title&quot;: s, &quot;key_points&quot;: [], &quot;claim_assignments&quot;: [],</span><span class="line">                 &quot;source_assignments&quot;: [], &quot;min_words&quot;: MIN_WORDS.get(s, 500)}</span><span class="line">                for s in SECTION_ORDER</span><span class="line">            ],</span><span class="line">            &quot;total_claims&quot;: len(claims_list),</span><span class="line">            &quot;total_sources&quot;: 0,</span><span class="line">        }</span><span class="line"></span><span class="line">    response = call_opus(prompt, system=OUTLINE_SYSTEM, max_tokens=3000)</span><span class="line">    outline = extract_json(response)</span><span class="line"></span><span class="line">    # Validate outline</span><span class="line">    section_ids = [s[&quot;id&quot;] for s in outline.get(&quot;sections&quot;, [])]</span><span class="line">    missing = [s for s in SECTION_ORDER if s not in section_ids]</span><span class="line">    if missing:</span><span class="line">        print(f&quot;  WARNING: Outline missing sections: {missing}. Retrying...&quot;)</span><span class="line">        response = call_opus(</span><span class="line">            prompt + f&quot;\n\nYour outline was missing sections: {missing}. Include ALL 7.&quot;,</span><span class="line">            system=OUTLINE_SYSTEM, max_tokens=3000,</span><span class="line">        )</span><span class="line">        outline = extract_json(response)</span><span class="line"></span><span class="line">    elapsed = time.time() - t0</span><span class="line">    print(f&quot;[PHASE A] Done in {elapsed:.1f}s — {len(outline.get(&#x27;sections&#x27;, []))} sections&quot;)</span><span class="line">    return outline</span><span class="line"></span><span class="line"></span><span class="line"># ---------------------------------------------------------------------------</span><span class="line"># Phase B: Sections</span><span class="line"># ---------------------------------------------------------------------------</span><span class="line"></span><span class="line">SECTION_SYSTEM = textwrap.dedent(&quot;&quot;&quot;\</span><span class="line">    You are Mia, writing ONE section of a research synthesis report.</span><span class="line"></span><span class="line">    STYLE RULES:</span><span class="line">    - Intelligence-grade writing: precise, evidence-based, no filler</span><span class="line">    - Every factual claim gets [E], [I], [J], or [A] label</span><span class="line">    - Every claim gets [S#] source reference</span><span class="line">    - Include &quot;For the decision maker:&quot; callout box</span><span class="line">    - Include section confidence percentage</span><span class="line">    - Use 3-Signal Confidence: source_signal × 0.5 + consistency × 0.3 + structural × 0.2</span><span class="line">    - BANNED words: &quot;&quot;&quot; + &quot;, &quot;.join(BANNED_WORDS) + &quot;&quot;&quot;</span><span class="line">    - Write in Florian&#x27;s analytical but direct style</span><span class="line">    - No hedging, no &quot;it&#x27;s worth noting&quot;</span><span class="line">&quot;&quot;&quot;)</span><span class="line"></span><span class="line"></span><span class="line">def _build_section_prompt(</span><span class="line">    section: dict[str, Any],</span><span class="line">    outline: dict[str, Any],</span><span class="line">    previous_sections: dict[str, str],</span><span class="line">    pipeline_data: dict[str, Any],</span><span class="line">    workspace_data: dict[str, Any],</span><span class="line">) -&gt; str:</span><span class="line">    &quot;&quot;&quot;Build the prompt for generating one section.&quot;&quot;&quot;</span><span class="line">    section_id = section[&quot;id&quot;]</span><span class="line"></span><span class="line">    # RAG retrieval for this section</span><span class="line">    rag_chunks = &quot;&quot;</span><span class="line">    if USE_RAG:</span><span class="line">        try:</span><span class="line">            chunks = query_for_section(section_id, top_k=20)  # type: ignore</span><span class="line">            rag_chunks = &quot;RELEVANT CHUNKS:\n&quot; + &quot;\n---\n&quot;.join(</span><span class="line">                c.get(&quot;text&quot;, &quot;&quot;)[:400] for c in chunks[:20]</span><span class="line">            )</span><span class="line">        except Exception:</span><span class="line">            pass</span><span class="line"></span><span class="line">    # Fallback: include sub-reports relevant to assigned claims</span><span class="line">    if not rag_chunks:</span><span class="line">        sub_reports = pipeline_data.get(&quot;sub_reports&quot;, [])</span><span class="line">        combined = &quot;\n\n&quot;.join(sr[&quot;text&quot;][:2000] for sr in sub_reports[:5])</span><span class="line">        rag_chunks = f&quot;SUB-REPORT EXCERPTS:\n{combined[:8000]}&quot;</span><span class="line"></span><span class="line">    # Previous sections</span><span class="line">    prev_text = &quot;&quot;</span><span class="line">    for sid in SECTION_ORDER:</span><span class="line">        if sid in previous_sections:</span><span class="line">            prev_text += f&quot;\n\n## {sid} (already written)\n{previous_sections[sid][:3000]}&quot;</span><span class="line"></span><span class="line">    min_words = MIN_WORDS.get(section_id, 500)</span><span class="line">    claims_assigned = section.get(&quot;claim_assignments&quot;, [])</span><span class="line">    sources_assigned = section.get(&quot;source_assignments&quot;, [])</span><span class="line"></span><span class="line">    # Reference library for source details</span><span class="line">    ref_lib = workspace_data.get(&quot;reference-library&quot;, {})</span><span class="line">    ref_details = &quot;&quot;</span><span class="line">    if ref_lib and sources_assigned:</span><span class="line">        entries = ref_lib if isinstance(ref_lib, list) else ref_lib.get(&quot;sources&quot;, [])</span><span class="line">        if isinstance(entries, list):</span><span class="line">            for entry in entries:</span><span class="line">                sid_entry = entry.get(&quot;id&quot;, &quot;&quot;)</span><span class="line">                if sid_entry in sources_assigned or f&quot;S{sid_entry}&quot; in sources_assigned:</span><span class="line">                    ref_details += f&quot;\n- [{sid_entry}] {entry.get(&#x27;title&#x27;, &#x27;&#x27;)} — {entry.get(&#x27;key_finding&#x27;, &#x27;&#x27;)}&quot;</span><span class="line"></span><span class="line">    prompt = textwrap.dedent(f&quot;&quot;&quot;\</span><span class="line">        OUTLINE (contract — follow this structure):</span><span class="line">        {json.dumps(outline, indent=1)[:3000]}</span><span class="line"></span><span class="line">        {prev_text}</span><span class="line"></span><span class="line">        {rag_chunks}</span><span class="line"></span><span class="line">        REFERENCE DETAILS:</span><span class="line">        {ref_details[:2000]}</span><span class="line"></span><span class="line">        CLAIMS ASSIGNED TO THIS SECTION: {&#x27;, &#x27;.join(claims_assigned)}</span><span class="line">        SOURCES ASSIGNED TO THIS SECTION: {&#x27;, &#x27;.join(sources_assigned)}</span><span class="line"></span><span class="line">        Write ONLY section &quot;{section_id}&quot; ({section.get(&#x27;title&#x27;, section_id)}).</span><span class="line">        MINIMUM {min_words} words.</span><span class="line">        Include ALL assigned claims with [E]/[I]/[J]/[A] labels and [S#] references.</span><span class="line">        Include &quot;For the decision maker:&quot; callout.</span><span class="line">        Include section confidence percentage.</span><span class="line">    &quot;&quot;&quot;)</span><span class="line"></span><span class="line">    return prompt</span><span class="line"></span><span class="line"></span><span class="line">def _validate_section(</span><span class="line">    text: str,</span><span class="line">    section: dict[str, Any],</span><span class="line">) -&gt; list[str]:</span><span class="line">    &quot;&quot;&quot;Validate a generated section. Returns list of issues.&quot;&quot;&quot;</span><span class="line">    issues: list[str] = []</span><span class="line">    section_id = section[&quot;id&quot;]</span><span class="line">    min_words = MIN_WORDS.get(section_id, 500)</span><span class="line"></span><span class="line">    word_count = len(text.split())</span><span class="line">    if word_count &lt; min_words:</span><span class="line">        issues.append(f&quot;word_count:{word_count}&lt;{min_words}&quot;)</span><span class="line"></span><span class="line">    # Check assigned claims present</span><span class="line">    for cl in section.get(&quot;claim_assignments&quot;, []):</span><span class="line">        if cl not in text:</span><span class="line">            issues.append(f&quot;missing_claim:{cl}&quot;)</span><span class="line"></span><span class="line">    # Check assigned sources present</span><span class="line">    for src in section.get(&quot;source_assignments&quot;, []):</span><span class="line">        # Check both [S1] and S1 formats</span><span class="line">        if f&quot;[{src}]&quot; not in text and f&quot;[S{src}]&quot; not in text and src not in text:</span><span class="line">            issues.append(f&quot;missing_source:{src}&quot;)</span><span class="line"></span><span class="line">    # Banned words</span><span class="line">    text_lower = text.lower()</span><span class="line">    for bw in BANNED_WORDS:</span><span class="line">        if bw.lower() in text_lower:</span><span class="line">            issues.append(f&quot;banned_word:{bw}&quot;)</span><span class="line"></span><span class="line">    # Decision maker callout</span><span class="line">    if &quot;for the decision maker&quot; not in text_lower:</span><span class="line">        issues.append(&quot;missing:decision_maker_callout&quot;)</span><span class="line"></span><span class="line">    # Confidence percentage</span><span class="line">    if not re.search(r&quot;\d+%&quot;, text):</span><span class="line">        issues.append(&quot;missing:confidence_percentage&quot;)</span><span class="line"></span><span class="line">    return issues</span><span class="line"></span><span class="line"></span><span class="line">def phase_b_sections(</span><span class="line">    outline: dict[str, Any],</span><span class="line">    pipeline_data: dict[str, Any],</span><span class="line">    workspace_data: dict[str, Any],</span><span class="line">    output_dir: Path,</span><span class="line">    dry_run: bool = False,</span><span class="line">) -&gt; dict[str, str]:</span><span class="line">    &quot;&quot;&quot;Phase B: Generate all 7 sections sequentially.&quot;&quot;&quot;</span><span class="line">    t0 = time.time()</span><span class="line">    print(&quot;\n[PHASE B] Generating Sections&quot;)</span><span class="line"></span><span class="line">    sections_done: dict[str, str] = {}</span><span class="line"></span><span class="line">    for i, section in enumerate(outline.get(&quot;sections&quot;, [])):</span><span class="line">        section_id = section[&quot;id&quot;]</span><span class="line">        st = time.time()</span><span class="line">        print(f&quot;\n  [{i + 1}/7] Section: {section_id}&quot;)</span><span class="line"></span><span class="line">        prompt = _build_section_prompt(</span><span class="line">            section, outline, sections_done, pipeline_data, workspace_data</span><span class="line">        )</span><span class="line"></span><span class="line">        if dry_run:</span><span class="line">            print(f&quot;    [DRY RUN] Prompt: {len(prompt)} chars&quot;)</span><span class="line">            sections_done[section_id] = f&quot;[DRY RUN] {section_id} content placeholder\n\nFor the decision maker: this is a dry run.\n\nConfidence: 50%&quot;</span><span class="line">            out_path = output_dir / f&quot;section-{i + 1}-{section_id}.md&quot;</span><span class="line">            out_path.write_text(sections_done[section_id])</span><span class="line">            continue</span><span class="line"></span><span class="line">        text = call_opus(prompt, system=SECTION_SYSTEM, max_tokens=4096)</span><span class="line"></span><span class="line">        # Validate</span><span class="line">        issues = _validate_section(text, section)</span><span class="line">        word_issues = [x for x in issues if x.startswith(&quot;word_count:&quot;)]</span><span class="line">        claim_source_issues = [x for x in issues if x.startswith(&quot;missing_claim:&quot;) or x.startswith(&quot;missing_source:&quot;)]</span><span class="line"></span><span class="line">        # Retry once for word count</span><span class="line">        if word_issues:</span><span class="line">            wc = len(text.split())</span><span class="line">            min_w = MIN_WORDS.get(section_id, 500)</span><span class="line">            print(f&quot;    RETRY: word count {wc} &lt; {min_w}&quot;)</span><span class="line">            text = call_opus(</span><span class="line">                prompt + f&quot;\n\nYour output was {wc} words. Write at least {min_w} words. Be thorough.&quot;,</span><span class="line">                system=SECTION_SYSTEM, max_tokens=6000,</span><span class="line">            )</span><span class="line">            issues = _validate_section(text, section)</span><span class="line"></span><span class="line">        # Retry once for missing claims/sources</span><span class="line">        elif claim_source_issues:</span><span class="line">            missing = &quot;, &quot;.join(claim_source_issues)</span><span class="line">            print(f&quot;    RETRY: {missing}&quot;)</span><span class="line">            text = call_opus(</span><span class="line">                prompt + f&quot;\n\nYou missed: {missing}. Include ALL assigned claims and sources.&quot;,</span><span class="line">                system=SECTION_SYSTEM, max_tokens=5000,</span><span class="line">            )</span><span class="line">            issues = _validate_section(text, section)</span><span class="line"></span><span class="line">        if issues:</span><span class="line">            print(f&quot;    WARNINGS: {issues}&quot;)</span><span class="line"></span><span class="line">        sections_done[section_id] = text</span><span class="line"></span><span class="line">        # Save individual section</span><span class="line">        out_path = output_dir / f&quot;section-{i + 1}-{section_id}.md&quot;</span><span class="line">        out_path.write_text(text)</span><span class="line"></span><span class="line">        elapsed_s = time.time() - st</span><span class="line">        print(f&quot;    Done ({len(text.split())} words, {elapsed_s:.0f}s)&quot;)</span><span class="line"></span><span class="line">    elapsed = time.time() - t0</span><span class="line">    print(f&quot;\n[PHASE B] Done in {elapsed:.1f}s — {len(sections_done)} sections&quot;)</span><span class="line">    return sections_done</span><span class="line"></span><span class="line"></span><span class="line"># ---------------------------------------------------------------------------</span><span class="line"># Phase C: Merge</span><span class="line"># ---------------------------------------------------------------------------</span><span class="line"></span><span class="line">def _build_source_log(</span><span class="line">    report_text: str,</span><span class="line">    ref_library: Any,</span><span class="line">) -&gt; str:</span><span class="line">    &quot;&quot;&quot;Auto-generate Source Log from referenced [S#] tags.&quot;&quot;&quot;</span><span class="line">    # Find all [S##] in report</span><span class="line">    refs_in_report = sorted(set(int(x) for x in re.findall(r&quot;\[S(\d+)\]&quot;, report_text)))</span><span class="line">    if not refs_in_report:</span><span class="line">        return &quot;\n## Source Log\n\n_No source references found._\n&quot;</span><span class="line"></span><span class="line">    # Build lookup from reference library</span><span class="line">    lookup: dict[int, dict[str, Any]] = {}</span><span class="line">    entries = []</span><span class="line">    if isinstance(ref_library, list):</span><span class="line">        entries = ref_library</span><span class="line">    elif isinstance(ref_library, dict):</span><span class="line">        entries = ref_library.get(&quot;sources&quot;, ref_library.get(&quot;entries&quot;, []))</span><span class="line">        if isinstance(entries, dict):</span><span class="line">            entries = list(entries.values())</span><span class="line"></span><span class="line">    for entry in entries:</span><span class="line">        sid = entry.get(&quot;id&quot;, &quot;&quot;)</span><span class="line">        # Extract numeric id</span><span class="line">        m = re.search(r&quot;(\d+)&quot;, str(sid))</span><span class="line">        if m:</span><span class="line">            lookup[int(m.group(1))] = entry</span><span class="line"></span><span class="line">    lines = [&quot;## Source Log\n&quot;]</span><span class="line">    lines.append(&quot;| ID | Title | Venue | DOI | Key Finding | Tier |&quot;)</span><span class="line">    lines.append(&quot;|---|---|---|---|---|---|&quot;)</span><span class="line"></span><span class="line">    for sid in refs_in_report:</span><span class="line">        entry = lookup.get(sid, {})</span><span class="line">        title = entry.get(&quot;title&quot;, &quot;Unknown&quot;)</span><span class="line">        venue = entry.get(&quot;venue&quot;, entry.get(&quot;journal&quot;, &quot;—&quot;))</span><span class="line">        doi = entry.get(&quot;doi&quot;, &quot;—&quot;)</span><span class="line">        finding = entry.get(&quot;key_finding&quot;, entry.get(&quot;finding&quot;, &quot;—&quot;))</span><span class="line">        tier = entry.get(&quot;tier&quot;, entry.get(&quot;quality&quot;, &quot;—&quot;))</span><span class="line">        lines.append(f&quot;| [S{sid}] | {title} | {venue} | {doi} | {finding[:80]} | {tier} |&quot;)</span><span class="line"></span><span class="line">    return &quot;\n&quot;.join(lines) + &quot;\n&quot;</span><span class="line"></span><span class="line"></span><span class="line">def _build_contradiction_register(contradictions: Any) -&gt; str:</span><span class="line">    &quot;&quot;&quot;Auto-generate Contradiction Register.&quot;&quot;&quot;</span><span class="line">    if not contradictions:</span><span class="line">        return &quot;\n## Contradiction Register\n\n_No contradictions detected._\n&quot;</span><span class="line"></span><span class="line">    entries = []</span><span class="line">    if isinstance(contradictions, list):</span><span class="line">        entries = contradictions</span><span class="line">    elif isinstance(contradictions, dict):</span><span class="line">        entries = contradictions.get(&quot;contradictions&quot;, [])</span><span class="line"></span><span class="line">    lines = [&quot;## Contradiction Register\n&quot;]</span><span class="line">    for i, c in enumerate(entries, 1):</span><span class="line">        claim_a = c.get(&quot;claim_a&quot;, c.get(&quot;side_a&quot;, &quot;?&quot;))</span><span class="line">        claim_b = c.get(&quot;claim_b&quot;, c.get(&quot;side_b&quot;, &quot;?&quot;))</span><span class="line">        resolution = c.get(&quot;resolution&quot;, c.get(&quot;assessment&quot;, &quot;unresolved&quot;))</span><span class="line">        lines.append(f&quot;**C-{i:02d}:** {claim_a} vs. {claim_b}&quot;)</span><span class="line">        lines.append(f&quot;  Resolution: {resolution}\n&quot;)</span><span class="line"></span><span class="line">    return &quot;\n&quot;.join(lines) + &quot;\n&quot;</span><span class="line"></span><span class="line"></span><span class="line">def phase_c_merge(</span><span class="line">    sections: dict[str, str],</span><span class="line">    outline: dict[str, Any],</span><span class="line">    pipeline_data: dict[str, Any],</span><span class="line">    workspace_data: dict[str, Any],</span><span class="line">) -&gt; str:</span><span class="line">    &quot;&quot;&quot;Phase C: Merge sections into final report.&quot;&quot;&quot;</span><span class="line">    t0 = time.time()</span><span class="line">    print(&quot;\n[PHASE C] Merge&quot;)</span><span class="line"></span><span class="line">    parts: list[str] = []</span><span class="line"></span><span class="line">    # Title</span><span class="line">    title = outline.get(&quot;title&quot;, &quot;Research Synthesis Report&quot;)</span><span class="line">    version = outline.get(&quot;version&quot;, &quot;v1&quot;)</span><span class="line">    parts.append(f&quot;# {title}\n**Version:** {version} | **Generated:** {datetime.now(timezone.utc).strftime(&#x27;%Y-%m-%d %H:%M UTC&#x27;)}\n&quot;)</span><span class="line"></span><span class="line">    # Sections in order</span><span class="line">    for section_def in outline.get(&quot;sections&quot;, []):</span><span class="line">        sid = section_def[&quot;id&quot;]</span><span class="line">        section_title = section_def.get(&quot;title&quot;, sid)</span><span class="line">        content = sections.get(sid, f&quot;_Section {sid} not generated._&quot;)</span><span class="line">        parts.append(f&quot;## {section_title}\n\n{content}&quot;)</span><span class="line"></span><span class="line">    report = &quot;\n\n---\n\n&quot;.join(parts)</span><span class="line"></span><span class="line">    # Source Log</span><span class="line">    ref_lib = workspace_data.get(&quot;reference-library&quot;, {})</span><span class="line">    source_log = _build_source_log(report, ref_lib)</span><span class="line">    report += &quot;\n\n---\n\n&quot; + source_log</span><span class="line"></span><span class="line">    # Contradiction Register</span><span class="line">    contras = pipeline_data.get(&quot;contradictions.json&quot;, {})</span><span class="line">    contra_reg = _build_contradiction_register(contras)</span><span class="line">    report += &quot;\n\n&quot; + contra_reg</span><span class="line"></span><span class="line">    elapsed = time.time() - t0</span><span class="line">    print(f&quot;[PHASE C] Done in {elapsed:.1f}s — {len(report)} chars, {len(report.split())} words&quot;)</span><span class="line">    return report</span><span class="line"></span><span class="line"></span><span class="line"># ---------------------------------------------------------------------------</span><span class="line"># Phase D: Validate</span><span class="line"># ---------------------------------------------------------------------------</span><span class="line"></span><span class="line">def _count_eija(text: str) -&gt; dict[str, int]:</span><span class="line">    &quot;&quot;&quot;Count E/I/J/A labels in text (multiple formats).&quot;&quot;&quot;</span><span class="line">    counts: dict[str, int] = {&quot;E&quot;: 0, &quot;I&quot;: 0, &quot;J&quot;: 0, &quot;A&quot;: 0}</span><span class="line">    # [E], [I], [J], [A]</span><span class="line">    for label in counts:</span><span class="line">        counts[label] += len(re.findall(rf&quot;\[{label}\]&quot;, text))</span><span class="line">    # | E |, |E| in tables</span><span class="line">    for label in counts:</span><span class="line">        counts[label] += len(re.findall(rf&quot;\|\s*{label}\s*\|&quot;, text))</span><span class="line">    return counts</span><span class="line"></span><span class="line"></span><span class="line">def _compute_claim_confidence(claim: dict[str, Any]) -&gt; float:</span><span class="line">    &quot;&quot;&quot;Compute 3-signal confidence for a claim.</span><span class="line">    </span><span class="line">    Uses agenttrust library if available, falls back to inline formula.</span><span class="line">    &quot;&quot;&quot;</span><span class="line">    admiralty = claim.get(&quot;admiralty&quot;, &quot;C3&quot;)</span><span class="line">    label = claim.get(&quot;label&quot;, &quot;&quot;)</span><span class="line">    text = claim.get(&quot;raw&quot;, &quot;&quot;) + &quot; &quot; + claim.get(&quot;text&quot;, &quot;&quot;)</span><span class="line"></span><span class="line">    if USE_AGENTTRUST:</span><span class="line">        result = _at_confidence(</span><span class="line">            claim=text,</span><span class="line">            admiralty=admiralty,</span><span class="line">            has_doi=&quot;doi&quot; in text.lower() or &quot;10.&quot; in text,</span><span class="line">            has_url=&quot;http&quot; in text,</span><span class="line">            has_percentage=&quot;%&quot; in text,</span><span class="line">            has_year=bool(re.search(r&quot;20[12]\d&quot;, text)),</span><span class="line">            has_source_ref=bool(re.search(r&quot;\[S\d+\]&quot;, text)),</span><span class="line">        )</span><span class="line">        return result.confidence_pct / 100.0  # normalize to 0-1</span><span class="line"></span><span class="line">    # Fallback: inline 3-signal formula</span><span class="line">    source_signal = ADMIRALTY_MAP.get(admiralty, 0.40)</span><span class="line">    consistency = EIJA_WEIGHTS.get(label, 0.40)</span><span class="line"></span><span class="line">    structural = 0.0</span><span class="line">    if &quot;doi&quot; in text.lower() or &quot;10.&quot; in text:</span><span class="line">        structural += 0.30</span><span class="line">    if &quot;http&quot; in text:</span><span class="line">        structural += 0.15</span><span class="line">    if &quot;%&quot; in text:</span><span class="line">        structural += 0.10</span><span class="line">    if re.search(r&quot;20[12]\d&quot;, text):</span><span class="line">        structural += 0.05</span><span class="line">    if re.search(r&quot;\[S\d+\]&quot;, text):</span><span class="line">        structural += 0.10</span><span class="line">    structural = min(structural, 0.50)</span><span class="line"></span><span class="line">    return 0.5 * source_signal + 0.3 * consistency + 0.2 * structural</span><span class="line"></span><span class="line"></span><span class="line">def _compute_report_confidence(claims: list[dict[str, Any]]) -&gt; float:</span><span class="line">    &quot;&quot;&quot;Weighted average confidence across claims.&quot;&quot;&quot;</span><span class="line">    if not claims:</span><span class="line">        return 0.50</span><span class="line"></span><span class="line">    label_weight = {&quot;E&quot;: 4.0, &quot;I&quot;: 3.0, &quot;J&quot;: 1.5, &quot;A&quot;: 1.0}</span><span class="line">    total_w = 0.0</span><span class="line">    total_conf = 0.0</span><span class="line">    for c in claims:</span><span class="line">        w = label_weight.get(c.get(&quot;label&quot;, &quot;&quot;), 1.0)</span><span class="line">        conf = _compute_claim_confidence(c)</span><span class="line">        c[&quot;computed_confidence&quot;] = round(conf, 3)</span><span class="line">        total_w += w</span><span class="line">        total_conf += w * conf</span><span class="line"></span><span class="line">    return round(total_conf / total_w, 3) if total_w &gt; 0 else 0.50</span><span class="line"></span><span class="line"></span><span class="line">def _find_source_orphans(report: str, source_log: str) -&gt; tuple[list[str], list[str]]:</span><span class="line">    &quot;&quot;&quot;Find orphan sources: in prose but not log, in log but not prose.&quot;&quot;&quot;</span><span class="line">    # Split report to get prose (everything before Source Log)</span><span class="line">    parts = report.split(&quot;## Source Log&quot;)</span><span class="line">    prose = parts[0] if parts else report</span><span class="line">    log_section = parts[1] if len(parts) &gt; 1 else source_log</span><span class="line"></span><span class="line">    refs_in_prose = set(re.findall(r&quot;\[S(\d+)\]&quot;, prose))</span><span class="line">    refs_in_log = set(re.findall(r&quot;\[S(\d+)\]&quot;, log_section))</span><span class="line"></span><span class="line">    orphan_refs = sorted(refs_in_prose - refs_in_log)  # in prose, not in log</span><span class="line">    orphan_sources = sorted(refs_in_log - refs_in_prose)  # in log, not in prose</span><span class="line">    return [f&quot;S{r}&quot; for r in orphan_refs], [f&quot;S{r}&quot; for r in orphan_sources]</span><span class="line"></span><span class="line"></span><span class="line">def _check_cross_references(report: str) -&gt; list[str]:</span><span class="line">    &quot;&quot;&quot;Check cross-references between sections.&quot;&quot;&quot;</span><span class="line">    warnings: list[str] = []</span><span class="line"></span><span class="line">    # &quot;If you read nothing else&quot; bullets should reference Key Findings</span><span class="line">    exec_section = &quot;&quot;</span><span class="line">    m = re.search(r&quot;(?i)executive.summary.*?(?=\n##|\Z)&quot;, report, re.DOTALL)</span><span class="line">    if m:</span><span class="line">        exec_section = m.group()</span><span class="line"></span><span class="line">    if &quot;if you read nothing else&quot; in exec_section.lower():</span><span class="line">        # Check for KF references</span><span class="line">        kf_refs = re.findall(r&quot;(?:Key Finding|KF|Finding)\s*#?\d+&quot;, exec_section, re.IGNORECASE)</span><span class="line">        if not kf_refs:</span><span class="line">            warnings.append(&quot;Executive summary &#x27;read nothing else&#x27; doesn&#x27;t reference Key Findings&quot;)</span><span class="line"></span><span class="line">    return warnings</span><span class="line"></span><span class="line"></span><span class="line">def _check_grounding(report: str, sub_reports: list[dict[str, str]]) -&gt; list[str]:</span><span class="line">    &quot;&quot;&quot;Check that all [S#] in report were in sub-reports.&quot;&quot;&quot;</span><span class="line">    report_refs = set(re.findall(r&quot;\[S(\d+)\]&quot;, report))</span><span class="line"></span><span class="line">    sub_refs: set[str] = set()</span><span class="line">    for sr in sub_reports:</span><span class="line">        sub_refs.update(re.findall(r&quot;\[S(\d+)\]&quot;, sr.get(&quot;text&quot;, &quot;&quot;)))</span><span class="line"></span><span class="line">    ungrounded = sorted(report_refs - sub_refs)</span><span class="line">    return [f&quot;S{r}&quot; for r in ungrounded]</span><span class="line"></span><span class="line"></span><span class="line">def _check_number_consistency(report: str) -&gt; list[str]:</span><span class="line">    &quot;&quot;&quot;Check for inconsistent numbers across sections.&quot;&quot;&quot;</span><span class="line">    warnings: list[str] = []</span><span class="line"></span><span class="line">    # Split into sections</span><span class="line">    section_splits = re.split(r&quot;\n##\s+&quot;, report)</span><span class="line"></span><span class="line">    # Extract numbers with context</span><span class="line">    number_occurrences: dict[str, list[str]] = {}</span><span class="line">    for section in section_splits:</span><span class="line">        section_name = section[:50].strip().split(&quot;\n&quot;)[0]</span><span class="line">        # Find percentages, dollar amounts</span><span class="line">        for m in re.finditer(r&quot;(\d+(?:\.\d+)?)\s*%&quot;, section):</span><span class="line">            key = f&quot;{m.group(1)}%&quot;</span><span class="line">            number_occurrences.setdefault(key, []).append(section_name)</span><span class="line">        for m in re.finditer(r&quot;\$\s*([\d,.]+(?:\.\d+)?)\s*(billion|million|B|M|trillion|T)?&quot;, section, re.IGNORECASE):</span><span class="line">            key = f&quot;${m.group(1)}{m.group(2) or &#x27;&#x27;}&quot;</span><span class="line">            number_occurrences.setdefault(key, []).append(section_name)</span><span class="line"></span><span class="line">    # Numbers appearing in multiple sections are fine (consistent)</span><span class="line">    # We&#x27;d need value extraction to detect mismatches — for now just report multi-section numbers</span><span class="line">    # This is a structural check, not a value mismatch detector</span><span class="line">    return warnings</span><span class="line"></span><span class="line"></span><span class="line">def phase_d_validate(</span><span class="line">    report: str,</span><span class="line">    pipeline_data: dict[str, Any],</span><span class="line">    workspace_data: dict[str, Any],</span><span class="line">) -&gt; dict[str, Any]:</span><span class="line">    &quot;&quot;&quot;Phase D: Validate the merged report.&quot;&quot;&quot;</span><span class="line">    t0 = time.time()</span><span class="line">    print(&quot;\n[PHASE D] Validate&quot;)</span><span class="line"></span><span class="line">    results: dict[str, Any] = {&quot;checks&quot;: {}, &quot;warnings&quot;: [], &quot;grade_inputs&quot;: {}}</span><span class="line"></span><span class="line">    # 1. E/I/J/A counts</span><span class="line">    eija = _count_eija(report)</span><span class="line">    total_eija = sum(eija.values())</span><span class="line">    results[&quot;checks&quot;][&quot;eija_counts&quot;] = eija</span><span class="line">    results[&quot;checks&quot;][&quot;eija_total&quot;] = total_eija</span><span class="line">    if total_eija &gt; 0:</span><span class="line">        results[&quot;checks&quot;][&quot;e_pct&quot;] = round(100 * eija[&quot;E&quot;] / total_eija, 1)</span><span class="line">        results[&quot;checks&quot;][&quot;j_pct&quot;] = round(100 * eija[&quot;J&quot;] / total_eija, 1)</span><span class="line">    else:</span><span class="line">        results[&quot;checks&quot;][&quot;e_pct&quot;] = 0</span><span class="line">        results[&quot;checks&quot;][&quot;j_pct&quot;] = 0</span><span class="line">    print(f&quot;  E/I/J/A: {eija} (total: {total_eija})&quot;)</span><span class="line"></span><span class="line">    # 2. Claim confidence</span><span class="line">    claims = parse_claim_ledger(report)</span><span class="line">    report_confidence = _compute_report_confidence(claims)</span><span class="line">    results[&quot;checks&quot;][&quot;claims_parsed&quot;] = len(claims)</span><span class="line">    results[&quot;checks&quot;][&quot;report_confidence&quot;] = report_confidence</span><span class="line">    results[&quot;checks&quot;][&quot;per_claim&quot;] = [</span><span class="line">        {&quot;id&quot;: c[&quot;id&quot;], &quot;label&quot;: c[&quot;label&quot;], &quot;confidence&quot;: c.get(&quot;computed_confidence&quot;, 0)}</span><span class="line">        for c in claims</span><span class="line">    ]</span><span class="line">    print(f&quot;  Claims: {len(claims)}, Report confidence: {report_confidence}&quot;)</span><span class="line"></span><span class="line">    # 3. Beipackzettel correction</span><span class="line">    risk_level = &quot;HIGH&quot; if report_confidence &lt; 0.60 else &quot;MEDIUM&quot; if report_confidence &lt;= 0.80 else &quot;LOW&quot;</span><span class="line">    results[&quot;checks&quot;][&quot;risk_level&quot;] = risk_level</span><span class="line">    results[&quot;checks&quot;][&quot;beipackzettel_corrected&quot;] = True</span><span class="line">    print(f&quot;  Risk level: {risk_level}&quot;)</span><span class="line"></span><span class="line">    # 4. Source orphan check</span><span class="line">    orphan_refs, orphan_sources = _find_source_orphans(report, &quot;&quot;)</span><span class="line">    results[&quot;checks&quot;][&quot;orphan_refs&quot;] = orphan_refs</span><span class="line">    results[&quot;checks&quot;][&quot;orphan_sources&quot;] = orphan_sources</span><span class="line">    if orphan_refs:</span><span class="line">        results[&quot;warnings&quot;].append(f&quot;Sources in prose but not in Source Log: {orphan_refs}&quot;)</span><span class="line">    if orphan_sources:</span><span class="line">        results[&quot;warnings&quot;].append(f&quot;Sources in Source Log but not in prose: {orphan_sources}&quot;)</span><span class="line">    print(f&quot;  Orphan refs: {len(orphan_refs)}, Orphan sources: {len(orphan_sources)}&quot;)</span><span class="line"></span><span class="line">    # 5. Cross-reference check</span><span class="line">    xref_warnings = _check_cross_references(report)</span><span class="line">    results[&quot;checks&quot;][&quot;cross_ref_warnings&quot;] = xref_warnings</span><span class="line">    results[&quot;warnings&quot;].extend(xref_warnings)</span><span class="line">    print(f&quot;  Cross-ref warnings: {len(xref_warnings)}&quot;)</span><span class="line"></span><span class="line">    # 6. Grounding check</span><span class="line">    sub_reports = pipeline_data.get(&quot;sub_reports&quot;, [])</span><span class="line">    ungrounded = _check_grounding(report, sub_reports)</span><span class="line">    results[&quot;checks&quot;][&quot;ungrounded_sources&quot;] = ungrounded</span><span class="line">    if ungrounded:</span><span class="line">        results[&quot;warnings&quot;].append(f&quot;Ungrounded sources (not in sub-reports): {ungrounded}&quot;)</span><span class="line">    print(f&quot;  Ungrounded sources: {len(ungrounded)}&quot;)</span><span class="line"></span><span class="line">    # 7. Consistency check</span><span class="line">    consistency_warnings = _check_number_consistency(report)</span><span class="line">    results[&quot;checks&quot;][&quot;consistency_mismatches&quot;] = len(consistency_warnings)</span><span class="line">    results[&quot;warnings&quot;].extend(consistency_warnings)</span><span class="line">    print(f&quot;  Consistency mismatches: {len(consistency_warnings)}&quot;)</span><span class="line"></span><span class="line">    # Section count</span><span class="line">    blocks = len(re.findall(r&quot;^## &quot;, report, re.MULTILINE))</span><span class="line">    results[&quot;checks&quot;][&quot;blocks&quot;] = blocks</span><span class="line"></span><span class="line">    # Store grade inputs</span><span class="line">    results[&quot;grade_inputs&quot;] = {</span><span class="line">        &quot;blocks&quot;: blocks,</span><span class="line">        &quot;e_pct&quot;: results[&quot;checks&quot;][&quot;e_pct&quot;],</span><span class="line">        &quot;j_pct&quot;: results[&quot;checks&quot;][&quot;j_pct&quot;],</span><span class="line">        &quot;orphan_refs&quot;: len(orphan_refs),</span><span class="line">        &quot;orphan_sources&quot;: len(orphan_sources),</span><span class="line">        &quot;claims&quot;: len(claims),</span><span class="line">        &quot;confidence&quot;: report_confidence,</span><span class="line">        &quot;consistency_mismatches&quot;: len(consistency_warnings),</span><span class="line">        &quot;ungrounded_sources&quot;: len(ungrounded),</span><span class="line">    }</span><span class="line"></span><span class="line">    elapsed = time.time() - t0</span><span class="line">    print(f&quot;[PHASE D] Done in {elapsed:.1f}s — {len(results[&#x27;warnings&#x27;])} warnings&quot;)</span><span class="line">    return results</span><span class="line"></span><span class="line"></span><span class="line">def correct_beipackzettel(</span><span class="line">    report: str,</span><span class="line">    confidence: float,</span><span class="line">    eija: dict[str, int],</span><span class="line">    risk_level: str,</span><span class="line">) -&gt; str:</span><span class="line">    &quot;&quot;&quot;Correct the Beipackzettel section with Python-calculated values.&quot;&quot;&quot;</span><span class="line">    # Find and replace confidence line</span><span class="line">    report = re.sub(</span><span class="line">        r&quot;(?i)(confidence[:\s]*)\d+(\.\d+)?%&quot;,</span><span class="line">        f&quot;\\g&lt;1&gt;{confidence * 100:.1f}%&quot;,</span><span class="line">        report,</span><span class="line">        count=1,</span><span class="line">    )</span><span class="line"></span><span class="line">    # Replace E/I/J/A line</span><span class="line">    eija_line = f&quot;E: {eija[&#x27;E&#x27;]} | I: {eija[&#x27;I&#x27;]} | J: {eija[&#x27;J&#x27;]} | A: {eija[&#x27;A&#x27;]}&quot;</span><span class="line">    report = re.sub(</span><span class="line">        r&quot;(?i)E:\s*\d+\s*\|\s*I:\s*\d+\s*\|\s*J:\s*\d+\s*\|\s*A:\s*\d+&quot;,</span><span class="line">        eija_line,</span><span class="line">        report,</span><span class="line">    )</span><span class="line"></span><span class="line">    # Replace risk level</span><span class="line">    report = re.sub(</span><span class="line">        r&quot;(?i)(risk\s*level[:\s]*)(HIGH|MEDIUM|LOW)&quot;,</span><span class="line">        f&quot;\\g&lt;1&gt;{risk_level}&quot;,</span><span class="line">        report,</span><span class="line">    )</span><span class="line"></span><span class="line">    return report</span><span class="line"></span><span class="line"></span><span class="line"># ---------------------------------------------------------------------------</span><span class="line"># Phase E: Grade + Output</span><span class="line"># ---------------------------------------------------------------------------</span><span class="line"></span><span class="line">def phase_e_output(</span><span class="line">    report: str,</span><span class="line">    validation: dict[str, Any],</span><span class="line">    output_dir: Path,</span><span class="line">    version: str,</span><span class="line">) -&gt; str:</span><span class="line">    &quot;&quot;&quot;Phase E: Grade and write output files.&quot;&quot;&quot;</span><span class="line">    t0 = time.time()</span><span class="line">    print(&quot;\n[PHASE E] Grade + Output&quot;)</span><span class="line"></span><span class="line">    gi = validation[&quot;grade_inputs&quot;]</span><span class="line"></span><span class="line">    # Correct beipackzettel</span><span class="line">    report = correct_beipackzettel(</span><span class="line">        report,</span><span class="line">        gi[&quot;confidence&quot;],</span><span class="line">        validation[&quot;checks&quot;][&quot;eija_counts&quot;],</span><span class="line">        validation[&quot;checks&quot;][&quot;risk_level&quot;],</span><span class="line">    )</span><span class="line"></span><span class="line">    # Grade</span><span class="line">    if (</span><span class="line">        gi[&quot;blocks&quot;] &gt;= 7</span><span class="line">        and gi[&quot;e_pct&quot;] &gt; 50</span><span class="line">        and gi[&quot;j_pct&quot;] &lt; 20</span><span class="line">        and gi[&quot;orphan_refs&quot;] == 0</span><span class="line">        and gi[&quot;orphan_sources&quot;] == 0</span><span class="line">        and gi[&quot;claims&quot;] &gt;= 12</span><span class="line">        and gi[&quot;confidence&quot;] != 0.50</span><span class="line">        and gi[&quot;consistency_mismatches&quot;] == 0</span><span class="line">        and gi[&quot;ungrounded_sources&quot;] == 0</span><span class="line">    ):</span><span class="line">        grade = &quot;A+++&quot;</span><span class="line">    elif gi[&quot;blocks&quot;] &gt;= 7 and gi[&quot;e_pct&quot;] &gt; 50 and gi[&quot;j_pct&quot;] &lt; 20:</span><span class="line">        grade = &quot;A++&quot;</span><span class="line">    elif gi[&quot;blocks&quot;] &gt;= 5 and gi[&quot;e_pct&quot;] &gt; 40:</span><span class="line">        grade = &quot;A+&quot;</span><span class="line">    else:</span><span class="line">        grade = &quot;B&quot;</span><span class="line"></span><span class="line">    print(f&quot;  Grade: {grade}&quot;)</span><span class="line"></span><span class="line">    # 1. Final report</span><span class="line">    report_path = output_dir / f&quot;final-report-{version}.md&quot;</span><span class="line">    report_path.write_text(report)</span><span class="line">    print(f&quot;  Wrote {report_path} ({len(report)} chars)&quot;)</span><span class="line"></span><span class="line">    # 2. Validation report</span><span class="line">    validation[&quot;grade&quot;] = grade</span><span class="line">    validation[&quot;version&quot;] = version</span><span class="line">    validation[&quot;timestamp&quot;] = datetime.now(timezone.utc).isoformat()</span><span class="line">    val_path = output_dir / &quot;validation-report.json&quot;</span><span class="line">    val_path.write_text(json.dumps(validation, indent=2, default=str))</span><span class="line">    print(f&quot;  Wrote {val_path}&quot;)</span><span class="line"></span><span class="line">    # 3. Beipackzettel JSON (agenttrust compatible)</span><span class="line">    if USE_AGENTTRUST:</span><span class="line">        bpz = _AT_Beipackzettel(</span><span class="line">            confidence=gi[&quot;confidence&quot;] * 100 if gi[&quot;confidence&quot;] &lt;= 1 else gi[&quot;confidence&quot;],</span><span class="line">            sources=[f&quot;[{s}]&quot; for s in gi.get(&quot;sources_used&quot;, [])],</span><span class="line">            uncertainties=validation.get(&quot;blindspots&quot;, []),</span><span class="line">            risks=[w for w in validation.get(&quot;warnings&quot;, []) if &quot;orphan&quot; in w.lower() or &quot;ungrounded&quot; in w.lower()],</span><span class="line">            not_checked=gi.get(&quot;not_checked&quot;, [&quot;Cross-domain generalization of ECE figures&quot;, &quot;Competitor product roadmaps&quot;]),</span><span class="line">            model=&quot;claude-opus-4-20250514&quot;,</span><span class="line">            agent_id=&quot;mia-pipeline-v3&quot;,</span><span class="line">        )</span><span class="line">        beipackzettel = bpz.to_dict()</span><span class="line">        beipackzettel[&quot;eija_counts&quot;] = validation[&quot;checks&quot;][&quot;eija_counts&quot;]</span><span class="line">        beipackzettel[&quot;claims_count&quot;] = gi[&quot;claims&quot;]</span><span class="line">        beipackzettel[&quot;grade&quot;] = grade</span><span class="line">        beipackzettel[&quot;report_version&quot;] = version</span><span class="line">        beipackzettel[&quot;generated&quot;] = datetime.now(timezone.utc).isoformat()</span><span class="line">    else:</span><span class="line">        beipackzettel = {</span><span class="line">            &quot;report_version&quot;: version,</span><span class="line">            &quot;confidence&quot;: gi[&quot;confidence&quot;],</span><span class="line">            &quot;risk_level&quot;: validation[&quot;checks&quot;][&quot;risk_level&quot;],</span><span class="line">            &quot;eija_counts&quot;: validation[&quot;checks&quot;][&quot;eija_counts&quot;],</span><span class="line">            &quot;claims_count&quot;: gi[&quot;claims&quot;],</span><span class="line">            &quot;grade&quot;: grade,</span><span class="line">            &quot;orphan_refs&quot;: gi[&quot;orphan_refs&quot;],</span><span class="line">            &quot;orphan_sources&quot;: gi[&quot;orphan_sources&quot;],</span><span class="line">            &quot;ungrounded_sources&quot;: gi[&quot;ungrounded_sources&quot;],</span><span class="line">            &quot;warnings&quot;: validation[&quot;warnings&quot;],</span><span class="line">            &quot;generated&quot;: datetime.now(timezone.utc).isoformat(),</span><span class="line">        }</span><span class="line">    bp_path = output_dir / &quot;beipackzettel.json&quot;</span><span class="line">    bp_path.write_text(json.dumps(beipackzettel, indent=2))</span><span class="line">    print(f&quot;  Wrote {bp_path}&quot;)</span><span class="line"></span><span class="line">    # 4. Trust Score Update (persistent, if agenttrust available)</span><span class="line">    if USE_AGENTTRUST:</span><span class="line">        trust_path = output_dir.parent / &quot;trust-score.json&quot;</span><span class="line">        ts = _AT_TrustScore(&quot;mia-pipeline&quot;)</span><span class="line">        if trust_path.exists():</span><span class="line">            try:</span><span class="line">                old = json.loads(trust_path.read_text())</span><span class="line">                ts._score = old.get(&quot;score&quot;, 0)</span><span class="line">            except Exception:</span><span class="line">                pass</span><span class="line">        stated = gi[&quot;confidence&quot;] * 100 if gi[&quot;confidence&quot;] &lt;= 1 else gi[&quot;confidence&quot;]</span><span class="line">        outcome = &quot;good&quot; if grade in (&quot;A+++&quot;, &quot;A++&quot;) else &quot;bad&quot;</span><span class="line">        event = ts.update(stated_confidence=stated, outcome=outcome,</span><span class="line">                         reason=f&quot;Report {version}: grade={grade}&quot;)</span><span class="line">        trust_path.write_text(json.dumps(ts.summary(), indent=2))</span><span class="line">        print(f&quot;  Trust: score={ts.score}, level={ts.trust_level.value} (delta={event.delta})&quot;)</span><span class="line">        print(f&quot;  Wrote {trust_path}&quot;)</span><span class="line"></span><span class="line">    # 4. PDF (optional)</span><span class="line">    try:</span><span class="line">        import weasyprint  # type: ignore</span><span class="line">        import markdown  # type: ignore</span><span class="line">        html = markdown.markdown(report, extensions=[&quot;tables&quot;, &quot;fenced_code&quot;])</span><span class="line">        styled = f&quot;&lt;html&gt;&lt;head&gt;&lt;style&gt;body{{font-family:sans-serif;max-width:800px;margin:auto;padding:2em}}table{{border-collapse:collapse;width:100%}}th,td{{border:1px solid #ccc;padding:8px}}&lt;/style&gt;&lt;/head&gt;&lt;body&gt;{html}&lt;/body&gt;&lt;/html&gt;&quot;</span><span class="line">        pdf_path = output_dir / f&quot;final-report-{version}.pdf&quot;</span><span class="line">        weasyprint.HTML(string=styled).write_pdf(str(pdf_path))</span><span class="line">        print(f&quot;  Wrote {pdf_path}&quot;)</span><span class="line">    except ImportError:</span><span class="line">        print(&quot;  PDF skipped (weasyprint/markdown not available)&quot;)</span><span class="line">    except Exception as e:</span><span class="line">        print(f&quot;  PDF failed: {e}&quot;)</span><span class="line"></span><span class="line">    elapsed = time.time() - t0</span><span class="line">    print(f&quot;\n[PHASE E] Done in {elapsed:.1f}s&quot;)</span><span class="line">    print(f&quot;  GRADE: {grade}&quot;)</span><span class="line">    print(f&quot;  Confidence: {gi[&#x27;confidence&#x27;]}&quot;)</span><span class="line">    print(f&quot;  Claims: {gi[&#x27;claims&#x27;]}&quot;)</span><span class="line">    print(f&quot;  Warnings: {len(validation[&#x27;warnings&#x27;])}&quot;)</span><span class="line"></span><span class="line">    return grade</span><span class="line"></span><span class="line"></span><span class="line"># ---------------------------------------------------------------------------</span><span class="line"># Main</span><span class="line"># ---------------------------------------------------------------------------</span><span class="line"></span><span class="line">def main() -&gt; None:</span><span class="line">    &quot;&quot;&quot;CLI entry point.&quot;&quot;&quot;</span><span class="line">    parser = argparse.ArgumentParser(</span><span class="line">        description=&quot;Mia Synthesis Engine v3 — Elite Research Report Generator&quot;</span><span class="line">    )</span><span class="line">    parser.add_argument(&quot;pipeline_dir&quot;, type=str, help=&quot;Path to pipeline output directory&quot;)</span><span class="line">    parser.add_argument(&quot;--version&quot;, type=str, default=&quot;v5&quot;, help=&quot;Report version (default: v5)&quot;)</span><span class="line">    parser.add_argument(&quot;--dry-run&quot;, action=&quot;store_true&quot;, help=&quot;Skip Opus calls, print prompts&quot;)</span><span class="line">    args = parser.parse_args()</span><span class="line"></span><span class="line">    pipeline_dir = Path(args.pipeline_dir).resolve()</span><span class="line">    version = args.version</span><span class="line">    dry_run = args.dry_run</span><span class="line"></span><span class="line">    print(f&quot;{&#x27;=&#x27; * 60}&quot;)</span><span class="line">    print(f&quot;Mia Synthesis Engine v3&quot;)</span><span class="line">    print(f&quot;Pipeline dir: {pipeline_dir}&quot;)</span><span class="line">    print(f&quot;Version: {version}&quot;)</span><span class="line">    print(f&quot;Dry run: {dry_run}&quot;)</span><span class="line">    print(f&quot;RAG layer: {&#x27;available&#x27; if USE_RAG else &#x27;fallback (direct load)&#x27;}&quot;)</span><span class="line">    print(f&quot;{&#x27;=&#x27; * 60}&quot;)</span><span class="line"></span><span class="line">    t_total = time.time()</span><span class="line"></span><span class="line">    # Load data</span><span class="line">    print(&quot;\n[LOAD] Pipeline data...&quot;)</span><span class="line">    if pipeline_dir.exists():</span><span class="line">        pipeline_data = load_pipeline_data(pipeline_dir)</span><span class="line">    else:</span><span class="line">        print(f&quot;  WARNING: Pipeline dir not found: {pipeline_dir}&quot;)</span><span class="line">        pipeline_data = {&quot;research-brief.json&quot;: {}, &quot;all-claims.json&quot;: {},</span><span class="line">                         &quot;contradictions.json&quot;: {}, &quot;sub-reviews.json&quot;: {},</span><span class="line">                         &quot;blindspots.json&quot;: {}, &quot;sub_reports&quot;: []}</span><span class="line"></span><span class="line">    print(&quot;\n[LOAD] Workspace data...&quot;)</span><span class="line">    workspace_data = load_workspace_data()</span><span class="line"></span><span class="line">    # Output directory</span><span class="line">    output_dir = pipeline_dir / &quot;synthesis-v3&quot;</span><span class="line">    output_dir.mkdir(parents=True, exist_ok=True)</span><span class="line"></span><span class="line">    # Phase A</span><span class="line">    outline = phase_a_outline(pipeline_data, workspace_data, version, dry_run=dry_run)</span><span class="line"></span><span class="line">    # Phase B</span><span class="line">    sections = phase_b_sections(outline, pipeline_data, workspace_data, output_dir, dry_run=dry_run)</span><span class="line"></span><span class="line">    # Phase C</span><span class="line">    report = phase_c_merge(sections, outline, pipeline_data, workspace_data)</span><span class="line"></span><span class="line">    # Phase D</span><span class="line">    validation = phase_d_validate(report, pipeline_data, workspace_data)</span><span class="line"></span><span class="line">    # Phase E</span><span class="line">    grade = phase_e_output(report, validation, output_dir, version)</span><span class="line"></span><span class="line">    elapsed_total = time.time() - t_total</span><span class="line">    print(f&quot;\n{&#x27;=&#x27; * 60}&quot;)</span><span class="line">    print(f&quot;SYNTHESIS COMPLETE — Grade: {grade} — {elapsed_total:.1f}s total&quot;)</span><span class="line">    print(f&quot;Output: {output_dir}&quot;)</span><span class="line">    print(f&quot;{&#x27;=&#x27; * 60}&quot;)</span><span class="line"></span><span class="line"></span><span class="line">if __name__ == &quot;__main__&quot;:</span><span class="line">    main()</span><span class="line"></span></code></pre>
</body></html>