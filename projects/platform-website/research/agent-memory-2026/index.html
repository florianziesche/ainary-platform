<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>Agent Memory — What Works, What Doesn't — Ainary Report AR-034</title>
<meta name="description" content="Academic consensus meets practitioner reality: a survey of memory architectures for AI agents, grounded in real failures from building 100-agent systems.">
<meta property="og:title" content="Agent Memory — What Works, What Doesn't">
<meta property="og:description" content="Memory is the frontier in agent AI. Here's what the papers say and what actually happened when we built it.">
<meta property="og:type" content="article">
<style>
  @font-face {
    font-family: 'Inter';
    src: url('/fonts/inter-variable.woff2') format('woff2');
    font-weight: 100 900;
    font-display: swap;
  }

  * { margin: 0; padding: 0; box-sizing: border-box; }

  body {
    font-family: 'Inter', -apple-system, BlinkMacSystemFont, sans-serif;
    background: #fafaf8;
    color: #333;
    line-height: 1.75;
    font-size: 0.95rem;
    font-weight: 400;
  }

  .page { max-width: 900px; margin: 0 auto; padding: 48px 40px; }

  .cover {
    min-height: 100vh;
    display: flex;
    flex-direction: column;
    justify-content: space-between;
    max-width: 900px;
    margin: 0 auto;
    padding: 48px 40px;
  }

  .back-cover {
    min-height: 100vh;
    display: flex;
    flex-direction: column;
    justify-content: center;
    align-items: center;
    text-align: center;
    max-width: 900px;
    margin: 0 auto;
    padding: 48px 40px;
    page-break-before: always;
  }

  h1 { font-size: 2.2rem; font-weight: 600; line-height: 1.2; color: #1a1a1a; letter-spacing: -0.02em; }
  h2 { font-size: 1.5rem; font-weight: 600; color: #1a1a1a; line-height: 1.3; margin-top: 3rem; margin-bottom: 8px; }
  h3 { font-size: 1.1rem; font-weight: 600; color: #1a1a1a; line-height: 1.4; margin-top: 2rem; margin-bottom: 8px; }
  p { margin-bottom: 1rem; }
  strong { font-weight: 600; color: #1a1a1a; }
  em { font-style: italic; }
  sup { font-size: 0.65rem; color: #888; vertical-align: super; }

  .cover-header { display: flex; justify-content: space-between; align-items: center; margin-bottom: 40vh; }
  .cover-brand { display: flex; align-items: center; gap: 8px; }
  .gold-punkt { color: #c8aa50; font-size: 14px; }
  .brand-name { font-size: 0.85rem; font-weight: 500; color: #1a1a1a; letter-spacing: 0.02em; }
  .cover-meta { display: flex; gap: 12px; font-size: 0.75rem; color: #888; }
  .cover-title-block { margin-bottom: auto; }
  .cover-title { margin-bottom: 16px; }
  .cover-subtitle { font-size: 1rem; font-weight: 400; color: #666; line-height: 1.5; }
  .cover-footer { display: flex; justify-content: space-between; align-items: flex-end; }
  .cover-date { font-size: 0.75rem; color: #888; }
  .cover-author { font-size: 0.75rem; color: #888; text-align: center; }

  .quote-page {
    min-height: 100vh;
    display: flex;
    flex-direction: column;
    justify-content: center;
    align-items: center;
    max-width: 700px;
    margin: 0 auto;
    padding: 48px 40px;
  }
  .quote-text { font-size: 1.2rem; font-style: italic; color: #333; line-height: 1.8; text-align: center; margin-bottom: 24px; }
  .quote-source { font-size: 0.85rem; color: #888; text-align: center; }

  .toc-label { font-size: 0.7rem; font-weight: 600; color: #1a1a1a; text-transform: uppercase; letter-spacing: 0.1em; margin-bottom: 24px; }
  .toc-section { margin-bottom: 32px; }
  .toc-section-label { font-size: 0.65rem; font-weight: 500; color: #888; text-transform: uppercase; letter-spacing: 0.12em; margin-bottom: 8px; }
  .toc-entry { display: flex; align-items: baseline; gap: 16px; padding: 8px 0; border-bottom: 1px solid #eee; text-decoration: none; transition: all 0.2s; }
  .toc-number { font-size: 0.8rem; color: #888; font-variant-numeric: tabular-nums; min-width: 24px; }
  .toc-title { font-size: 0.95rem; font-weight: 500; color: #1a1a1a; flex: 1; transition: color 0.2s; }
  .toc-entry:hover .toc-title { color: #c8aa50; }

  .how-to-read-table, .exhibit-table {
    width: 100%;
    border-collapse: collapse;
    margin: 24px 0;
    page-break-inside: avoid;
  }
  .how-to-read-table th, .exhibit-table th {
    text-align: left;
    font-size: 0.7rem;
    font-weight: 600;
    color: #555;
    text-transform: uppercase;
    letter-spacing: 0.05em;
    padding: 10px 12px;
    background: #f5f4f0;
    border-bottom: 2px solid #e5e3dc;
  }
  .how-to-read-table td, .exhibit-table td {
    font-size: 0.85rem;
    color: #333;
    padding: 10px 12px;
    border-bottom: 1px solid #ddd;
  }

  .thesis { font-size: 1rem; font-weight: 600; color: #1a1a1a; line-height: 1.6; margin-bottom: 24px; }
  .evidence-list { margin-left: 20px; margin-bottom: 24px; }
  .evidence-list li { font-size: 0.9rem; color: #333; line-height: 1.6; margin-bottom: 8px; }
  .keywords { font-size: 0.8rem; color: #666; font-style: italic; margin-top: 32px; padding-top: 16px; border-top: 1px solid #eee; }

  .confidence-badge { font-size: 0.75rem; font-weight: 500; color: #1a1a1a; background: #f5f4f0; padding: 3px 8px; border-radius: 10px; margin-left: 8px; vertical-align: middle; }
  .confidence-line { font-size: 0.8rem; color: #888; font-style: italic; display: block; margin-bottom: 16px; }
  .key-insight { font-weight: 600; color: #1a1a1a; }

  .badge { font-size: 0.65rem; font-weight: 600; padding: 1px 5px; border-radius: 3px; margin-left: 4px; vertical-align: middle; }
  .badge-e { background: #e8f5e9; color: #2e7d32; }
  .badge-i { background: #e3f2fd; color: #1565c0; }
  .badge-j { background: #fff3e0; color: #e65100; }
  .badge-a { background: #fce4ec; color: #c62828; }

  .callout { background: #f5f4f0; padding: 16px 20px; border-radius: 4px; margin: 1.5rem 0; page-break-inside: avoid; }
  .callout-label { font-size: 0.7rem; font-weight: 600; text-transform: uppercase; letter-spacing: 0.08em; margin-bottom: 8px; }
  .callout-body { font-size: 0.9rem; color: #555; line-height: 1.6; }
  .callout.claim .callout-label { color: #555; }
  .callout.invalidation { border-left: 3px solid #ddd; }
  .callout.invalidation .callout-label { color: #888; }
  .callout.sowhat { border-left: 3px solid #c8aa50; }
  .callout.sowhat .callout-label { color: #c8aa50; }

  .exhibit { margin: 2rem 0; }
  .exhibit-label { font-size: 0.75rem; font-weight: 600; color: #555; margin-bottom: 8px; }
  .exhibit-source { font-size: 0.7rem; color: #888; margin-top: 8px; font-style: italic; }

  .kpi-grid { display: grid; grid-template-columns: repeat(auto-fit, minmax(200px, 1fr)); gap: 48px; margin: 2rem 0; }
  .kpi { text-align: left; }
  .kpi-number { font-size: 2rem; font-weight: 600; color: #1a1a1a; line-height: 1.2; }
  .kpi-label { font-size: 0.75rem; color: #666; margin-top: 4px; }
  .kpi-source { font-size: 0.65rem; color: #888; margin-top: 2px; }

  ul, ol { margin-left: 20px; margin-bottom: 1rem; }
  li { margin-bottom: 4px; }

  .transparency-intro { font-size: 0.85rem; color: #555; line-height: 1.6; margin-bottom: 8px; }
  .transparency-table { width: 100%; border-collapse: collapse; margin-top: 12px; }
  .transparency-table td:first-child { font-size: 0.85rem; font-weight: 600; color: #555; padding: 8px 0; border-bottom: 1px solid #eee; width: 180px; vertical-align: top; }
  .transparency-table td:last-child { font-size: 0.85rem; color: #333; padding: 8px 0; border-bottom: 1px solid #eee; }

  .reference-entry { font-size: 0.8rem; color: #555; line-height: 1.5; margin-bottom: 6px; padding-left: 24px; text-indent: -24px; }

  .author-section { margin-top: 3rem; padding-top: 2rem; border-top: 1px solid #e5e3dc; }
  .author-label { font-size: 0.85rem; font-weight: 600; color: #555; margin-bottom: 8px; }
  .author-bio { font-size: 0.85rem; color: #555; line-height: 1.6; }

  .back-cover-services { font-size: 0.85rem; color: #666; margin-bottom: 24px; }
  .back-cover-cta { font-size: 0.85rem; color: #888; margin-bottom: 16px; }
  .back-cover-contact { font-size: 0.8rem; color: #888; }

  .scenario-label {
    font-size: 0.75rem;
    font-weight: 600;
    color: #888;
    text-transform: uppercase;
    letter-spacing: 0.08em;
    background: #f5f4f0;
    padding: 4px 10px;
    border-radius: 3px;
    display: inline-block;
    margin-bottom: 16px;
  }

  @media print {
    @page { size: A4; margin: 2cm; }
    body { background: white; }
    .page, .cover, .back-cover { page-break-after: always; }
    .callout, .exhibit { page-break-inside: avoid; }
    @page :first { @top-center { content: none; } @bottom-center { content: none; } }
    @page {
      @top-center { content: "Ainary Report | State of AI Agent Trust 2026"; font-size: 0.7rem; color: #888; }
      @bottom-left { content: "© 2026 Ainary Ventures"; font-size: 0.7rem; color: #888; }
      @bottom-right { content: counter(page); font-size: 0.7rem; color: #888; }
    }
  }

</style>
</head>
<body>

<!-- ==================== COVER ==================== -->
<div class="cover">
  <div class="cover-header">
    <div class="cover-brand">
      <span class="gold-punkt">●</span>
      <span class="brand-name">Ainary</span>
    </div>
    <div class="cover-meta">
      <span>AR-034</span>
      <span>Confidence: 72%</span>
    </div>
  </div>

  <div class="cover-title-block">
    <h1 class="cover-title">Agent Memory —<br>What Works, What Doesn't</h1>
    <p class="cover-subtitle">Academic consensus meets practitioner reality. A survey of memory architectures for AI agents — grounded in real failures from building 100-agent systems, 44GB of unmanaged logs, and the pipeline that finally worked.</p>
  </div>

  <div class="cover-footer">
    <div class="cover-date">
      February 2026<br>
      <span style="font-size: 0.7rem; color: #aaa;">v1.0</span>
    </div>
    <div class="cover-author">
      Florian Ziesche · Ainary
    </div>
  </div>
</div>

<!-- ==================== TABLE OF CONTENTS ==================== -->
<div class="page">
  <p class="toc-label">Contents</p>

  <div class="toc-section">
    <p class="toc-section-label">Foundation</p>
    <a href="#exec-summary" class="toc-entry">
      <span class="toc-number">1</span>
      <span class="toc-title">Executive Summary</span>
    </a>
  </div>

  <div class="toc-section">
    <p class="toc-section-label">The Research</p>
    <a href="#academic-landscape" class="toc-entry">
      <span class="toc-number">2</span>
      <span class="toc-title">The Academic Landscape</span>
    </a>
    <a href="#memory-r1" class="toc-entry">
      <span class="toc-number">3</span>
      <span class="toc-title">Memory-R1: When to Remember</span>
    </a>
    <a href="#mirix" class="toc-entry">
      <span class="toc-number">4</span>
      <span class="toc-title">MIRIX: Shared Memory Across Agents</span>
    </a>
  </div>

  <div class="toc-section">
    <p class="toc-section-label">The Practice</p>
    <a href="#case-study" class="toc-entry">
      <span class="toc-number">5</span>
      <span class="toc-title">Case Study: What Happened When We Didn't Manage Memory</span>
    </a>
    <a href="#pipeline" class="toc-entry">
      <span class="toc-number">6</span>
      <span class="toc-title">The Memory Pipeline That Works</span>
    </a>
  </div>

  <div class="toc-section">
    <p class="toc-section-label">Forward</p>
    <a href="#whats-missing" class="toc-entry">
      <span class="toc-number">7</span>
      <span class="toc-title">What's Missing</span>
    </a>
    <a href="#recommendations" class="toc-entry">
      <span class="toc-number">8</span>
      <span class="toc-title">Recommendations</span>
    </a>
    <a href="#methodology" class="toc-entry">
      <span class="toc-number">9</span>
      <span class="toc-title">Methodology & Limitations</span>
    </a>
  </div>
</div>

<!-- ==================== EXECUTIVE SUMMARY ==================== -->
<div class="page" id="exec-summary">
  <h2>1. Executive Summary</h2>

  <p class="thesis">Memory is the single biggest unsolved problem in production AI agents. Academic research has exploded — 100+ papers surveyed in February 2026 alone — but the gap between what papers propose and what practitioners can deploy remains enormous. This report bridges that gap with real numbers from real failures.</p>

  <ul class="evidence-list">
    <li><strong>A 60-author survey</strong> of memory mechanisms for foundation agents identifies five cognitive memory types and reviews hundreds of papers — confirming that the field has no consensus architecture<sup>[1]</sup><span class="badge badge-e">E</span></li>
    <li><strong>Memory-R1 demonstrates that agents can learn <em>when</em> to remember</strong> using reinforcement learning, outperforming static heuristics with only 152 training examples<sup>[2]</sup><span class="badge badge-e">E</span></li>
    <li><strong>MIRIX introduces six-type modular memory</strong> for multi-agent systems, achieving 85.4% accuracy on long-form conversation benchmarks while reducing storage by 99.9%<sup>[3]</sup><span class="badge badge-e">E</span></li>
    <li><strong>Our own system produced a 44GB debug log</strong> in a single file, had 24 cron jobs writing to memory without coordination, and experienced context compaction destroying previously loaded memory — before we built the pipeline that now works<span class="badge badge-e">E</span></li>
    <li><strong>The pipeline that works</strong>: Daily notes → Weekly extraction → Monthly compression → MEMORY.md, validated across a 100-agent evolution experiment that produced 33,000 words of convergent protocol<span class="badge badge-e">E</span></li>
  </ul>

  <p class="keywords"><strong>Keywords:</strong> agent memory, episodic memory, semantic memory, working memory, reinforcement learning, multi-agent systems, memory management, context window, long-horizon reasoning</p>
</div>

<!-- ==================== THE ACADEMIC LANDSCAPE ==================== -->
<div class="page" id="academic-landscape">
  <h2>2. The Academic Landscape
    <span class="confidence-badge">80%</span>
  </h2>
  <span class="confidence-line">(Confidence: High — based on comprehensive survey paper)</span>

  <p><span class="key-insight">Memory is now the most active research frontier in agent AI. Four of the top ten agent papers in February 2026 focus on memory architectures — more than planning, tool use, or reasoning.</span><span class="badge badge-e">E</span></p>

  <p>In February 2026, Huang et al. published "Rethinking Memory Mechanisms of Foundation Agents in the Second Half" — a survey with <strong>60 co-authors</strong> spanning institutions from LMU Munich to Stanford, reviewing hundreds of papers on agent memory<sup>[1]</sup>. The survey establishes a taxonomy along three dimensions: <strong>memory substrate</strong> (internal vs. external), <strong>cognitive mechanism</strong> (episodic, semantic, sensory, working, and procedural), and <strong>memory subject</strong> (agent-centric vs. user-centric).<span class="badge badge-e">E</span></p>

  <h3>The Five Memory Types</h3>

  <p>The survey draws directly from cognitive science to categorize agent memory:</p>

  <div class="exhibit">
    <p class="exhibit-label">Exhibit 1: Memory Taxonomy from the Survey</p>
    <table class="exhibit-table">
      <tr>
        <th>Memory Type</th>
        <th>Function</th>
        <th>Agent Equivalent</th>
        <th>Trade-off</th>
      </tr>
      <tr>
        <td><strong>Working Memory</strong></td>
        <td>Active manipulation of current information</td>
        <td>Context window, scratchpads</td>
        <td>Fast but extremely limited (tokens)</td>
      </tr>
      <tr>
        <td><strong>Episodic Memory</strong></td>
        <td>Specific past experiences with temporal context</td>
        <td>Conversation logs, interaction histories</td>
        <td>Rich but expensive to search</td>
      </tr>
      <tr>
        <td><strong>Semantic Memory</strong></td>
        <td>General knowledge and facts</td>
        <td>Knowledge bases, extracted rules</td>
        <td>Compact but loses context</td>
      </tr>
      <tr>
        <td><strong>Procedural Memory</strong></td>
        <td>How to do things</td>
        <td>Tool usage patterns, workflows</td>
        <td>Efficient but hard to update</td>
      </tr>
      <tr>
        <td><strong>Sensory Memory</strong></td>
        <td>Raw perceptual input</td>
        <td>Screenshots, audio, multimodal input</td>
        <td>Massive volume, needs filtering</td>
      </tr>
    </table>
    <p class="exhibit-source">Source: Huang et al. (2026), "Rethinking Memory Mechanisms of Foundation Agents in the Second Half" [1]. Taxonomy synthesized from cognitive science literature applied to agent architectures.</p>
  </div>

  <p>The critical insight from the survey: <strong>most production agent systems use only one or two memory types</strong> — typically working memory (context window) supplemented by some form of retrieval-augmented generation (RAG) acting as a primitive episodic memory. The full cognitive stack remains theoretical.<span class="badge badge-i">I</span></p>

  <p>The survey also distinguishes between <strong>agent-centric memory</strong> (what the agent needs to complete tasks) and <strong>user-centric memory</strong> (what the agent needs to personalize for its user). This distinction matters: most research focuses on agent-centric memory, while most practitioner pain points are user-centric — remembering preferences, past decisions, evolving context.<span class="badge badge-i">I</span></p>

  <p>The academic consensus is clear: <strong>static, heuristic-driven memory pipelines are insufficient</strong>. Agents need learned memory policies that adapt to task requirements. But the gap between this consensus and production reality is wide. The survey documents hundreds of proposed architectures; the number deployed at scale is close to zero.<span class="badge badge-i">I</span></p>

  <div class="callout sowhat">
    <p class="callout-label">So What?</p>
    <p class="callout-body">If you're building an agent memory system, start by asking: which of the five memory types does your system actually implement? Most systems implement only working memory (context window) and call everything else "RAG." The taxonomy gives you a vocabulary for what's missing — and the survey shows you what academic solutions have been proposed for each gap.</p>
  </div>
</div>

<!-- ==================== MEMORY-R1 ==================== -->
<div class="page" id="memory-r1">
  <h2>3. Memory-R1: When to Remember
    <span class="confidence-badge">78%</span>
  </h2>
  <span class="confidence-line">(Confidence: High — peer-reviewed, benchmarked across three datasets)</span>

  <p><span class="key-insight">The most important question in agent memory is not "what to remember" — it is "when to store, when to retrieve, when to update, and when to do nothing." Memory-R1 is the first system to learn these decisions via reinforcement learning.</span><span class="badge badge-e">E</span></p>

  <p>Yan et al. present Memory-R1<sup>[2]</sup>, a reinforcement learning framework with two specialized agents: a <strong>Memory Manager</strong> that learns structured operations (ADD, UPDATE, DELETE, NOOP) and an <strong>Answer Agent</strong> that pre-selects and reasons over relevant memory entries. Both agents are fine-tuned with outcome-driven RL (PPO and GRPO).<span class="badge badge-e">E</span></p>

  <div class="kpi-grid">
    <div class="kpi">
      <div class="kpi-number">152</div>
      <div class="kpi-label">training QA pairs needed</div>
      <div class="kpi-source">Memory-R1 [2]</div>
    </div>
    <div class="kpi">
      <div class="kpi-number">3B–14B</div>
      <div class="kpi-label">parameter range validated</div>
      <div class="kpi-source">Memory-R1 [2]</div>
    </div>
    <div class="kpi">
      <div class="kpi-number">3</div>
      <div class="kpi-label">benchmarks (LoCoMo, MSC, LongMemEval)</div>
      <div class="kpi-source">Memory-R1 [2]</div>
    </div>
  </div>

  <p>What makes Memory-R1 significant is not the performance numbers but the conceptual shift: <strong>memory management is a learnable skill, not a fixed pipeline</strong>. Static systems apply the same rules regardless of context — store everything, retrieve by similarity, hope for the best. Memory-R1's agents learn that sometimes the correct memory operation is NOOP — doing nothing. Sometimes the correct operation is DELETE — actively forgetting information that has become stale or misleading.<span class="badge badge-i">I</span></p>

  <p>The framework validates across three challenging benchmarks: LoCoMo (long-form conversation), MSC (multi-session chat), and LongMemEval (long-term memory evaluation). With only 152 training examples, it outperforms strong baselines including full-context approaches. The low training data requirement is particularly important for practitioners: it means this approach could be fine-tuned on domain-specific memory management tasks without massive datasets.<span class="badge badge-e">E</span></p>

  <h3>Why This Matters for Practitioners</h3>

  <p>Every production agent system we've seen (including our own) uses hardcoded rules for memory: "store every conversation," "retrieve top-k by embedding similarity," "compress after N tokens." These rules are brittle. They don't distinguish between information worth remembering for months and information that's relevant for five minutes. Memory-R1 proves the alternative works — but the gap from paper to production is the engineering, not the science.<span class="badge badge-j">J</span></p>

  <div class="callout sowhat">
    <p class="callout-label">So What?</p>
    <p class="callout-body">If you're running static memory heuristics (and you almost certainly are), Memory-R1 shows what the next generation looks like: learned policies that decide when to store, update, delete, or ignore. The 152-example training requirement means this is within reach of most teams. The question is whether your memory infrastructure supports dynamic operations, or whether it's append-only.</p>
  </div>
</div>

<!-- ==================== MIRIX ==================== -->
<div class="page" id="mirix">
  <h2>4. MIRIX: Shared Memory Across Agents
    <span class="confidence-badge">70%</span>
  </h2>
  <span class="confidence-line">(Confidence: Medium-High — strong benchmarks, limited production validation)</span>

  <p><span class="key-insight">Multi-agent systems without shared memory are just multiple single agents. MIRIX is the first system to implement six distinct, coordinated memory types across agent teams — and it works.</span><span class="badge badge-e">E</span></p>

  <p>Wang and Chen introduce MIRIX<sup>[3]</sup>, a modular multi-agent memory system with six memory components: <strong>Core Memory</strong> (persistent identity and preferences), <strong>Episodic Memory</strong> (specific past experiences), <strong>Semantic Memory</strong> (abstracted knowledge), <strong>Procedural Memory</strong> (learned workflows), <strong>Resource Memory</strong> (external references), and <strong>Knowledge Vault</strong> (verified, high-confidence facts). A multi-agent framework dynamically controls updates and retrieval across all six types.<span class="badge badge-e">E</span></p>

  <div class="kpi-grid">
    <div class="kpi">
      <div class="kpi-number">85.4%</div>
      <div class="kpi-label">accuracy on LOCOMO benchmark (SOTA)</div>
      <div class="kpi-source">MIRIX [3]</div>
    </div>
    <div class="kpi">
      <div class="kpi-number">99.9%</div>
      <div class="kpi-label">storage reduction vs. raw retention</div>
      <div class="kpi-source">MIRIX [3]</div>
    </div>
    <div class="kpi">
      <div class="kpi-number">+35%</div>
      <div class="kpi-label">accuracy vs. RAG baseline on ScreenshotVQA</div>
      <div class="kpi-source">MIRIX [3]</div>
    </div>
  </div>

  <p>MIRIX addresses a problem that every multi-agent builder encounters: <strong>how do agents share knowledge without stepping on each other?</strong> The six-type architecture provides natural access control — procedural memory might be agent-specific, while semantic memory is shared across the team. The multi-agent framework coordinates updates, preventing the conflict resolution nightmares that plague naive shared-memory approaches.<span class="badge badge-i">I</span></p>

  <p>The ScreenshotVQA result is particularly striking: MIRIX processes nearly 20,000 high-resolution screenshots per sequence, a task where no existing memory system could previously be applied. By structuring memory into typed layers, MIRIX achieves dramatic storage reduction (99.9%) while <em>increasing</em> accuracy by 35% over RAG baselines. This validates the core thesis that <strong>structured forgetting beats total retention</strong>.<span class="badge badge-e">E</span></p>

  <p>The system also provides a packaged desktop application that monitors screens in real time, builds personalized memory bases, and offers visualization with local storage for privacy. This matters: it means the architecture has been built beyond paper-level prototypes.<span class="badge badge-e">E</span></p>

  <div class="callout sowhat">
    <p class="callout-label">So What?</p>
    <p class="callout-body">If you're building multi-agent systems, MIRIX's six-type taxonomy is the most mature reference architecture available. The 99.9% storage reduction proves that "keep everything" is not just wasteful — it actively hurts accuracy. Start by mapping your current memory to MIRIX's types: which do you have? Which are missing? The gaps will tell you where your agents are flying blind.</p>
  </div>
</div>

<!-- ==================== CASE STUDY ==================== -->
<div class="page" id="case-study">
  <h2>5. Case Study: What Happened When We Didn't Manage Memory
    <span class="confidence-badge">90%</span>
  </h2>
  <span class="confidence-line">(Confidence: Very High — first-party data, observed directly)</span>

  <p><span class="key-insight">Before we built a memory pipeline, our agent system produced a single 44GB debug log file, ran 24 concurrent cron jobs all writing to memory without coordination, and experienced context compaction silently destroying previously loaded memories. These are not hypothetical risks — they are documented failures with exact numbers.</span><span class="badge badge-e">E</span></p>

  <h3>The 44GB Log</h3>

  <p>On February 16, 2026, during a disk space audit, we discovered <code>cache-trace.jsonl</code> — a single debug log file consuming <strong>44GB</strong> of disk space. The file was a trace log that had been accumulating without any rotation, compression, or retention policy. On a MacBook Air with limited storage, this single file had consumed all available space, forcing emergency cleanup that included deleting browser caches (8.5GB) and npm caches (5.4GB) just to continue operating.<span class="badge badge-e">E</span></p>

  <p>The 44GB log is a perfect example of what happens when memory has no forgetting discipline: <strong>unbounded accumulation eventually destroys the system it was meant to support</strong>. The log contained useful debugging information. All of it. Forever. Until there was no disk space left for the actual work.<span class="badge badge-i">I</span></p>

  <h3>The 24 Uncoordinated Crons</h3>

  <p>Our agent system ran 24 cron jobs, many of which wrote to shared memory files — MEMORY.md, daily notes, topic files. These crons had no coordination mechanism. Multiple crons could attempt to update the same file within the same minute. There was no locking, no conflict resolution, no awareness of what other crons had recently written.<span class="badge badge-e">E</span></p>

  <p>The result was memory corruption through overwrite: Cron A would read MEMORY.md, prepare an update, and write it back. Cron B, which had read the same file milliseconds earlier, would write its own update — overwriting Cron A's changes entirely. Information was being both added and lost simultaneously. We discovered this only after noticing that memory entries would appear and disappear between sessions.<span class="badge badge-i">I</span></p>

  <p>The fix was structural: we added a rule that <strong>crons MUST NOT modify SOUL.md, AGENTS.md, or MEMORY.md autonomously</strong>. Only the main session, with human oversight, can write to core identity and long-term memory files. This is the agent equivalent of database write locking — simple, but it took a production failure to implement it.<span class="badge badge-e">E</span></p>

  <h3>Context Compaction Destroying Loaded Memory</h3>

  <p>The most insidious failure was context compaction. When the agent's context window filled up, the platform automatically compacted older context to make room for new tokens. This compaction is designed to preserve the most relevant information — but "relevant" is determined heuristically, and it has no knowledge of what was <em>loaded from memory files</em> vs. what emerged during the conversation.<span class="badge badge-i">I</span></p>

  <p>The result: carefully loaded memory — preferences, project context, decision history read from MEMORY.md at session start — would be silently compressed away as the conversation progressed. The agent would begin the session knowing the user's communication preferences, active projects, and established patterns. Two hours later, after extensive work had expanded the context, compaction would strip those memory-loaded facts to make room. The agent would continue operating, but with its foundational context gone — making decisions that contradicted established preferences without any awareness that it had "forgotten."<span class="badge badge-i">I</span></p>

  <p>This failure mode is not documented in any of the academic papers we surveyed. It is uniquely a production problem: academic benchmarks use controlled contexts, not dynamic sessions where loaded memory competes with generated content for limited context space.<span class="badge badge-j">J</span></p>

  <div class="kpi-grid">
    <div class="kpi">
      <div class="kpi-number">44 GB</div>
      <div class="kpi-label">single unmanaged log file</div>
      <div class="kpi-source">First-party, Feb 16 2026</div>
    </div>
    <div class="kpi">
      <div class="kpi-number">24</div>
      <div class="kpi-label">concurrent crons writing to memory</div>
      <div class="kpi-source">First-party, Feb 2026</div>
    </div>
    <div class="kpi">
      <div class="kpi-number">11 GB</div>
      <div class="kpi-label">main memory database (main.sqlite)</div>
      <div class="kpi-source">First-party, Feb 16 2026</div>
    </div>
  </div>

  <div class="callout sowhat">
    <p class="callout-label">So What?</p>
    <p class="callout-body">These failures share a common root: <strong>no forgetting discipline</strong>. The 44GB log never forgot anything. The 24 crons never coordinated who should remember what. Context compaction "forgot" the wrong things. Production memory systems need explicit policies for what to keep, what to discard, and who has write access — before the system teaches you the hard way.</p>
  </div>
</div>

<!-- ==================== THE PIPELINE THAT WORKS ==================== -->
<div class="page" id="pipeline">
  <h2>6. The Memory Pipeline That Works
    <span class="confidence-badge">75%</span>
  </h2>
  <span class="confidence-line">(Confidence: High for our use case — generalizability unproven)</span>

  <p><span class="key-insight">After the failures documented in Section 5, we built a memory pipeline through a 100-agent evolution experiment. Ten groups of ten agents, each using different thinking methods, converged on the same architecture independently. That convergence is the strongest signal we have that the pipeline works.</span><span class="badge badge-e">E</span></p>

  <h3>The Experiment</h3>

  <p>We ran a 100-agent experiment to discover how self-improving agents should manage memory. Ten groups of agents (each using a different analytical method: First Principles, Inversion, Analogical, Adversarial, Quantitative, Socratic, Constraint, Narrative, Systems, and Random Mutation) independently designed memory protocols. The experiment produced <strong>33,000 words</strong> of transcripts across 222,207 characters of source material.<sup>[4]</sup><span class="badge badge-e">E</span></p>

  <p>The convergence was striking: <strong>10 out of 10 groups independently identified "Files = Intelligence"</strong> as the foundational law — that external memory files are the <em>only</em> improvement mechanism for stateless agents. 8 out of 10 converged on multi-timescale feedback loops. The memory pipeline emerged not from one group's design but from the intersection of all ten.<span class="badge badge-e">E</span></p>

  <h3>The Pipeline</h3>

  <div class="exhibit">
    <p class="exhibit-label">Exhibit 2: The Memory Pipeline (Production)</p>
    <table class="exhibit-table">
      <tr>
        <th>Stage</th>
        <th>Cadence</th>
        <th>Input</th>
        <th>Output</th>
        <th>Rule</th>
      </tr>
      <tr>
        <td><strong>Raw Interaction</strong></td>
        <td>Continuous</td>
        <td>Every conversation</td>
        <td>Narrative daily log</td>
        <td>Story format, not just facts</td>
      </tr>
      <tr>
        <td><strong>Daily Notes</strong></td>
        <td>Daily</td>
        <td>Session events, decisions, corrections</td>
        <td><code>memory/YYYY-MM-DD.md</code></td>
        <td>Write immediately, not at session end</td>
      </tr>
      <tr>
        <td><strong>Weekly Extraction</strong></td>
        <td>Weekly</td>
        <td>7 daily notes</td>
        <td>Behavioral rules, pattern updates</td>
        <td>Only patterns that repeat 5+ times</td>
      </tr>
      <tr>
        <td><strong>Monthly Compression</strong></td>
        <td>Monthly</td>
        <td>4 weekly extractions</td>
        <td>MEMORY.md updates</td>
        <td>"Fits on one page? Keep. Doesn't? Cut."</td>
      </tr>
      <tr>
        <td><strong>Hub Memory ID</strong></td>
        <td>Monthly</td>
        <td>Full memory graph</td>
        <td>Top 10 most-connected nodes</td>
        <td>Never auto-pruned, weight retrieval</td>
      </tr>
    </table>
    <p class="exhibit-source">Source: SYNTHESIS-v2.md [4], synthesized from 100-agent experiment. Pipeline has been in production since February 2026.</p>
  </div>

  <h3>The File Structure</h3>

  <p>The experiment converged on a specific file structure that maps roughly to the cognitive memory types identified by the academic survey<sup>[1]</sup>:</p>

  <ul>
    <li><strong>SOUL.md</strong> — Agent identity, anti-patterns, protocol (≈ procedural memory)</li>
    <li><strong>USER.md</strong> — Co-authored user model (≈ user-centric semantic memory)</li>
    <li><strong>MEMORY.md</strong> — Curated long-term wisdom (≈ semantic memory)</li>
    <li><strong>memory/YYYY-MM-DD.md</strong> — Daily narrative logs (≈ episodic memory)</li>
    <li><strong>memory/kintsugi.md</strong> — Golden repairs from failures (≈ episodic, high-value subset)</li>
    <li><strong>memory/graveyard.md</strong> — Killed beliefs + reasoning (≈ negative semantic memory)</li>
    <li><strong>memory/preferences.md</strong> — Structured behavioral preferences (≈ user-centric procedural)</li>
  </ul>

  <h3>The Forgetting Discipline</h3>

  <p>The experiment identified three tiers of memory persistence — a direct parallel to MIRIX's observation that 99.9% storage reduction <em>improves</em> accuracy:</p>

  <ul>
    <li><strong>Tier 1 (Permanent):</strong> Identity core, hub memories, kintsugi entries</li>
    <li><strong>Tier 2 (90-day half-life):</strong> Active project context, current preferences</li>
    <li><strong>Tier 3 (30-day half-life):</strong> Ephemeral context, temporary states</li>
  </ul>

  <p>Monthly: anything unaccessed for 60 days and not in Tier 1 → archive. The critical rule: <strong>"Ask once before major deletions."</strong> Automated forgetting without human oversight produced the same corrupted-memory problems that motivated the pipeline in the first place.<span class="badge badge-e">E</span></p>

  <h3>What the Experiment Found That the Papers Didn't</h3>

  <p>Three findings from the 100-agent experiment that we did not find in any surveyed paper:</p>

  <ol>
    <li><strong>The Belief Graveyard.</strong> Killed beliefs must be permanently archived and searchable, or they return as "zombie beliefs" — assumptions the agent re-derives from the same signals that produced them originally. No academic system we surveyed implements negative memory (things the agent has explicitly decided are <em>not</em> true).<span class="badge badge-j">J</span></li>
    <li><strong>Hub Memories.</strong> Some memories are "mother trees" — they connect to many other memories and explain multiple behaviors. These should never be auto-pruned and should weight retrieval. This is conceptually similar to MIRIX's Core Memory, but identified independently via biological analogy (mycorrhizal networks).<span class="badge badge-i">I</span></li>
    <li><strong>"Mental notes" don't survive.</strong> The simplest, most important lesson: if the agent thinks "I should remember this" but doesn't write it to a file, it is lost. 100% of the time. Every agent group rediscovered this independently. The implication: <strong>write-first architectures</strong> (write to memory immediately, not at session end) dramatically outperform write-deferred architectures.<span class="badge badge-e">E</span></li>
  </ol>

  <div class="callout sowhat">
    <p class="callout-label">So What?</p>
    <p class="callout-body">The pipeline is simple: daily notes, weekly extraction, monthly compression, explicit tiers, and write-first. The value is not in complexity but in consistency — a pipeline that runs every day beats a sophisticated architecture that runs sporadically. Start with daily notes. Everything else builds on that foundation.</p>
  </div>
</div>

<!-- ==================== WHAT'S MISSING ==================== -->
<div class="page" id="whats-missing">
  <h2>7. What's Missing
    <span class="confidence-badge">65%</span>
  </h2>
  <span class="confidence-line">(Confidence: Medium-High — informed by both literature gaps and practitioner needs)</span>

  <p><span class="key-insight">Despite the academic explosion and our own production experience, five critical capabilities remain unsolved in both research and practice.</span></p>

  <h3>1. Active Forgetting</h3>

  <p>Memory-R1 proves that agents can learn DELETE operations<sup>[2]</sup>. MIRIX achieves 99.9% storage reduction<sup>[3]</sup>. Our experiment produced explicit forgetting tiers. But <strong>no production system implements relevance-scored, learned forgetting at scale</strong>. Current forgetting is either manual ("archive after 60 days") or heuristic ("drop lowest-similarity entries"). An agent that actively learns what to forget — not just what to remember — does not yet exist outside research papers.<span class="badge badge-j">J</span></p>

  <h3>2. Relevance Scoring That Adapts</h3>

  <p>Current retrieval relies on embedding similarity — cosine distance between a query and stored memories. This is better than nothing but worse than what's needed. A memory's relevance depends on the current task, the user's current goals, the time since storage, and the memory's connection to other memories. <strong>Static embedding similarity captures none of this.</strong> Memory-R1's approach (learned retrieval) is the right direction, but it has not been validated outside controlled benchmarks.<span class="badge badge-j">J</span></p>

  <h3>3. Shared Memory Between Sessions</h3>

  <p>Our pipeline uses files as the inter-session bridge: today's session reads yesterday's daily notes. This works for a single agent with a single user. But it does not solve: (a) multiple agents sharing memory about the same user, (b) the same agent running in multiple concurrent sessions, or (c) agents handing off context to different agents mid-workflow. MIRIX addresses multi-agent memory<sup>[3]</sup>, but the practical integration challenge — how do you connect a MIRIX-style system to existing agent platforms? — remains unsolved.<span class="badge badge-i">I</span></p>

  <h3>4. Context Compaction Awareness</h3>

  <p>No research paper we surveyed addresses the production problem of context compaction destroying loaded memory (Section 5). This is because academic benchmarks operate in controlled contexts where the full memory is always available. In production, where agents run for hours and context windows fill up, <strong>the platform's own memory management (compaction) fights against the agent's memory management (loaded files)</strong>. A memory system that is aware of — and can interact with — the platform's compaction layer does not exist.<span class="badge badge-j">J</span></p>

  <h3>5. Static Retrieval vs. Learned Policies</h3>

  <p>The gap between the academic frontier (Memory-R1's learned retrieval policies) and production reality (hardcoded "retrieve top-5 by similarity") is approximately 2-3 years of engineering. Memory-R1 works with 152 training examples — the science is solved. But integrating RL-trained memory management into existing agent frameworks (LangChain, CrewAI, AutoGen, OpenClaw) requires infrastructure that doesn't exist: <strong>reward signals from task outcomes piped back to memory operations, fine-tuning loops that run alongside production inference, and evaluation frameworks that measure memory quality beyond benchmark accuracy</strong>.<span class="badge badge-j">J</span></p>

  <div class="callout sowhat">
    <p class="callout-label">So What?</p>
    <p class="callout-body">These five gaps define the next 12-18 months of agent memory development. If you're building today, invest in the pipeline (Section 6) — it's the best available. But architect for extensibility: your memory system should support dynamic operations (not just append), learned policies (not just hardcoded rules), and multi-agent coordination (not just single-agent files). The systems that can evolve toward these capabilities will outperform those that can't.</p>
  </div>
</div>

<!-- ==================== RECOMMENDATIONS ==================== -->
<div class="page" id="recommendations">
  <h2>8. Recommendations
    <span class="confidence-badge">70%</span>
  </h2>
  <span class="confidence-line">(Confidence: Medium-High — grounded in practice, limited by single-team experience)</span>

  <p>These recommendations target practitioners building agent memory systems — developers, architects, and technical leads. They synthesize the academic research (Sections 2-4) with our production experience (Sections 5-6) and the gap analysis (Section 7).</p>

  <h3>Start Today</h3>

  <ol>
    <li><strong>Implement daily notes immediately.</strong> One file per day, narrative format, written during the session (not after). This is the foundation everything else builds on. Cost: zero. Value: everything.<span class="badge badge-j">J</span></li>
    <li><strong>Add write locking on critical memory files.</strong> If multiple agents or crons can write to the same file, you will lose data. Our rule: only the main session can write to SOUL.md, MEMORY.md, and AGENTS.md. Crons can write to daily notes only.<span class="badge badge-j">J</span></li>
    <li><strong>Set a forgetting policy.</strong> Define what gets archived after 30, 60, and 90 days. If you can't decide, start with: "If nobody accessed it in 60 days and it's not in the identity core, archive it." You can always restore from archive.<span class="badge badge-j">J</span></li>
  </ol>

  <h3>Build This Quarter</h3>

  <ol start="4">
    <li><strong>Implement the weekly extraction loop.</strong> Every 7 days, process the week's daily notes into behavioral rules and pattern updates. Only promote patterns observed 5+ times. This is where noise becomes signal.<span class="badge badge-j">J</span></li>
    <li><strong>Map your memory to the five-type taxonomy.</strong> Working, episodic, semantic, procedural, sensory — which do you have? MIRIX's six-type structure<sup>[3]</sup> is the most comprehensive reference architecture. Start with the gaps.<span class="badge badge-j">J</span></li>
    <li><strong>Implement a belief graveyard.</strong> When you discover an agent assumption is wrong, don't just correct it — archive it with reasoning. Without this, the agent will re-derive the same wrong conclusion from the same signals.<span class="badge badge-j">J</span></li>
  </ol>

  <h3>Plan For Next Year</h3>

  <ol start="7">
    <li><strong>Watch Memory-R1 for production readiness.</strong> The 152-example training requirement means RL-based memory management is within reach. When frameworks support reward-signal integration for memory operations, adopt early.<span class="badge badge-j">J</span></li>
    <li><strong>Architect for dynamic memory operations.</strong> Your memory layer should support ADD, UPDATE, DELETE, and NOOP — not just append. This is a prerequisite for any learned memory policy.<span class="badge badge-j">J</span></li>
    <li><strong>Invest in context compaction awareness.</strong> If your platform compacts context automatically, you need to understand what it preserves and what it discards. Consider re-loading critical memory entries after compaction events, or flagging memory entries as "compaction-resistant."<span class="badge badge-j">J</span></li>
  </ol>

  <div class="exhibit">
    <p class="exhibit-label">Exhibit 3: Memory System Maturity Model</p>
    <table class="exhibit-table">
      <tr>
        <th>Level</th>
        <th>Description</th>
        <th>Indicator</th>
      </tr>
      <tr>
        <td><strong>0: None</strong></td>
        <td>Context window only. Nothing persists.</td>
        <td>Every session starts from zero</td>
      </tr>
      <tr>
        <td><strong>1: Append-Only</strong></td>
        <td>Logs stored, maybe RAG. No curation.</td>
        <td>Storage grows unbounded</td>
      </tr>
      <tr>
        <td><strong>2: Curated</strong></td>
        <td>Pipeline with extraction + compression. Forgetting policy.</td>
        <td>Storage is bounded, quality improves over time</td>
      </tr>
      <tr>
        <td><strong>3: Typed</strong></td>
        <td>Multiple memory types (episodic, semantic, procedural).</td>
        <td>Different information stored differently</td>
      </tr>
      <tr>
        <td><strong>4: Learned</strong></td>
        <td>RL-based memory management. Dynamic operations.</td>
        <td>Memory quality measurably improves via feedback</td>
      </tr>
      <tr>
        <td><strong>5: Coordinated</strong></td>
        <td>Multi-agent shared memory with access control.</td>
        <td>Agents share knowledge without conflicts</td>
      </tr>
    </table>
    <p class="exhibit-source">Source: Author framework [J]. Most production systems are at Level 0-1. The pipeline in Section 6 achieves Level 2. MIRIX targets Level 3-5. Memory-R1 targets Level 4. No production system we're aware of has achieved Level 5.</p>
  </div>
</div>

<!-- ==================== METHODOLOGY & LIMITATIONS ==================== -->
<div class="page" id="methodology">
  <h2>9. Methodology & Limitations</h2>

  <table class="transparency-table">
    <tr>
      <td>Overall Confidence</td>
      <td>72% (Medium-High). Academic sections rely on peer-reviewed papers with strong benchmarks. Practitioner sections rely on first-party data from a single team. Recommendations are judgment calls informed by both.</td>
    </tr>
    <tr>
      <td>Sources</td>
      <td>3 primary academic papers [1-3], 1 internal experiment synthesis [4], 2 daily memory logs (first-party), 1 memory structure document (first-party). Web search for supplementary context.</td>
    </tr>
    <tr>
      <td>Strongest Evidence</td>
      <td>Memory-R1 benchmarks (3 datasets, multiple model scales); MIRIX benchmarks (SOTA on LOCOMO, 99.9% storage reduction); 44GB log and 24-cron coordination failure (first-party, exact numbers).</td>
    </tr>
    <tr>
      <td>Weakest Point</td>
      <td>The pipeline (Section 6) has been validated by one team for one use case over weeks, not months. The 100-agent experiment produced convergent design but has not been A/B tested against alternatives. Generalizability to different agent platforms, team sizes, and domains is unproven.</td>
    </tr>
    <tr>
      <td>What Would Invalidate</td>
      <td>If (a) append-only memory with better retrieval outperforms curated pipelines, (b) context window sizes expand enough to eliminate the need for external memory, (c) platform-level memory management (e.g., built into OpenAI, Anthropic APIs) makes application-level pipelines unnecessary.</td>
    </tr>
  </table>

  <h3>Confidence Per Section</h3>

  <div class="exhibit">
    <table class="exhibit-table">
      <tr>
        <th>Section</th>
        <th>Confidence</th>
        <th>Basis</th>
      </tr>
      <tr>
        <td>2. Academic Landscape</td>
        <td>80%</td>
        <td>60-author survey, hundreds of papers reviewed</td>
      </tr>
      <tr>
        <td>3. Memory-R1</td>
        <td>78%</td>
        <td>Peer-reviewed, 3 benchmarks, multiple model scales</td>
      </tr>
      <tr>
        <td>4. MIRIX</td>
        <td>70%</td>
        <td>Strong benchmarks, limited production validation</td>
      </tr>
      <tr>
        <td>5. Case Study</td>
        <td>90%</td>
        <td>First-party data, exact numbers, directly observed</td>
      </tr>
      <tr>
        <td>6. Pipeline</td>
        <td>75%</td>
        <td>100-agent convergence, weeks of production use</td>
      </tr>
      <tr>
        <td>7. What's Missing</td>
        <td>65%</td>
        <td>Gap analysis from literature + practice, judgment-heavy</td>
      </tr>
      <tr>
        <td>8. Recommendations</td>
        <td>70%</td>
        <td>Practice-grounded but single-team experience</td>
      </tr>
    </table>
  </div>

  <h3>Conflict of Interest</h3>

  <p>The publisher of this report builds and operates AI agent systems — and has a commercial interest in the conclusions presented here. The case study data is first-party: we are reporting our own failures and successes. Evaluate evidence independently; claims marked [J] reflect judgment, not evidence.</p>

  <h3>How This Report Was Produced</h3>

  <p>This report was produced using a multi-agent research pipeline: automated literature search, paper analysis, cross-referencing with production logs, and synthesis — each performed by specialized agents. The irony is not lost on us: the memory pipeline described in Section 6 is the same pipeline that enabled this report to be written.</p>

  <!-- ==================== REFERENCES ==================== -->
  <h2 style="margin-top: 3rem;">References</h2>

  <p class="reference-entry">[1] Huang, W.-C., Zhang, W., Liang, Y., et al. (60 authors). (2026). "Rethinking Memory Mechanisms of Foundation Agents in the Second Half: A Survey." arXiv:2602.06052. Feb 6, 2026. <a href="https://arxiv.org/abs/2602.06052" style="color: #c8aa50;">https://arxiv.org/abs/2602.06052</a></p>

  <p class="reference-entry">[2] Yan, S., Yang, X., Huang, Z., Nie, E., Ding, Z., Li, Z., Ma, X., Bi, J., Kersting, K., Pan, J.Z., Schütze, H., Tresp, V., Ma, Y. (2025). "Memory-R1: Enhancing Large Language Model Agents to Manage and Utilize Memories via Reinforcement Learning." arXiv:2508.19828. <a href="https://arxiv.org/abs/2508.19828" style="color: #c8aa50;">https://arxiv.org/abs/2508.19828</a></p>

  <p class="reference-entry">[3] Wang, Y., Chen, X. (2025). "MIRIX: Multi-Agent Memory System for LLM-Based Agents." arXiv:2507.07957. Jul 10, 2025. <a href="https://arxiv.org/abs/2507.07957" style="color: #c8aa50;">https://arxiv.org/abs/2507.07957</a></p>

  <p class="reference-entry">[4] Ainary Research. (2026). "THE GRAND SYNTHESIS v2.0 — Full-Transcript Analysis of 100-Agent Evolution Experiment." Internal document. 222,207 characters across 10 groups.</p>

  <p class="reference-entry">[5] Ainary Operations. (2026). Daily memory logs: memory/2026-02-16.md, memory/2026-02-17.md. First-party operational data.</p>

  <p class="reference-entry">[6] Ainary Operations. (2026). MEMORY.md — Production memory structure with layered loading protocol. First-party.</p>

  <p style="margin-top: 32px; font-size: 0.8rem; color: #888;">Cite as: Ainary Research. (2026). "Agent Memory — What Works, What Doesn't." AR-034, v1.0.</p>

  <div class="author-section">
    <p class="author-label">About This Report</p>
    <p class="author-bio">AI strategy · research · implementation. By someone who built the systems first. This report was produced by Ainary's multi-agent research pipeline. <a href="https://ainaryventures.com" style="color: #c8aa50;">ainaryventures.com</a></p>
  </div>
</div>

<!-- ==================== BACK COVER ==================== -->
<div class="back-cover">
  <div style="margin-bottom: 48px;">
    <span class="gold-punkt" style="font-size: 24px;">●</span>
    <p class="brand-name" style="font-size: 1.2rem; margin-top: 8px;">Ainary</p>
  </div>
  <p class="back-cover-services">AI Strategy · System Design · Execution · Consultancy · Research</p>
  <p class="back-cover-cta"><a href="https://ainaryventures.com/contact.html" style="color: #888; text-decoration: none;">Contact</a> · <a href="https://ainaryventures.com/contact.html" style="color: #888; text-decoration: none;">Feedback</a></p>
  <p class="back-cover-contact">
    ainaryventures.com<br>
    florian@ainaryventures.com
  </p>
  <p style="font-size: 0.75rem; color: #aaa; margin-top: 48px;">© 2026 Ainary Ventures</p>
</div>

</body>
</html>
