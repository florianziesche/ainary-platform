{
  "gpt4o": {
    "model": "GPT-4o",
    "chars": 7331,
    "tokens": 4026,
    "time_s": 22.7,
    "confidence": 0.3802,
    "n_claims": 15,
    "llm_phrases": 0,
    "claims": [
      {
        "text": "Trust calibration effectiveness is highly context-dependent, with real-time feed",
        "confidence": 0.76,
        "weight": 1.0,
        "admiralty": "A1",
        "verification": "verified"
      },
      {
        "text": "Adaptive trust calibration methods reduce over-trust in AI systems by 25% compar",
        "confidence": 0.76,
        "weight": 1.0,
        "admiralty": "A1",
        "verification": "verified"
      },
      {
        "text": "The Trust Calibration Maturity Model (TCMM) improves trust calibration metrics b",
        "confidence": 0.56,
        "weight": 0.6,
        "admiralty": "B2",
        "verification": "verified"
      },
      {
        "text": "Incorporating cognitive cues in AI interfaces can enhance user trust by up to 20",
        "confidence": 0.76,
        "weight": 0.6,
        "admiralty": "A1",
        "verification": "verified"
      },
      {
        "text": "Aligning system trustworthiness with user trust perceptions improves user satisf",
        "confidence": 0.76,
        "weight": 1.0,
        "admiralty": "A1",
        "verification": "verified"
      },
      {
        "text": "Overcoming over-trust remains a challenge, with users exhibiting over-trust in 1",
        "confidence": 0.76,
        "weight": 0.6,
        "admiralty": "A1",
        "verification": "verified"
      },
      {
        "text": "Providing explanations for AI decisions enhances trust calibration, increasing u",
        "confidence": 0.76,
        "weight": 0.6,
        "admiralty": "A1",
        "verification": "verified"
      },
      {
        "text": "Dynamic trust calibration improves trust alignment by 30% in environments with h",
        "confidence": 0.76,
        "weight": 0.6,
        "admiralty": "A1",
        "verification": "verified"
      },
      {
        "text": "Do not deploy AI systems if they lack the ability to adapt trust calibration str",
        "confidence": 0.032,
        "weight": 1.0,
        "admiralty": "C3",
        "verification": "unverifiable"
      },
      {
        "text": "Avoid deployment if the system does not incorporate real-time feedback mechanism",
        "confidence": 0.032,
        "weight": 1.0,
        "admiralty": "C3",
        "verification": "unverifiable"
      },
      {
        "text": "Do not deploy if the system fails to provide clear and understandable explanatio",
        "confidence": 0.032,
        "weight": 1.0,
        "admiralty": "C3",
        "verification": "unverifiable"
      },
      {
        "text": "Avoid deployment if there is a significant misalignment between the system's tru",
        "confidence": 0.032,
        "weight": 1.0,
        "admiralty": "C3",
        "verification": "unverifiable"
      },
      {
        "text": "Do not deploy if the system relies solely on static trust calibration models.",
        "confidence": 0.032,
        "weight": 1.0,
        "admiralty": "C3",
        "verification": "unverifiable"
      },
      {
        "text": "Implement adaptive trust calibration methods that adjust based on user interacti",
        "confidence": 0.032,
        "weight": 0.6,
        "admiralty": "C3",
        "verification": "unverifiable"
      },
      {
        "text": "Enhance system transparency by providing clear, understandable explanations for ",
        "confidence": 0.032,
        "weight": 0.6,
        "admiralty": "C3",
        "verification": "unverifiable"
      }
    ],
    "cross_confidence": 0.1556
  },
  "sonnet": {
    "model": "Claude Sonnet 4",
    "chars": 14633,
    "tokens": 5881,
    "time_s": 61.9,
    "confidence": 0.1462,
    "n_claims": 15,
    "llm_phrases": 0,
    "claims": [
      {
        "text": "calibrated trust occurs when trust and trustworthiness are aligned with each oth",
        "confidence": 0.16,
        "weight": 1.0,
        "admiralty": "C3",
        "verification": "partial"
      },
      {
        "text": "The emergence of the Trust Calibration Maturity Model (TCMM) in 2025 represents ",
        "confidence": 0.16,
        "weight": 1.0,
        "admiralty": "C3",
        "verification": "partial"
      },
      {
        "text": "recent advances in real-time trust assessment using machine learning algorithms ",
        "confidence": 0.16,
        "weight": 0.6,
        "admiralty": "C3",
        "verification": "partial"
      },
      {
        "text": "adaptive trust calibration significantly helped participants change their behavi",
        "confidence": 0.16,
        "weight": 1.0,
        "admiralty": "C3",
        "verification": "partial"
      },
      {
        "text": "Research implementing four types of Trust Calibration Cues (Visual/Audio/Verbal/",
        "confidence": 0.16,
        "weight": 0.6,
        "admiralty": "C3",
        "verification": "partial"
      },
      {
        "text": "under-trust scenarios lack validated intervention strategies",
        "confidence": 0.016,
        "weight": 1.0,
        "admiralty": "D4",
        "verification": "unverifiable"
      },
      {
        "text": "structured paths for characterizing and communicating the maturity of trustworth",
        "confidence": 0.16,
        "weight": 0.6,
        "admiralty": "C3",
        "verification": "partial"
      },
      {
        "text": "real-time assessment of trust critical for capturing dynamic changes, thereby fa",
        "confidence": 0.16,
        "weight": 0.6,
        "admiralty": "C3",
        "verification": "partial"
      },
      {
        "text": "trustworthiness thresholds can be calibrated on evaluation sets to find appropri",
        "confidence": 0.16,
        "weight": 0.6,
        "admiralty": "C3",
        "verification": "partial"
      },
      {
        "text": "The foundational Lee and See model from 2004 established the first conceptual fr",
        "confidence": 0.16,
        "weight": 0.3,
        "admiralty": "C3",
        "verification": "partial"
      },
      {
        "text": "30-year longitudinal review covering 1995 through June 2025",
        "confidence": 0.16,
        "weight": 0.3,
        "admiralty": "C3",
        "verification": "partial"
      },
      {
        "text": "(1) exo versus endo trust calibrations, (2) warranted versus unwarranted trust c",
        "confidence": 0.16,
        "weight": 0.6,
        "admiralty": "C3",
        "verification": "partial"
      },
      {
        "text": "trust calibration challenges in healthcare are not to eliminate trust in AI but ",
        "confidence": 0.16,
        "weight": 0.6,
        "admiralty": "C3",
        "verification": "partial"
      },
      {
        "text": "humans and AI have comparable performance alone demonstrate that confidence info",
        "confidence": 0.16,
        "weight": 1.0,
        "admiralty": "C3",
        "verification": "partial"
      },
      {
        "text": "whether calibration improves after practice and whether calibration of own relia",
        "confidence": 0.16,
        "weight": 0.6,
        "admiralty": "C3",
        "verification": "partial"
      }
    ],
    "cross_confidence": 0.1133
  },
  "summary": {
    "winner": "GPT-4o",
    "avg_confidence_gpt4o": 0.26789999999999997,
    "avg_confidence_sonnet": 0.12975,
    "timestamp": "2026-02-19T12:25:15.574111",
    "topic": "Trust Calibration for AI Agents"
  }
}