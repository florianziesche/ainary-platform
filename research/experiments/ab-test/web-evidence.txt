- [2503.15511] The Trust Calibration Maturity Model for Characterizing and Communicating Trustworthiness of AI Systems: Abstract page for arXiv paper 2503.15511: The Trust Calibration Maturity Model for Characterizing and Communicating Trustworthiness of AI Systems (https://arxiv.org/abs/2503.15511)
- UUR 1 SAND2025-00999O The Trust Calibration Maturity Model for: known (Chai et al., 2020; Münchmeyer et al., 2022; Myren et al., 2025; Park et al., 2024), no (https://arxiv.org/pdf/2503.15511)
- TYPE Opinion PUBLISHED 04 September 2025 DOI 10.3389/fcomp.2025.1638657: Puranam, 2024; Yuan and Hu, 2024). The challenge is not to eliminate trust in AI tutors but · to calibrate it—ensuring that trust is informed, tentative, and (https://www.frontiersin.org/journals/computer-science/articles/10.3389/fcomp.2025.1638657/pdf)
- From Trust in Automation to Trust in AI in Healthcare: A 30-Year Longitudinal Review and an Interdisciplinary Framework - PMC: In what follows, Section 3 addresses ... a research agenda rather than to exhaust all studies or perform a meta-analysis. <strong>We include English, peer-reviewed publications from 1995 through June 2025</strong>.... (https://pmc.ncbi.nlm.nih.gov/articles/PMC12562135/)
- Trust Calibration for Joint Human/AI Decision-Making in ...: ACM Charles P. &quot;Chuck&quot; Thacker Breakthrough in Computing Award 2025 · For fundamental contributions to the design and automation of field-programmable systems and customizable computing. View Profile ... ACM A. M. Turing Award 2024 (https://dl.acm.org/doi/10.1007/978-3-031-93412-4_6)
- Adaptive trust calibration for human-AI collaboration - PMC: Our results indicated that they are not always sufficient to recover from over-trust, and our method of adaptive trust calibration significantly helped the participants change their behavior and recover from the over-trust. Despite several limitations, this study has demonstrated the effectiveness of presenting cognitive cues at the time of over-trust. We strongly believe that the findings of this study will contribute to better user interface designs for collaborative systems with autonomous AI agents. (https://pmc.ncbi.nlm.nih.gov/articles/PMC7034851/)
- A Systematic Review on Fostering Appropriate Trust in Human-AI Interaction: Trends, Opportunities and Challenges | ACM Journal on Responsible Computing: A seminal article by Lee and See [106] in 2004 provided the first conceptual model of the relationship among calibration, resolution, and automation capability in defining appropriate trust in automation. This work by Lee and See was built on the key work by Cohen et al. [36] in 1998. The Lee &amp; See model was based on purpose, process, and performance dimensions of information that describe the goal-oriented characteristics of the agent to maintain an appropriate level of trust. In 2006, Duez et al. [48] followed Lee and See’s model to study information requirements for appropriate trust in automation, whereas Dongen and van Maanen [187] investigated whether calibration improves after practice and whether calibration of own reliability differs from calibration of the aid’s reliability. (https://dl.acm.org/doi/10.1145/3696449)
- Adaptive trust calibration for human-AI collaboration | PLOS One: Our results indicated that they are not always sufficient to recover from over-trust, and our method of adaptive trust calibration significantly helped the participants change their behavior and recover from the over-trust. Despite several limitations, this study has demonstrated the effectiveness of presenting cognitive cues at the time of over-trust. We strongly believe that the findings of this study will contribute to better user interface designs for collaborative systems with autonomous AI agents. (https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0229132)
- Dynamic calibration of trust and trustworthiness in AI-enabled systems | International Journal on Software Tools for Technology Transfer | Springer Nature Link: In the context of AI-enabled systems, ... system-side counterpart to trust is trustworthiness. <strong>When trust and trustworthiness are aligned with each other, there is calibrated trust</strong>.... (https://link.springer.com/article/10.1007/s10009-026-00840-6)
- Calibrating Trust in AI-Assisted Decision Making: Zhang et al. conducted a case study of AI-assisted decision making in which humans and AI · have comparable performance alone, and explores whether confidence or a local explanation · can calibrate trust and improve the joint performance of the human and AI (Zhang et al. (https://www.ischool.berkeley.edu/sites/default/files/sproject_attachments/humanai_capstonereport-final.pdf)
- A Systematic Review on Fostering Appropriate Trust in Human-AI Interaction: Trends, Opportunities and Challenges | ACM Journal on Responsible Computing: The Lee &amp; See model was based on purpose, process, and performance dimensions of information that describe the goal-oriented characteristics of the agent to maintain an appropriate level of trust. In 2006, Duez et al. [48] followed Lee and See’s model to study information requirements for appropriate trust in automation, whereas Dongen and van Maanen [187] investigated whether calibration improves after practice and whether calibration of own reliability differs from calibration of the aid’s reliability. (https://dl.acm.org/doi/10.1145/3696449)
- A Systematic Review on Fostering Appropriate Trust in Human-AI Interaction:: of dynamic trust and trust variations to the Human-AI interaction [106, 138]. We define calibrated trust as similar · to the appropriate trust in that a human’s trust belief about the agent corresponds to their actual trustworthiness. (https://arxiv.org/pdf/2311.06305)
- Developing trustworthy artificial intelligence: insights from research on interpersonal, human-automation, and human-AI trust - PMC: <strong>Machine learning algorithms were then used to estimate trust based on these data</strong>. This real-time assessment of trust is critical for capturing its dynamic changes, thereby facilitating trust calibration. AI typically refers to the simulation of human intelligence by computers (Gillath et al., 2021). (https://pmc.ncbi.nlm.nih.gov/articles/PMC11061529/)
- Dynamic calibration of trust and trustworthiness in AI-enabled systems | International Journal on Software Tools for Technology Transfer | Springer Nature Link: Brzowski, M., Nathan-Roberts, D.: Trust measurement in human–automation interaction: a systematic review. In: Proceedings of the Human Factors and Ergonomics Society Annual Meeting, vol. 63, pp. 1595–1599. SAGE Publications Sage CA, Los Angeles (2019) ... Carter, J.A.: Simion and kelp on trustworthy AI. (https://link.springer.com/article/10.1007/s10009-026-00840-6)
- Adaptive trust calibration for human-AI collaboration - PMC: In the following subsections, we review related work on trust calibration and propose our adaptive trust calibration approach. Next, we cover our experiment and the results. Finally, we discuss the results and describe our future work. Extensive research has been conducted to examine the factors that influence a human’s trust in autonomous agents such as automation. (https://pmc.ncbi.nlm.nih.gov/articles/PMC7034851/)
- Benchmarking real-time trust scoring across five AI Agent architectures: You can <strong>calibrate the trustworthiness threshold on a eval set to find the appropriate threshold that satisfies this error tolerance, and then quickly get your AI Agent into production</strong>. (https://cleanlab.ai/blog/agent-tlm-hallucination-benchmarking/)
- [2503.15511] The Trust Calibration Maturity Model for Characterizing and Communicating Trustworthiness of AI Systems: <strong>The TCMM incorporates five dimensions of analytic maturity: Performance Characterization, Bias &amp; Robustness Quantification, Transparency, Safety &amp; Security, and Usability</strong>. The TCMM can be presented along with system performance information to ... (https://arxiv.org/abs/2503.15511)
- UUR 1 SAND2025-00999O The Trust Calibration Maturity Model for: Table 2: The Trust Calibration Maturity Model (TCMM) provides a structured path for characterizing and · communicating the maturity of trustworthiness of a given AI system for use on a target task. ... ROUGE score, and many more (see (Liang et al., 2023) for a discussion of holistic metric usage). For foundation models and generative AI, performance is often measured against public · benchmarks on broad tasks related to the application the system is designed for. (https://arxiv.org/pdf/2503.15511)
- Measuring and Understanding Trust Calibrations for Automated Systems: A Survey of the State-Of-The-Art and Future Directions | Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems: Based on the trust calibrations from all survey papers, we develop four trust calibration dimensions that reflect the different calibration strategies and their key advantages and shortcomings: (1) exo versus endo trust calibrations, (2) warranted versus unwarranted trust calibrations, (3) static versus adaptive trus t calibrations, and (4) capabilities versus process-oriented trust calibrations. We close our paper by summarizing our observations, identifying potential gaps, and providing recommendations for future work. For this work, we follow Lee and See’s [74] definition of trust in automation, which is defined as “the attitude that an agent will help achieve an individual’s goals in a situation characterized by uncertainty and vulnerability” (p. (https://dl.acm.org/doi/full/10.1145/3544548.3581197)
- Adaptive trust calibration for human-AI collaboration - PMC: Based on these pieces of literature, we designed four types of TCCs (Visual/Audio/Verbal/Anthropomorphic) and evaluated them in the experiment. Details will be explained in the next section. With the framework and TCCs described above, we propose a method of adaptive trust calibration as follows. (Details of the detection algorithm will be described later). ... Observe a user’s reliance behavior on an agent. (https://pmc.ncbi.nlm.nih.gov/articles/PMC7034851/)