# Research Inbox — 2026-02-17

**Scan:** 7 new articles | **Relevant:** 4 | **Top Score:** 8/10

---

## Top Articles

### 1. Will I Be Paid in Tokens? (8/10)
**Source:** Tomasz Tunguz  
**Link:** https://www.tomtunguz.com/inference-as-compensation/  
**Summary:** AI inference costs as a new compensation component—author scaled from $7.2K to $100K run rate using agent subscriptions, then migrated to open-source models with testing loops to achieve 12% cost at same performance. Companies now treating inference budgets like salary bands.

**Why relevant:** Agent economics, operational patterns, testing/verification loops for agent parity, practical cost management for agentic workflows.

---

### 2. Claude Code Shrinking Question-to-Answer Distance (7/10)
**Source:** Simon Willison (quoting Dimitris Papailiopoulos)  
**Link:** https://simonwillison.net/2026/Feb/17/dimitris-papailiopoulos/  
**Summary:** Researcher describes Claude Code as reducing the gap between research questions and first answers to "just me, Claude Code, and a few days of GPU time"—replacing the need for student assistants for initial signal exploration.

**Why relevant:** Agentic research workflows, self-directed exploration, compound intelligence through AI-assisted ideation.

---

### 3. How to Do AI Analysis You Can Actually Trust (6/10)
**Source:** Lenny's Newsletter  
**Link:** https://www.lennysnewsletter.com/p/how-to-do-ai-analysis-you-can-actually  
**Summary:** Deep dive on AI reliability in user research—covers quote verification, hallucination detection, false insights, and model comparison (Claude vs ChatGPT vs Gemini). Includes practical prompting techniques for trustworthy analysis output.

**Why relevant:** Agent trust calibration, verification protocols, preventing overconfidence in agent output—critical for compound intelligence systems.

---

### 4. Open Models in Perpetual Catch-Up (5/10)
**Source:** Interconnects  
**Link:** https://www.interconnects.ai/p/open-models-in-perpetual-catch-up  
**Summary:** Analysis of open vs. closed model performance gap (~6 months steady), Chinese model ecosystem collaboration patterns, and sovereign AI trends. Argues open models stay closer than expected despite resource gaps.

**Why relevant:** Model selection for agent systems, cost vs. capability trade-offs, global AI diffusion—less about agent architecture, more about landscape.

---

## Not Relevant (3)

- **First kākāpō chick...** (Simon Willison) — Wildlife/nature
- **Star Trek opening narration draft** (Simon Willison) — Historical pop culture
- **Duplicate:** Lenny's Newsletter article appeared twice in feed

---

**Next Actions:**
- Tunguz piece worth deep read for cost optimization patterns
- Papailiopoulos quote reinforces existing compound intelligence thesis
- Lenny's verification tactics → consider for agent output QA protocols
