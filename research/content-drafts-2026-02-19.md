# LinkedIn Post Drafts — 2026-02-19

---

## Draft 1: YC's Spring 2026 RFS + My Take

**Hook:** YC just published their Spring 2026 RFS. Here's what it means if you're building AI infrastructure.

**Body:**

Seven categories. Three match my background exactly.

**AI-Native Agencies** — YC wants "agencies that look like software companies, with software margins." That's what I built with Ainary: AI consulting + execution with agents instead of junior consultants. Scaling like software, not like McKinsey.

**Make LLMs Easy to Train** — They're looking for APIs that abstract training, databases for large datasets, dev environments for ML research. AgentTrust is part of this: infrastructure for trust & governance in agentic systems. I know how to build €5M SaaS infrastructure (36ZERO proved that).

**AI for Government** — I spent years selling to BMW, Siemens, Bosch. Government is the same problem × 10: slow adoption, compliance nightmares, auditability requirements. AgentTrust solves that. I know how to sell there.

The common thread? Infrastructure for AI systems that scale. Not research — execution.

**CTA:**  
Building in one of these areas? Let's talk.

---

**Word count:** 168  
**Tone check:** Direct, no filler, hook first ✓  
**Anti-LLM:** Varied sentence structure, personal background, no "Here's the thing" ✓  
**Source:** research/yc-rfs-spring-2026-analysis.md

---

## Draft 2: We Built a Knowledge Graph in One Night

**Hook:** Last night my AI co-founder and I unified three knowledge systems in four hours.

**Body:**

The problem: Agent memory was scattered. Daily logs in one place. Semantic embeddings in another. Platform sync running separately. Every search meant checking three systems.

We fixed it.

**Single source of truth:** Symlinked the workspace to the Obsidian Vault. Now there's one folder, not two.

**Backlink index:** 557 files, 1,442 links, 197 orphans identified. The agent can navigate its own knowledge graph.

**Semantic search:** 4,884 chunks embedded, 98MB. Context retrieval went from "grep and hope" to "find the relevant paragraph in 200ms."

**Platform sync:** 25 topics + 106 findings auto-exported to the Vault every night. Trust scores, decisions, everything.

The result? My agent went from "I think I remember" to "here's the exact file, line 47, written on Feb 12."

Most knowledge management systems fail because they optimize for human UX, not machine retrieval. Backlinks + embeddings + single source of truth = agents that actually learn.

**Lesson:** You don't need more systems. You need one system with three interfaces.

**CTA:**  
How do you manage your AI agent's memory?

---

**Word count:** 224  
**Tone check:** Technical but accessible, storytelling over framework ✓  
**Anti-LLM:** Short sentences, then longer. No perfect parallelism. No "genuinely" or "Here's the thing" ✓  
**Source:** memory/daily/2026-02-19.md (Night Sprint 01:30-04:35)

---

## Publishing Checklist

Before posting:
- [ ] Read out loud — does it sound human?
- [ ] Every number has a source (or is personal experience)
- [ ] No "we" when I mean "I" (Draft 2: "my AI co-founder" = acceptable)
- [ ] Would I send this to 1,000 strangers? (Confidence check)
- [ ] Concrete takeaway exists? (Draft 1: RFS match, Draft 2: Single system > multiple)
- [ ] Run through Anti-LLM checklist (no LLM tells, varied structure)

---

**Erstellt:** 2026-02-19, 04:54 CET  
**Standard:** standards/CONTENT-VOICE.md  
**Status:** READY TO REVIEW — Florian entscheidet ob Post 1, Post 2, oder beide
