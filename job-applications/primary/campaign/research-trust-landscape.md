# Trust in AI Agents: Research Landscape 2025-2026

**Research Goal:** Validate Florian's "trust-as-a-currency" framework by identifying who else is thinking about trust-as-a-metric for agent systems.

**Date:** February 18, 2026  
**Status:** Interview-ready references

---

## Executive Summary

Trust has emerged as **the bottleneck** for AI agent deployment in 2025-2026. The research validates Florian's "trust-as-a-currency" framework: multiple sources independently describe trust not just as a checkbox but as an **operational metric, constraint, and competitive advantage** in agent systems.

**Key validation points:**
- Google Cloud CTO: "Trust became the bottleneck" (Dec 2025)
- OriginTrail: "Trust is Capital" — treating integrity as first-class requirement
- HBR Survey: Only 6% of companies fully trust AI agents for core processes
- ArXiv TRiSM framework: Trust, Risk, Security Management as system architecture
- Academic validation: Trust scales, metrics, and multi-dimensional frameworks

---

## 1. Academic Papers & Frameworks (2025-2026)

### 1.1 TRiSM for Agentic AI (ArXiv, Dec 2025)
**Citation:** Raza, S., Sapkota, R., Karkee, M., & Emmanouilidis, C. (2025). *TRiSM for Agentic AI: A Review of Trust, Risk, and Security Management in LLM-based Agentic Multi-Agent Systems*. arXiv:2506.04133v5.

**Why it matters:**
- **Trust as architecture**, not afterthought: Proposes Trust, Risk, and Security Management (TRiSM) as five pillars (Explainability, ModelOps, Security, Privacy, Governance)
- Introduces **Component Synergy Score (CSS)** and **Tool Utilization Efficacy (TUE)** as trust metrics
- Validates that "as AI systems gain autonomy, robust trust, risk mitigation, and security controls become indispensable"
- Trust-specific risks: coordination failures, prompt injection, memory poisoning, emergent misbehavior

**Florian's angle:** This paper operationalizes trust as **system-level controls**. Your framework goes further: trust as a tradeable, measurable resource that agents spend/earn.

**URL:** https://arxiv.org/html/2506.04133v5

---

### 1.2 Measuring Trust in AI: Validated Scale (Frontiers in AI, Apr 2025)
**Citation:** McGrath, M.J., Lack, O., Tisch, J., & Duenser, A. (2025). *Measuring trust in artificial intelligence: validation of an established scale and its short form*. Frontiers in Artificial Intelligence, 10.3389/frai.2025.1582880.

**Why it matters:**
- **Trust is measurable**: Validates Trust in Automation Scale (TIAS) and develops Short Trust in Automation Scale (S-TIAS)
- Trust predicts **behavioral intention** — users rely on AI when trust is calibrated
- Trust calibration concept: "user trust must be appropriately calibrated to the capabilities of the system" — too much = misuse, too little = disuse
- Multi-dimensional: performance, integrity, reliability as trust components

**Florian's angle:** Your framework extends this: trust isn't just calibration for *individual* decisions, but a **budget** that depletes/regenerates over multiple interactions.

**URL:** https://www.frontiersin.org/journals/artificial-intelligence/articles/10.3389/frai.2025.1582880/full

---

### 1.3 Trustworthiness Assessment Model — TrAM (ScienceDirect, Apr 2025)
**Citation:** *How do we assess the trustworthiness of AI? Introducing the trustworthiness assessment model (TrAM)*. ScienceDirect, April 14, 2025.

**Why it matters:**
- Distinguishes **system characteristics, actual trustworthiness, perceived trustworthiness, individual standards, and cues**
- Trust as multi-layered: not just "does the AI work?" but "do stakeholders believe it works, and why?"
- Framework for **auditing** trustworthiness claims

**Florian's angle:** TrAM focuses on static assessment. Your framework adds dynamics: trust as a **time-series metric** that agents must actively manage.

**URL:** https://www.sciencedirect.com/science/article/pii/S0747563225001189

---

### 1.4 Evaluating AI Trustworthiness: Metrics & Applications (MDPI, Jul 2025)
**Citation:** *Evaluating Trustworthiness in AI: Risks, Metrics, and Applications Across Industries*. MDPI Electronics 14(13):2717, July 4, 2025.

**Why it matters:**
- Explores **metrics for evaluating AI trustworthiness**: fairness, transparency, privacy, security
- Industry applications: what trust looks like in healthcare vs. finance vs. supply chain
- Trust as **risk mitigation** across industries

**Florian's angle:** Industry-specific trust thresholds = different "exchange rates" for trust-as-currency in different domains.

**URL:** https://www.mdpi.com/2079-9292/14/13/2717

---

## 2. Industry Reports & Thought Leadership

### 2.1 Google Cloud: "Trust Became the Bottleneck" (Dec 2025)
**Citation:** Grannis, W., et al. (2025). *Lessons from 2025 on agents and trust from The Office of the CTO*. Google Cloud Blog, December 19, 2025.

**Why it matters:**
- **"Three things defined 2025: agents got jobs, evaluation became architecture, and trust became the bottleneck."**
- Trust as integration challenge: "humans lack complete trust in AI... requires robust processes allowing gradual integration"
- Troy Trimble (Google): "After successful integrations build trust, we'll transition to AI-first systems"
- Trust as prerequisite for autonomy: "trust deficit requires robust processes"

**Florian's angle:** Perfect validation. Google identifies trust as **the constraint** on agent deployment. Your framework: make that constraint *visible, measurable, and tradeable*.

**URL:** https://cloud.google.com/transform/ai-grew-up-and-got-a-job-lessons-from-2025-on-agents-and-trust

---

### 2.2 OriginTrail: "Trust is Capital" (Dec 2025)
**Citation:** OriginTrail Team. (2025). *5 Trends to drive the AI ROI in 2026: Trust is Capital*. Medium/OriginTrail, December 23, 2025.

**Why it matters:**
- **"Trust is Capital"** — direct framing as economic asset
- I-DIKW framework: Integrity → Data → Information → Knowledge → Wisdom (trust as foundation)
- "Leading firms will treat AI integrity (security, ethics, and transparency) as a **first-class requirement**"
- Case study: Switzerland rejected Palantir due to "unacceptable risks" to data sovereignty — **trust as deal-breaker**
- "Control over data = trust. Trusted data is the fuel for AI ROI."

**Florian's angle:** Closest parallel to your framework. OriginTrail treats trust as **infrastructure investment**. You go further: trust as **operational currency** that agents spend/earn per-action.

**URL:** https://medium.com/origintrail/5-trends-to-drive-the-ai-roi-in-2026-trust-is-capital-372ac5dabc38

---

### 2.3 HBR/Fortune: Only 6% Trust AI Agents (Dec 2025)
**Citation:** Harvard Business Review Analytic Services (sponsored by Workato & AWS). (2025). *Enterprise Agentic AI Survey*. Reported in Fortune, December 9, 2025.

**Why it matters:**
- **Only 6% of companies fully trust AI agents** to handle core business processes
- 72% say benefits outweigh risks, but trust is constrained to "lower-risk work"
- Trust deficit = adoption bottleneck: 43% restrict agents to "limited or routine operational tasks"
- "Without robust foundations in data quality, governance, and architecture, organizations risk falling into 'garbage in, garbage out' scenarios that **erode trust** rather than build it"

**Florian's angle:** Trust gap = market opportunity. Your framework: make trust **auditable and recoverable** so companies can cross the 6% → 100% threshold.

**URL:** https://fortune.com/2025/12/09/harvard-business-review-survey-only-6-percent-companies-trust-ai-agents/

---

### 2.4 Fast Company: "AI's Most Important Benchmark in 2026? Trust" (Dec 2025)
**Citation:** *AI's most important benchmark in 2026? Trust*. Fast Company, December 31, 2025.

**Why it matters:**
- "AI tools are just beginning to build trust with most users"
- Trust as **benchmark** — not just accuracy, but reliability over time

**Florian's angle:** Reinforces trust-as-metric framing.

**URL:** https://www.fastcompany.com/91462096/ai-trust-benchmark-2026-openai-anthropic

---

### 2.5 Foundation Capital: "AI Security as Board-Level Metric" (Jan 2026)
**Citation:** Foundation Capital. (2026). *Where AI is headed in 2026*. January 15, 2026.

**Why it matters:**
- "In 2026, I expect AI security to become as standard a board-level metric as **cybersecurity readiness**"
- Trust operationalized: security/compliance as **measurable KPIs** at executive level

**Florian's angle:** Trust escalating to C-suite. Your framework: make it *quantifiable* so boards can actually track it.

**URL:** https://foundationcapital.com/where-ai-is-headed-in-2026/

---

### 2.6 Trustible's 2026 AI Predictions (Jan 2026)
**Citation:** Trustible. (2026). *Trustible's 2026 AI Predictions*. Substack, January 7, 2026.

**Why it matters:**
- Transparency vs. adoption paradox: "transparency decreased overall in 2025... yet AI adoption increased"
- Trust ≠ transparency (Florian: trust as **outcome** metric, not just input)

**URL:** https://insight.trustible.ai/p/trustibles-2026-ai-predictions

---

## 3. Emerging Frameworks & Standards

### 3.1 Forbes: Six-Step Framework for Trust in Agentic AI (Oct 2025)
**Citation:** *A Six-Step Framework To Improve Trust And Accuracy In Agentic AI*. Forbes Tech Council, October 8, 2025.

**Why it matters:**
- **"Scaling is a gated progression"** — trust unlocks stages
- Begin with assistive copilots, prove accuracy, *then* broaden autonomy in stages
- Trust as gate, not binary

**Florian's angle:** Your framework adds *measurement* to these gates: quantify trust thresholds for each stage.

**URL:** https://www.forbes.com/councils/forbestechcouncil/2025/10/08/a-six-step-framework-to-improve-trust-and-accuracy-in-agentic-ai/

---

### 3.2 Medium: Establishing Trust in AI Agents (Sep 2025)
**Citation:** Masood, A. (2025). *Establishing Trust in AI Agents — I: Monitoring, Control, Reliability, and Accuracy*. Medium, September 17, 2025.

**Why it matters:**
- Trust through **monitoring and control** — real-time oversight
- Leading frameworks for trust: governance, explainability, auditability

**URL:** https://medium.com/@adnanmasood/establishing-trust-in-ai-agents-i-monitoring-control-reliability-and-accuracy-f440664df5fd

---

### 3.3 Forbes: Agentic AI Redefines Digital Trust (Oct 2025)
**Citation:** Bradley, T. (2025). *How Agentic AI Redefines Digital Trust*. Forbes, October 10, 2025.

**Why it matters:**
- "Think of an autonomous customer-service agent empowered to issue refunds. Its authority must be limited by transaction size, frequency and context—and those parameters must be **enforced cryptographically, not manually**"
- Trust as **programmable constraint**

**Florian's angle:** Trust-as-currency enables cryptographic enforcement: agents check trust balance before high-stakes actions.

**URL:** https://www.forbes.com/sites/tonybradley/2025/10/10/how-agentic-ai-redefines-digital-trust/

---

### 3.4 MDPI: Consumer Trust & Acceptance of AI Agents (Mar 2025)
**Citation:** *How Do Consumers Trust and Accept AI Agents? An Extended Theoretical Framework and Empirical Evidence*. MDPI Behavioral Sciences 15(3):337, March 10, 2025.

**Why it matters:**
- Ethical expectations variable: explainability, transparency, ethical norms
- Trust → acceptance → usage

**URL:** https://www.mdpi.com/2076-328X/15/3/337

---

## 4. Enterprise Implementation & Tools

### 4.1 KPMG: 72% Plan to Deploy Agents from Trusted Providers (Jan 2026)
**Citation:** KPMG. (2026). *AI at Scale: How 2025 Set the Stage for Agent-Driven Enterprise Reinvention in 2026*. Q4 AI Pulse, January 15, 2026.

**Why it matters:**
- Trust as vendor selection criterion: **72% plan to deploy agents from trusted technology providers**
- Data privacy up from 53% → 77% concern
- Trust hardening: "pragmatically by hardening platforms, controls, and integration"

**URL:** https://kpmg.com/us/en/media/news/q4-ai-pulse.html

---

### 4.2 Microsoft: AI Agent Performance = Three Pillars (Feb 2026)
**Citation:** Microsoft Dynamics 365. (2026). *AI Agent Performance Measurement: Redefining Excellence*. February 4, 2026.

**Why it matters:**
- "To build AI agents that customers truly **trust**, organizations must move beyond fragmented metrics"
- Composite approach: unified measure of quality across capabilities
- **Trust as outcome metric**, not input

**URL:** https://www.microsoft.com/en-us/dynamics-365/blog/it-professional/2026/02/04/ai-agent-performance-measurement/

---

### 4.3 Kore.ai: Agent Evaluation Metrics (Feb 2026)
**Citation:** Kore.ai. (2026). *AI Agent Evaluation: Reliable, Compliant & Scalable AI Agents*. Blog, February 13, 2026.

**Why it matters:**
- Key metrics include: **latency, error rate, tool invocation accuracy, groundedness, hallucination rate, bias detection, PII protection, containment rate, CSAT/ESAT scores, revenue impact**
- Continuous monitoring for trustworthiness

**URL:** https://www.kore.ai/blog/ai-agents-evaluation

---

## 5. Key Concepts & Convergences

### Validation of "Trust-as-a-Currency" Framework

| Source | Concept | Alignment with Florian's Framework |
|--------|---------|-----------------------------------|
| **Google Cloud CTO** | "Trust became the bottleneck" | Trust = limiting constraint on agent capability |
| **OriginTrail** | "Trust is Capital" | Trust = economic asset, ROI driver |
| **HBR Survey** | 6% trust threshold | Trust deficit = adoption gap (opportunity) |
| **ArXiv TRiSM** | Component Synergy Score, Tool Utilization Efficacy | Trust = measurable system property |
| **Frontiers in AI** | Trust calibration, behavioral intention | Trust = predictive metric for agent usage |
| **Forbes (Bradley)** | "Authority limited by parameters enforced cryptographically" | Trust as programmable constraint |
| **Foundation Capital** | "AI security as board-level metric" | Trust escalates to strategic KPI |

### Emerging Terminology

1. **Trust calibration** — matching user trust to system capability (under-trust = disuse, over-trust = misuse)
2. **Trust as bottleneck** — deployment constraint that must be actively managed
3. **Trust as capital/infrastructure** — investment that enables future ROI
4. **Trust metrics** — CSS, TUE, TIAS, trustworthiness scores
5. **Trust gating** — staged deployment based on trust thresholds
6. **Trust erosion** — systems that lose trust over time without governance
7. **Trust-first architecture** — designing with trust as first-class requirement

---

## 6. Interview-Ready Talking Points

**When discussing the "trust-as-a-currency" framework:**

1. **"Trust became the bottleneck in 2025"** (Google Cloud CTO)  
   → Position yourself as solving **the** limiting constraint for agent deployment

2. **"Only 6% of companies fully trust AI agents"** (HBR)  
   → Market gap: trust deficit = $X billion in unrealized automation value

3. **"Trust is Capital"** (OriginTrail)  
   → Your framework operationalizes this: make trust **visible, measurable, tradeable**

4. **"Trust as architecture, not afterthought"** (ArXiv TRiSM)  
   → Academic validation: trust requires system-level design (CSS, TUE metrics)

5. **"Enforced cryptographically, not manually"** (Forbes)  
   → Technical implementation: agents check trust balance before high-stakes actions

6. **"AI security as board-level metric"** (Foundation Capital)  
   → Trust escalates to strategic priority — VCs/enterprises need visibility

---

## 7. Gaps & Opportunities (Where Florian Differentiates)

**What existing research covers:**
- Trust as **static assessment** (TrAM, TIAS)
- Trust as **architecture pillar** (TRiSM)
- Trust as **binary gate** (low-risk vs. high-risk tasks)

**What Florian's framework adds:**
- Trust as **dynamic, depleting/regenerating resource** (currency metaphor)
- Trust as **tradeable** between agents (trust markets?)
- Trust as **real-time operational constraint** (not just design-time consideration)
- Trust **accounting**: earned, spent, audited, recovered
- Trust as **competitive moat**: agents with higher trust scores win more delegations

**Analogy upgrade:**
- Existing: "Trust is like a foundation" (static, binary)
- Florian: "Trust is like a bank account" (dynamic, quantified, transactional)

---

## 8. References for Citations

### Academic (peer-reviewed)
1. Raza et al. (2025) — TRiSM for Agentic AI, arXiv
2. McGrath et al. (2025) — Measuring Trust in AI, Frontiers in AI
3. MDPI (2025) — Evaluating Trustworthiness in AI: Metrics & Applications
4. ScienceDirect (2025) — Trustworthiness Assessment Model (TrAM)
5. MDPI (2025) — Consumer Trust & Acceptance of AI Agents

### Industry Reports
6. Google Cloud CTO (2025) — Lessons from 2025 on agents and trust
7. Harvard Business Review / Fortune (2025) — Enterprise Agentic AI Survey
8. OriginTrail (2025) — Trust is Capital: 5 Trends for AI ROI in 2026
9. KPMG (2026) — AI at Scale: Agent-Driven Enterprise Reinvention
10. Microsoft Dynamics 365 (2026) — AI Agent Performance Measurement

### Thought Leadership
11. Fast Company (2025) — AI's Most Important Benchmark: Trust
12. Foundation Capital (2026) — Where AI is headed in 2026
13. Forbes (Bradley, 2025) — How Agentic AI Redefines Digital Trust
14. Forbes Tech Council (2025) — Six-Step Framework for Trust in Agentic AI
15. Adnan Masood (2025) — Establishing Trust in AI Agents (Medium)
16. Trustible (2026) — 2026 AI Predictions
17. Kore.ai (2026) — AI Agent Evaluation

---

## 9. Next Steps

**For interview prep:**
1. Memorize 3-5 key stats (6%, "trust became bottleneck", "trust is capital")
2. Practice pivot: "Academic research validates trust-as-metric. My framework goes further: trust-as-*currency*."
3. Prepare case study: How would trust accounting work in [interviewer's domain]?

**For deeper validation:**
- Check if any sources cite "trust economy" or "trust markets" (economic framing)
- Look for game-theoretic models of trust in multi-agent systems
- Explore blockchain/crypto literature on "proof of trust" mechanisms

---

**Research completed:** Feb 18, 2026  
**Confidence:** High — multiple independent sources validate trust-as-metric/capital framing  
**Differentiation:** Clear — Florian's currency metaphor adds operational dynamics to existing static/architectural approaches
