# Source Log — AR-001-v2.3: State of AI Agent Trust 2026
Generated: 2026-02-15 | Research Agent | Phase 2
Updated: 2026-02-15 | Research Agent | Phase 2 (v2.3 — Source Diversity Supplement)

---

## S1
- Title: The Agentic Reality Check: Preparing for a Silicon-Based Workforce (Deloitte Tech Trends 2026)
- Publisher / Type: reputable_secondary
- URL: https://www.deloitte.com/us/en/insights/topics/technology-management/tech-trends/2026/agentic-ai-strategy.html
- Publication date: 2025-12-10
- Access date: 2026-02-15
- Freshness check: WITHIN_WINDOW
- Key points:
  - Only 14% of enterprises have agentic AI solutions ready for deployment; 11% actively in production
  - Pilots built through strategic partnerships are 2x more likely to reach full deployment vs built internally
  - Gartner predicts >40% of agentic AI projects canceled by end of 2027
  - Toyota case study: agents replacing 50-100 mainframe screen workflows
  - Mapfre insurance: hybrid human-agent design with governance-first approach
- Supports: C1, C5, C8, C13, C15
- Caveats/limits: Deloitte's own survey methodology not fully disclosed; sample size unclear
- Quality: High

## S2
- Title: G2's Enterprise AI Agents Report: Industry Outlook for 2026
- Publisher / Type: reputable_secondary
- URL: https://learn.g2.com/enterprise-ai-agents-report
- Publication date: 2025-12-17
- Access date: 2026-02-15
- Freshness check: WITHIN_WINDOW
- Key points:
  - G2 Aug 2025 survey: 57% of companies have AI agents in production, 22% in pilot, 21% pre-pilot
  - 3 out of 4 companies invested in AI agents within the past year
  - Trust remains central concern: accuracy, explainability, security cited as top concerns
  - >25% of enterprises report meaningful impact within 3 months; median time-to-value 6 months
  - Cross-functional deployment patterns across IT, customer support, HR, marketing, finance
- Supports: C1, C2, C6, C10
- Caveats/limits: Survey of 5 enterprise vendors (small sample, potential self-selection bias); Aug 2025 broader survey methodology not detailed
- Quality: Medium

## S3
- Title: AI Adoption Trends in the Enterprise 2026 (TechRepublic)
- Publisher / Type: reputable_secondary
- URL: https://www.techrepublic.com/article/ai-adoption-trends-enterprise/
- Publication date: 2026-01-07
- Access date: 2026-02-15
- Freshness check: WITHIN_WINDOW
- Key points:
  - Survey of 120,000+ enterprise respondents (March 2025–January 2026)
  - Only 8.6% have AI agents deployed in production
  - 14% developing agents in pilot form
  - 63.7% report no formalized AI initiative
- Supports: C1, C2
- Caveats/limits: Could not deep-read (blocked by Cloudflare); stats from search snippet only. Contradicts G2 and others on adoption rates.
- Quality: Medium

## S4
- Title: Agentic AI Market Size to Hit USD 199.05 Billion by 2034 (Precedence Research)
- Publisher / Type: primary_research
- URL: https://www.precedenceresearch.com/agentic-ai-market
- Publication date: 2025-12-01
- Access date: 2026-02-15
- Freshness check: WITHIN_WINDOW
- Key points:
  - Global agentic AI market: $7.55B (2025) → $10.86B (2026) → $199.05B (2034)
  - CAGR 43.84% (2025-2034)
  - North America 46% market share (2024)
  - Cloud-based deployment: 62% share
  - Technology & software sector: 38% of market
- Supports: C3, C4
- Caveats/limits: Market research firm estimates; methodology not independently validated. Covers entire agentic AI market, not trust/governance segment specifically.
- Quality: Medium

## S5
- Title: AI Governance Market Size, Share and Trends 2025 to 2034 (Precedence Research)
- Publisher / Type: primary_research
- URL: https://www.precedenceresearch.com/ai-governance-market
- Publication date: 2025-11-05
- Access date: 2026-02-15
- Freshness check: WITHIN_WINDOW
- Key points:
  - AI governance market: $309M (2025) → $419M (2026) → $4.83B (2034)
  - CAGR 35.74% (2025-2034)
  - Separate from broader agentic AI market — this is the trust/governance tooling segment
- Supports: C3, C4, C14
- Caveats/limits: Market research estimates; not peer-reviewed. Separate report from GM Insights gives different numbers ($197.9M in 2024, 49.2% CAGR).
- Quality: Medium

## S6
- Title: Top AI Security Incidents of 2025 Revealed (Adversa AI)
- Publisher / Type: reputable_secondary
- URL: https://adversa.ai/blog/adversa-ai-unveils-explosive-2025-ai-security-incidents-report-revealing-how-generative-and-agentic-ai-are-already-under-attack/
- Publication date: 2025-07-31
- Access date: 2026-02-15
- Freshness check: WITHIN_WINDOW
- Key points:
  - 35% of all real-world AI security incidents caused by prompt injection
  - Some incidents led to $100K+ real losses
  - Agentic AI caused most dangerous failures: crypto thefts, API abuses, supply chain attacks
  - AI security incidents doubled since 2024
  - Failures at all layers: model, infrastructure, human oversight
- Supports: C7, C8, C9
- Caveats/limits: Adversa AI is a vendor (AI red teaming); potential incentive to emphasize threats. Report details behind download gate.
- Quality: Medium

## S7
- Title: AI Agents' Trust Reckoning: One Hack Fells 50, Exposing Urgent Need for Digital Identity Backbone (WebProNews)
- Publisher / Type: reputable_secondary
- URL: https://www.webpronews.com/ai-agents-trust-reckoning-one-hack-fells-50-exposing-urgent-need-for-digital-identity-backbone/
- Publication date: 2026-01-25 (approx, "3 weeks ago")
- Access date: 2026-02-15
- Freshness check: WITHIN_WINDOW
- Key points:
  - 50-agent ML system collapsed in 6 minutes from single compromised agent
  - Agent Name Service (ANS) proposed as "DNS for AI agents" — maps names to cryptographic identities
  - Supply chain attack on OpenAI plugin ecosystem: credentials from 47 enterprises harvested
  - Researchers deployed 44 AI agents, faced 1.8M attacks and 62,000 breaches
  - Salesforce "trust layer" tackles 80% enterprise AI project failure rate
  - Google A2A, Anthropic MCP, IBM ACP, Linux Foundation AAIF all addressing agent trust
- Supports: C7, C8, C9, C11, C12
- Caveats/limits: Aggregation article; primary sources cited but not all independently verified. Some claims from vendor sources.
- Quality: Medium

## S8
- Title: The 2025 AI Agent Security Landscape: Players, Trends, and Risks (Obsidian Security)
- Publisher / Type: blog (vendor)
- URL: https://www.obsidiansecurity.com/blog/ai-agent-market-landscape
- Publication date: 2026-01-15 (approx, "1 month ago")
- Access date: 2026-02-15
- Freshness check: WITHIN_WINDOW
- Key points:
  - AI agent security emerged as distinct discipline in 2025
  - Key attack vectors: token compromise, identity spoofing, data exfiltration via agent queries, excessive privilege accumulation, shadow agent deployments
  - Compliance frameworks ISO 42001, NIST AI RMF, GDPR now mandate controls for autonomous systems
  - Gartner: 40% of enterprise apps will embed agents by 2026 (from <5% in 2025)
  - Identity-first controls and real-time behavioral monitoring required
- Supports: C8, C9, C11, C12
- Caveats/limits: Vendor blog (Obsidian Security sells agent security); used as supplementary only
- Quality: Medium

## S9
- Title: EU AI Act 2026 Updates: Compliance Requirements and Business Risks (LegalNodes)
- Publisher / Type: reputable_secondary
- URL: https://www.legalnodes.com/article/eu-ai-act-2026-updates-compliance-requirements-and-business-risks
- Publication date: 2026-02-12 (approx, "3 days ago")
- Access date: 2026-02-15
- Freshness check: WITHIN_WINDOW
- Key points:
  - Full enforcement begins 2 August 2026
  - Risk-based classification: unacceptable (banned), high-risk (strict), limited risk (transparency), minimal risk
  - Organizations must continuously monitor, report incidents, cooperate with authorities
  - Penalties up to €35M or 7% of global revenue
  - High-risk AI in Annex III: may apply up to Dec 2027
- Supports: C5, C16, C17
- Caveats/limits: Legal analysis article, not primary regulatory text. Based on current reading of regulation.
- Quality: High

## S10
- Title: Gartner: Intelligent Agents in AI
- Publisher / Type: official
- URL: https://www.gartner.com/en/articles/intelligent-agent-in-ai
- Publication date: 2025-10-17
- Access date: 2026-02-15
- Freshness check: WITHIN_WINDOW
- Key points:
  - By 2028, 33% of enterprise software applications will include agentic AI (up from <1% in 2024)
  - 15% of day-to-day work decisions made autonomously
  - Gartner predicts >40% of agentic AI projects will be canceled by end of 2027
- Supports: C1, C2, C5, C15
- Caveats/limits: Gartner predictions have wide confidence intervals; could not access full report (paywall). Two seemingly conflicting predictions (40% apps embed agents by 2026 vs 33% by 2028) suggest different Gartner reports with different definitions.
- Quality: High

## S11
- Title: McKinsey State of AI Global Survey 2025
- Publisher / Type: primary_research
- URL: https://www.mckinsey.com/capabilities/quantumblack/our-insights/the-state-of-ai
- Publication date: 2025-11-05
- Access date: 2026-02-15
- Freshness check: WITHIN_WINDOW
- Key points:
  - Survey: 1,993 participants, 105 countries, June-July 2025
  - 88% of organizations deploy AI in at least one function
  - Only 6% classified as "winning" with AI (deep integration)
  - Agentic patterns emerging across IT, knowledge management, engineering
- Supports: C1, C2, C6
- Caveats/limits: Broad AI survey, not agent-specific. "88% adoption" includes basic AI usage, not agent-level autonomy.
- Quality: High

## S12
- Title: McKinsey: Reimagining the Value Proposition of Tech Services for Agentic AI
- Publisher / Type: primary_research
- URL: https://www.mckinsey.com/industries/technology-media-and-telecommunications/our-insights/reimagining-the-value-proposition-of-tech-services-for-agentic-ai
- Publication date: 2025-12-17
- Access date: 2026-02-15
- Freshness check: WITHIN_WINDOW
- Key points:
  - Survey of 200 C-suite executives (July 2025) across Asia, Europe, North America, 6 industries
  - Focused on agentic AI specifically
- Supports: C1, C6
- Caveats/limits: Could not deep-read full report. Stats from search snippet only.
- Quality: High

## S13
- Title: NIST AI Risk Management Framework
- Publisher / Type: standard
- URL: https://www.nist.gov/itl/ai-risk-management-framework
- Publication date: 2025-05-05 (last updated)
- Access date: 2026-02-15
- Freshness check: WITHIN_WINDOW
- Key points:
  - Voluntary framework for trustworthiness in AI design, development, use, evaluation
  - Four functions: GOVERN, MAP, MEASURE, MANAGE
  - Widely referenced for production AI governance
- Supports: C11, C16
- Caveats/limits: Framework document, not adoption data. Voluntary, not mandatory.
- Quality: High

## S14
- Title: Dayforce Achieves ISO 42001 Certification and NIST AI RMF Attestation
- Publisher / Type: official
- URL: https://www.globenewswire.com/news-release/2026/02/10/3235271/0/en/Dayforce-Advances-Trustworthy-AI-Through-Independent-Validation.html
- Publication date: 2026-02-10
- Access date: 2026-02-15
- Freshness check: WITHIN_WINDOW
- Key points:
  - Dayforce achieved ISO 42001 certification + NIST AI RMF attestation (Feb 2026)
  - One of the first enterprise HCM vendors to obtain both
  - Signals that dual-framework compliance is practical and achievable
- Supports: C11, C16
- Caveats/limits: Single company press release; not representative of broader adoption.
- Quality: Medium

## S15
- Title: AI Governance Tools: Selection and Security Guide for 2026 (Vectra AI)
- Publisher / Type: blog (vendor)
- URL: https://www.vectra.ai/topics/ai-governance-tools
- Publication date: 2026-02-08 (approx, "1 week ago")
- Access date: 2026-02-15
- Freshness check: WITHIN_WINDOW
- Key points:
  - IBM watsonx.governance 2.3.x (Dec 2025): agent inventory management, behavior monitoring, decision evaluation, hallucination detection
  - Growing vendor landscape for AI governance tooling
  - Forrester 2025 report highlights growing set of platforms spanning policy automation, model risk management, explainability, audit reporting
- Supports: C12, C14
- Caveats/limits: Vendor blog; used as supplementary. References Forrester report but doesn't link it.
- Quality: Low

## S16 (Internal)
- Title: State of AI Agent Trust 2026 — Ainary Report AR-001
- Publisher / Type: internal
- URL: /Users/florianziesche/.openclaw/workspace/content/reports/state-of-agent-trust-2026.html
- Publication date: 2026-02 (approx)
- Access date: 2026-02-15
- Freshness check: WITHIN_WINDOW
- Key points:
  - Three-layer trust model (Calibration, Verification, Economics)
  - Cost asymmetry: $0.005 per calibration check vs $5K-$3B+ failure cost
  - 95% corporate AI failure rate (MIT via secondary)
  - EU AI Act enforcement Aug 2026, penalties up to €35M/7% revenue
  - Tool-calling failure rates 3-15%
  - Overconfidence as missing failure mode (original claim)
- Supports: Cross-reference for all claims; NOT used as independent evidence
- Caveats/limits: Internal report. Several claims rely on single sources. Three-layer model is author's framework. VW Cariad example was multi-year strategic failure, not single agent error.
- Quality: N/A (internal)

## S17
- Title: 2026 State of Agentic Orchestration and Automation (Camunda)
- Publisher / Type: reputable_secondary
- URL: https://camunda.com/state-of-agentic-orchestration-and-automation/
- Publication date: 2026-01-13
- Access date: 2026-02-15
- Freshness check: WITHIN_WINDOW
- Key points:
  - 73% of organizations report a gap between their agentic AI vision and current reality
  - 71% of organizations using AI agents in some capacity
  - Only 11% of agentic use cases reached production in the last year
  - Report explores how enterprises can move from isolated agent experiments to orchestrated, governed agentic automation
- Supports: C1, C2, C5
- Caveats/limits: Camunda is a vendor (process orchestration); survey methodology and sample size not disclosed in summary materials
- Quality: Medium

---

## CONTRADICTION REGISTER

### CONTRADICTION 1
- Conflict: Enterprise AI agent production deployment rates vary wildly: 8.6% (TechRepublic/120K respondents) vs 11% (Deloitte) vs 57% (G2)
- Sources: S3 vs S1 vs S2
- Why they differ: definitions — G2 likely uses broad "AI agents" definition including simple automation; TechRepublic uses stricter "formalized AI agents in production"; Deloitte focuses on agentic AI specifically. Also methodology (G2 surveyed vendors/customers on their platform vs TechRepublic broader enterprise survey).
- Impact on thesis: High — the adoption baseline determines urgency of trust infrastructure. If 8.6%, there's more time; if 57%, urgency is critical.
- Resolution: Use Deloitte's 11% as conservative baseline for agentic AI specifically, acknowledge range. Note that even the low estimate shows acceleration.

### CONTRADICTION 2
- Conflict: Gartner predictions — "33% of enterprise software will include agentic AI by 2028" vs "40% of enterprise apps will embed agents by 2026"
- Sources: S10 (Gartner direct) vs S8/multiple secondary sources citing Gartner
- Why they differ: timeframe and definitions — the 33%/2028 figure is from Gartner's own published article (Oct 2025); the 40%/2026 figure appears in many secondary sources but may be from an earlier or different Gartner report, or the definition of "embed" differs from "include agentic AI."
- Impact on thesis: Moderate — both indicate massive growth, but the timeline matters for investment decisions.
- Resolution: Prefer Gartner's own published article (33% by 2028) as primary. Note the 40%/2026 figure exists in secondary sources but couldn't be verified at primary source.

### CONTRADICTION 3
- Conflict: Gartner also predicts >40% of agentic AI projects will be CANCELED by 2027
- Sources: S1 (Deloitte citing Gartner) vs S10 (Gartner adoption predictions)
- Why they differ: Not contradictory per se — both can be true (rapid adoption AND high failure). This reflects the typical hype-cycle pattern.
- Impact on thesis: Reinforces the case for trust infrastructure — without it, projects fail.
- Resolution: Use both data points together: adoption is accelerating AND failure rates are high → trust infrastructure is the differentiator.

---

## RECOMMENDED SOURCES STILL NEEDED

1. **Need: Gartner Magic Quadrant or Market Guide for AI Trust/Governance/Safety (if published 2025-2026)** — would provide definitive vendor landscape and adoption data
2. **Need: Forrester Wave for AI Governance platforms (referenced in S15 but not accessed)** — would validate vendor landscape claims
3. **Need: ISO 42001 adoption statistics from ISO directly** — number of certified organizations globally
4. **Need: NIST AI RMF adoption survey data** — how many enterprises are using the framework
5. **Need: Independent case study of enterprise trust infrastructure ROI** — currently no source provides hard ROI numbers for trust-specific (not general AI) investments
6. **Need: Gartner "Predicts Over 40% of Agentic AI Projects Will Be Canceled" full report (June 2025)** — only accessed via secondary citations
7. **Need: EU AI Office guidance on AI agent-specific compliance** — Code of Practice expected June 2026
8. **Need: PwC 2025 AI survey** (cited in secondary sources claiming "79% adoption") — could not verify primary source

---

## v2.3 SOURCE DIVERSITY SUPPLEMENT (2026-02-15)

### Source Diversity Audit (v2 baseline)

| Category | Count | Sources | % |
|---|---|---|---|
| Industry Reports (Gartner, Deloitte, McKinsey, Precedence, G2, Camunda) | 8 | S1, S2, S4, S5, S10, S11, S12, S17 | 50% |
| Trade/News/Vendor blogs | 7 | S3, S6, S7, S8, S9, S14, S15 | 44% |
| Standards/Regulatory | 1 | S13 | 6% |
| Academic/Peer-Reviewed | 0 | — | 0% |
| Practitioner/Contrarian | 0 | — | 0% |

**Finding:** Zero academic and zero contrarian sources. 94% industry/vendor. Critical gap for credibility and for challenging the report's pro-investment thesis.

---

### NEW SOURCES (v2.3)

## S18
- Title: Why Do Multi-Agent LLM Systems Fail? (UC Berkeley — Cemri, Pan, Yang et al.)
- Publisher / Type: Academic (arXiv / under review)
- URL: https://arxiv.org/abs/2503.13657
- Publication date: 2025-03-17 (updated Oct 2025)
- Access date: 2026-02-15
- Freshness check: WITHIN_WINDOW
- Key points:
  - 1,600+ annotated failure traces across 7 popular MAS frameworks
  - First multi-agent system failure taxonomy (MAST): 14 failure modes in 3 categories (system design, inter-agent misalignment, task verification)
  - State-of-the-art open-source MAS (ChatDev) correctness can be as low as 25%
  - Performance gains from multi-agent over single-agent are often minimal on benchmarks
  - High inter-annotator agreement (kappa = 0.88) — rigorous methodology
- Supports: C5, C7, C8, C9, C10 (strengthens); NEW claims C21, C22
- Caveats/limits: Benchmark tasks, not production enterprise deployments. arXiv preprint, peer review pending.
- Quality: High

## S19
- Title: TRiSM for Agentic AI: Trust, Risk, and Security Management in LLM-based Agentic Multi-Agent Systems (Raza et al.)
- Publisher / Type: Academic (arXiv)
- URL: https://arxiv.org/abs/2506.04133
- Publication date: 2025-06-04 (updated to v5)
- Access date: 2026-02-15
- Freshness check: WITHIN_WINDOW
- Key points:
  - Structured TRiSM framework adapted specifically for agentic multi-agent systems
  - Proposes Component Synergy Score (CSS) and Tool Utilization Efficacy (TUE) as measurable trust metrics
  - Risk taxonomy covering coordination failures, prompt-based adversarial manipulation, privacy leakage
  - Reviews explainability, security, privacy and lifecycle governance for AMAS
  - Systematic literature review (2022-2025)
- Supports: C9, C11, C12 (strengthens); NEW claim C23
- Caveats/limits: Framework paper — proposes metrics but limited empirical validation of CSS/TUE in production
- Quality: High

## S20
- Title: HBR/Workato Survey: Only 6% of Companies Fully Trust AI Agents for Core Processes (via Fortune)
- Publisher / Type: Primary Research (HBR Analytic Services, n=603)
- URL: https://fortune.com/2025/12/09/harvard-business-review-survey-only-6-percent-companies-trust-ai-agents/
- Publication date: 2025-12-09
- Access date: 2026-02-15
- Freshness check: WITHIN_WINDOW
- Key points:
  - Only 6% of companies fully trust AI agents for core business processes
  - 43% trust agents only for limited/routine tasks; 39% restrict to supervised/noncore
  - 9% have fully deployed agentic AI; 50% piloting/exploring
  - Only 20% say infrastructure fully ready; 12% say governance controls in place
  - 72% expect investment to increase over next 2 years
  - Readiness index: 27% leaders, 50% followers, 24% laggards
- Supports: C1, C2, C5, C10 (strongly strengthens); NEW claim C24
- Caveats/limits: Sponsored by Workato + AWS (vendor interest). Survey July 2025. n=603 is decent but self-selected business/tech leaders.
- Quality: High

## S21
- Title: AI Agents Have, So Far, Mostly Been a Dud (Gary Marcus)
- Publisher / Type: Practitioner/Contrarian (Substack)
- URL: https://garymarcus.substack.com/p/ai-agents-have-so-far-mostly-been
- Publication date: 2025-08-03
- Access date: 2026-02-15
- Freshness check: WITHIN_WINDOW
- Key points:
  - Marcus predicted (Jan 2025) agents would be "endlessly hyped but far from reliable except in very narrow use cases" — claims vindication
  - All major companies released agents but none are reliable for general use
  - ChatGPT agent launched with heavy caveats ("still in early stages")
  - Critique of vendor claims vs actual deployment reality
  - Highlights gap between announced capability and production reliability
- Supports: C5 (reinforces cancellation prediction); NEW claim C25
- Caveats/limits: Known AI skeptic — may overweight negatives. Blog post, not peer-reviewed. Anecdotal evidence.
- Quality: Medium (valuable as contrarian voice)

## S22
- Title: The Great AI Hype Correction of 2025 (MIT Technology Review)
- Publisher / Type: Practitioner/Critical (reputable tech journalism)
- URL: https://www.technologyreview.com/2025/12/15/1129174/the-great-ai-hype-correction-of-2025/
- Publication date: 2025-12-15
- Access date: 2026-02-15
- Freshness check: WITHIN_WINDOW
- Key points:
  - 2025 was a "year of reckoning" for AI — hype outpaced reality
  - GPT-5 launch (Aug 2025) was the biggest vibe shift — "more of the same"
  - Business uptake of AI tools is stalling (cites US Census Bureau, Stanford)
  - Studies show agents powered by top LLMs failed to complete many straightforward workplace tasks
  - FOMO-driven enterprise adoption failing to produce expected results
  - Core model improvements are no longer step changes
- Supports: C5, C1 (complicates); NEW claim C26
- Caveats/limits: Narrative journalism, not primary research. Synthesizes multiple studies without full citations.
- Quality: High (MIT Tech Review is reputable and well-sourced)

## S23
- Title: The Agentic AI Hype Cycle Is Out of Control — Yet Widely Normalized (Eric Siegel, Forbes)
- Publisher / Type: Practitioner/Contrarian
- URL: https://www.forbes.com/sites/ericsiegel/2025/07/28/the-agentic-ai-hype-cycle-is-insane--dont-normalize-it/
- Publication date: 2025-07-28
- Access date: 2026-02-15
- Freshness check: WITHIN_WINDOW
- Key points:
  - Argues the Gartner Hype Cycle itself normalizes irrational industry behavior
  - "Agentic AI" overpromising is worse than previous hype cycles
  - Critique of vendor marketing driving enterprise FOMO
  - "Agent-washing" emerging as vendors relabel existing automation as "agentic"
- Supports: C5; NEW claim C27
- Caveats/limits: Could not deep-read (Forbes paywall). Eric Siegel is a known ML practitioner and critic. Opinion piece.
- Quality: Medium (valuable as contrarian perspective from credible voice)

## S24
- Title: Measuring AI Ability to Complete Long Tasks (METR)
- Publisher / Type: Academic/Research org (arXiv + METR)
- URL: https://arxiv.org/abs/2503.14499
- Publication date: 2025-03-19 (updated Dec 2025)
- Access date: 2026-02-15
- Freshness check: WITHIN_WINDOW
- Key points:
  - AI agent task completion ability is doubling every ~7 months
  - Measured 50% time horizon (task length at which agents succeed 50% of the time)
  - 80% time horizon tasks are ~5x shorter — agents brittle on harder tasks
  - Progress driven by improved reasoning, tool use, and error recovery
  - Exponential capability growth BUT current absolute performance still limited for complex tasks
- Supports: C2 (adoption trajectory); NEW claim C28
- Caveats/limits: METR is an AI safety org — may frame results cautiously. Benchmark tasks, not enterprise workflows.
- Quality: High

## S25
- Title: 2023 State of Threat Detection (Vectra AI)
- Publisher / Type: primary_research (vendor)
- URL: https://www.vectra.ai/resources/2023-state-of-threat-detection
- Publication date: 2023-06-01 (approx)
- Access date: 2026-02-15
- Freshness check: OUTSIDE_WINDOW (2023) — used for established industry statistic
- Key points:
  - Survey of 2,000 SOC analysts globally
  - 67% of security alerts are ignored or not investigated
  - Alert fatigue is systemic across enterprise security operations
- Supports: §9 Step 5 (Governance Lag Cascade — human oversight failure)
- Caveats/limits: Vectra AI is a vendor (NDR/XDR); survey may oversample their customer base. 2023 data — pre-agentic era, but alert fatigue dynamics are structural.
- Quality: Medium

---

### CONTRADICTION REGISTER UPDATE (v2.3)

### CONTRADICTION 4
- Conflict: Agent capability is "doubling every 7 months" (METR/S24) vs "agents failed to complete many straightforward workplace tasks" (MIT Tech Review/S22 citing studies)
- Sources: S24 vs S22
- Why they differ: METR measures relative improvement on benchmarks; real-world tasks have different complexity distributions and require reliability, not average performance. Doubling from a low base can still mean unreliable.
- Impact on thesis: High — investment thesis assumes capability will catch up to trust needs. If capability growth is real but absolute performance is still poor, the trust infrastructure argument shifts from "govern capable agents" to "prevent premature deployment of incapable agents."
- Resolution: Both are true — capability IS improving exponentially AND current agents are unreliable. This STRENGTHENS the trust argument: the gap between what agents CAN do (narrow) and what enterprises TRY to deploy them for (broad) is the core risk.

### CONTRADICTION 5
- Conflict: Multi-agent systems show "minimal performance gains" on benchmarks (S18/UC Berkeley) vs industry reports claiming major enterprise value from multi-agent orchestration (S17/Camunda, S1/Deloitte)
- Sources: S18 vs S17, S1
- Why they differ: Academic benchmarks test correctness on defined tasks; industry reports measure business metrics (time saved, cost reduction) in narrow applied contexts. Also, industry surveys self-select for positive experiences.
- Impact on thesis: Moderate — calls into question whether multi-agent architectures (which the report assumes will proliferate) actually deliver value.
- Resolution: Acknowledge that multi-agent value is not yet proven at the capability layer. This further strengthens the trust argument: if the architectures are fragile, governance is MORE not less important.

---

## GAP MAP (v2.3)

### 1. UNANSWERED QUESTIONS — What does NO source answer?

1. **What is the actual production failure rate of enterprise AI agents?** — Academic sources measure benchmark failures; industry sources measure adoption. Nobody has published production failure rate data from real enterprise deployments.
2. **What does trust infrastructure actually cost to implement?** — C18 estimates $200K-$2M but no source provides validated TCO data for trust-specific infrastructure.
3. **Do enterprises that invest in trust infrastructure actually see better agent outcomes?** — The entire report thesis (invest in trust NOW) lacks direct causal evidence. No A/B study exists.
4. **How do non-Western enterprises approach agent trust?** — All sources are US/EU-centric. China, India, Southeast Asia, Middle East perspectives completely absent.
5. **What happens to enterprises that DON'T invest in trust infrastructure?** — No documented case of an enterprise suffering regulatory penalties specifically for AI agent governance failure (EU AI Act not yet enforced).

### 2. SILENT ASSUMPTIONS — What do ALL sources assume but never prove?

1. **"More agents = more risk"** — All sources assume scaling agents increases risk linearly or worse. But perhaps well-designed multi-agent systems with proper isolation could be SAFER than monolithic agents.
2. **"Trust frameworks work"** — ISO 42001 and NIST AI RMF are cited universally as solutions, but no source tests whether implementing them actually reduces failures.
3. **"Enterprise adoption will continue accelerating"** — Every source assumes the growth trajectory continues. None models a scenario where enterprises pull back (despite Gartner's 40% cancellation prediction suggesting this IS happening).
4. **"The trust gap is the primary barrier"** — Could be that cost, talent, or basic capability gaps matter more than trust/governance for most enterprises.
5. **"Human oversight is the correct default"** — Even sources critical of HITL still assume human oversight should be the goal. Perhaps fully autonomous agents with strong monitoring are better than human-in-the-loop for certain domains.

### 3. SURPRISING FINDINGS — What contradicts conventional wisdom?

1. **Multi-agent systems DON'T reliably outperform single agents** (S18) — contradicts the entire multi-agent orchestration narrative (S17, S1, S7)
2. **Only 6% of companies fully trust agents for core processes** (S20) — much lower than adoption rates suggest. Companies are deploying agents they don't trust.
3. **AI capability is doubling every 7 months BUT absolute performance is still poor** (S24 + S22) — exponential growth from a low base ≠ production readiness
4. **"Agent-washing" is a real phenomenon** (S23) — much of what's called "agentic AI" is relabeled automation, inflating adoption statistics
5. **The biggest AI companies couldn't keep their own agent promises** (S21, S22) — GPT-5 as "more of the same," agents launched with heavy caveats

### 4. IGNORED ANGLES — What perspective is absent?

1. **Non-Western/Global South perspectives** — All sources are US/EU. China's AI agent ecosystem, India's AI adoption patterns, regulatory approaches in Asia/Middle East completely absent.
2. **Worker/labor perspective** — How do employees experience AI agent deployment? Union responses? Job displacement data?
3. **Small/medium business perspective** — All data is enterprise-focused. SMB adoption, trust needs, and constraints are invisible.
4. **Insurance/liability perspective** — Who bears the cost when agents fail? How are insurers pricing AI agent risk?
5. **Open-source vs proprietary trust infrastructure** — No source compares whether open-source governance tools (e.g., MLflow, Evidently) vs commercial platforms differ in effectiveness.
6. **Long-term systemic risk** — What happens when thousands of enterprises deploy agents simultaneously? Correlated failures? Systemic risk like 2008 financial crisis?

### 5. SYNTHESIS OPPORTUNITIES — Which 3+ findings COMBINE into something nobody has said?

1. **"The Deployment-Trust Inversion"**: Enterprises are deploying agents (9-57% in production) that they don't trust (only 6% full trust) with governance they haven't built (only 12% have controls in place). This is a ticking time bomb — NOT because agents are dangerous per se, but because deployment is outrunning every guardrail simultaneously. (S1 + S2 + S20 + S18)

2. **"The Hype-Fragility Paradox"**: Agent-washing inflates adoption numbers (S23), making the market appear more mature than it is. Meanwhile, academic evidence shows multi-agent systems are fragile (S18, correctness as low as 25%). The trust infrastructure being built is designed for a market that doesn't exist yet — which could mean either "invest early" or "you're building for a mirage." (S23 + S18 + S22 + S17)

3. **"The Exponential Capability vs. Linear Governance Gap"**: AI agent capability doubles every 7 months (S24) while governance frameworks update annually at best (S13, S9). The gap between what agents CAN do and what governance CAN control is widening, not narrowing. This is the real urgency — not today's failures, but tomorrow's ungovernable capabilities. (S24 + S13 + S9 + S19)
