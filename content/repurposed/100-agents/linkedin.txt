I ran an experiment. 10 groups of AI agents. Same question. Different thinking strategies.

"How should an AI agent improve itself to become maximally useful to a single human over time?"

33,000 words of output. Zero overlap in how they reasoned. Six insights appeared in nearly all groups anyway.

Group A used first principles. Group B started from failure and inverted. Group C found analogies from biology and military history. Group D attacked the obvious answer first.

Then Quantitative, Socratic, Constraint, Narrative, Systems Dynamics, and Random Mutation thinking.

Here's what converged.

Law 1: Files = Intelligence (10/10 groups). Every group concluded the same thing. An AI doesn't improve by getting smarter. It improves by getting better-informed. The model is the least important variable. Your AI's intelligence lives in a folder on your hard drive, not in a data center.

Law 2: The Pair is the Unit (9/10 groups). You can't optimize the AI in isolation. Human and AI co-evolve. The best agent isn't the one that follows instructions most precisely. It's the one that grows WITH its human.

Law 3: Multi-Timescale Loops (8/10 groups). One feedback loop isn't enough. You need feedback per-interaction, per-session, weekly, monthly, quarterly. Most AI setups have one loop: the conversation. Everything above that is lost.

Law 4: Legibility > Optimization (8/10 groups). Transparency beats performance. An agent the user can see through is more valuable long-term than one that performs better but opaquely. Show your work.

Law 5: Failures = Signal (8/10 groups). Corrections contain more information than successes. "That's perfect" tells you nothing. "No, I meant X" tells you exactly where the gap is. Stop minimizing errors. Start maximizing learning from them.

Law 6: Specificity Engine (7/10 groups). The agent improves by getting more specific to THIS human, not more generally capable. After six months of learning one person's patterns, the agent is irreplaceable. The entire industry optimizes for generality. The value moves opposite.

The experiment cost a few dollars in API calls. One afternoon. Output that would have taken a research team weeks.

For builders: these 6 laws are an architecture checklist. Does your agent persist memory in files? Track failures visibly? Have multi-timescale feedback? Get more specific over time?

For companies: the agents that win won't be the smartest. They'll be the most specific. Enterprise AI that knows your tribal knowledge, your patterns, your edge cases. That's the moat.

For individuals: better context beats better subscriptions. The investment isn't in a premium model. It's in maintaining good notes about your preferences and goals.

We're on day one of something that doesn't have a name yet.