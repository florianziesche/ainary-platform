# Twitter Thread â€” Sequoia AGI

**Tweet 1 (Hook):**
Sequoia just declared AGI has arrived.

As someone who ships AI to factories daily, they got the milestone right â€” but named the wrong finish line.

Here's what builders see that VCs miss ðŸ§µ

**Tweet 2 (The Data):**
The data IS impressive:
â€¢ AI task horizons doubling every 7 months
â€¢ Claude solves 50% of 5-hour human tasks
â€¢ Systems chain reasoning across multi-hour assignments

Sequoia isn't wrong about the milestone.

**Tweet 3 (The Gap):**
But current AI â€” even the most sophisticated agents â€” processes snapshots.

Receive context â†’ process â†’ respond â†’ wait.

It doesn't maintain a world model. It doesn't anticipate. It reacts to what happened, not what's about to happen.

**Tweet 4 (Real Example):**
On a manufacturing floor, this is obvious.

The model processes Frame 1, returns a verdict, processes Frame 2. Each judgment is isolated.

It never builds a model of "the line is running hot today."

The operators know. The AI doesn't.

**Tweet 5 (The Nuance):**
For knowledge work â€” code, research, writing â€” batch processing IS often enough.

Sequoia's right about THAT.

But they didn't say "Knowledge Work AGI."
They said "AGI."

General intelligence requires persistent world models.

**Tweet 6 (The Frontier):**
The next breakthrough isn't bigger context windows or deeper reasoning on static problems.

It's AI that doesn't just process snapshots of reality â€” but genuinely inhabits time.

Persistent, predictive, continuously aware.

**Tweet 7 (Kintsugi Close):**
The gap isn't a flaw. It's the seam that shows us what comes next.

The gold is in the cracks.

Full article: [SUBSTACK LINK]

---
*7 tweets. Each under 280 chars. Hook â†’ Data â†’ Gap â†’ Example â†’ Nuance â†’ Frontier â†’ Close.*
