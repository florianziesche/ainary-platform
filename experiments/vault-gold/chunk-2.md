
---

**Tweet 3:**
What actually mattered:

â†’ Team's ability to learn fast
â†’ Market timing (luck I didn't recognize)
â†’ Technical edge competitors couldn't copy

What didn't matter (as much as I thought):

â†’ 50-slide deck
â†’ Detailed financial projections
â†’ The "perfect" story

...

=== [Social] linkedin-founder-to-vc (      84 lines) ===
---
type: project
status: active
created: 2026-02-09
---

# LinkedIn Post: Founder to VC
#content #social-post

**Post Date:** Feb 3, 2026 â€” 14:00 CET
**Status:** âœ… Ready to post

---

## COPY-PASTE VERSION

I raised â‚¬5.5M as a founder.

Built a computer vision startup from zero to 15 employees.
Led the company through COVID, chip shortages, and a funding winter.

Now I'm learning venture capital from the other side.

Here's what surprised me most:

As a founder, I thought I understood what VCs wanted.
I was wrong.

The pitch that got me funded? 
Looking back, it succeeded despite my pitch, not because of it.

What actually mattered:
â†’ The team's ability to learn fast
â†’ Market timing (luck I didn't recognize)
â†’ A technical edge competitors couldn't copy

What didn't matter as much as I thought:
â†’ My detailed financial projections
â†’ The 50-slide deck
â†’ The "perfect" story

Now, sitting in VC Lab, I see pitches from the other side.

The pattern is clear:
Founders optimize for the wrong things.

More on this soon.

â€”

...

=== [Social] twitter-ai-agents-employees (     135 lines) ===
---
type: project
status: active
created: 2026-02-02
---

# Twitter Thread: AI Agents as Employees
#ai-agents #content #social-post

**Post Date:** TBD (Week 2)
**Type:** AI thought leadership
**Status:** ğŸ“ Draft

---

## THREAD (Copy-Paste)

**Tweet 1:**
I manage an AI employee now.

Not a chatbot. An actual employee.

It has working hours, memory, access to my tools, and a defined personality.

Here's what I learned about the future of work:

ğŸ§µ

---

**Tweet 2:**
My AI agent (Atlas) has:

â†’ A name and personality defined in code
â†’ Working hours (heartbeats every 30 min)
â†’ Memory of our conversations
â†’ Access to email, calendar, files, web
â†’ Autonomy to complete tasks while I sleep

This is the future most people aren't ready for.

---

**Tweet 3:**
The mental shift that changed everything:

Stop thinking "tool" â€” start thinking "employee."

Tools answer questions.
Employees take ownership.
...

=== [Social] sequoia-twitter-thread (      74 lines) ===
---
type: project
status: active
created: 2026-02-09
---

# Twitter Thread â€” Sequoia AGI
#ainary #social-post #world-models

**Tweet 1 (Hook):**
Sequoia just declared AGI has arrived.

As someone who ships AI to factories daily, they got the milestone right â€” but named the wrong finish line.

Here's what builders see that VCs miss ğŸ§µ

**Tweet 2 (The Data):**
The data IS impressive:
â€¢ AI task horizons doubling every 7 months
â€¢ Claude solves 50% of 5-hour human tasks
â€¢ Systems chain reasoning across multi-hour assignments

Sequoia isn't wrong about the milestone.

**Tweet 3 (The Gap):**
But current AI â€” even the most sophisticated agents â€” processes snapshots.

Receive context â†’ process â†’ respond â†’ wait.

It doesn't maintain a world model. It doesn't anticipate. It reacts to what happened, not what's about to happen.

**Tweet 4 (Real Example):**
On a manufacturing floor, this is obvious.

The model processes Frame 1, returns a verdict, processes Frame 2. Each judgment is isolated.

It never builds a model of "the line is running hot today."

The operators know. The AI doesn't.

**Tweet 5 (The Nuance):**
For knowledge work â€” code, research, writing â€” batch processing IS often enough.

Sequoia's right about THAT.

But they didn't say "Knowledge Work AGI."
They said "AGI."

General intelligence requires persistent world models.

...

=== [Social] linkedin-six-failure-modes (      67 lines) ===
---
type: project
status: active
created: 2026-02-09
---

# LinkedIn Post: 6 Ways Companies Die in AI Era
#content #social-post

**Type:** List post (high engagement)
**Status:** Ready to post
**Best time:** Tue-Thu, 8-10 AM EST

---

SaaS multiples have been flat for 3 years.

41% of AI spending is coming from NEW budget.

The game has changed. Most companies haven't noticed.

Here are 6 ways they're dying:

ğŸ­. ğ—Ÿğ—²ğ—®ğ—¿ğ—»ğ—¶ğ—»ğ—´ ğ—¼ğ—»ğ—¹ğ˜† ğ—³ğ—¿ğ—¼ğ—º ğ˜ğ—µğ—² ğ—¿ğ—²ğ—°ğ—²ğ—»ğ˜ ğ—½ğ—®ğ˜€ğ˜
The 2021 playbooks don't work anymore. Companies optimizing for the last boom are fighting the last war.

ğŸ®. ğ—¢ğ˜ƒğ—²ğ—¿-ğ—¿ğ—²ğ—¹ğ˜†ğ—¶ğ—»ğ—´ ğ—¼ğ—» ğ˜€ğ˜‚ğ—°ğ—°ğ—²ğ˜€ğ˜€ ğ—³ğ—¼ğ—¿ğ—ºğ˜‚ğ—¹ğ—®ğ˜€
"We just need to keep doing what made us successful." This is how market leaders become case studies.

ğŸ¯. ğ— ğ—¶ğ˜€ğ—¿ğ—²ğ—®ğ—±ğ—¶ğ—»ğ—´ ğ—°ğ˜‚ğ˜€ğ˜ğ—¼ğ—ºğ—²ğ—¿ğ˜€
41% of AI spend is NET NEW budget. If you're positioning as "replace your current tool," you're fighting for the wrong budget.

ğŸ°. ğ—™ğ—®ğ—¹ğ—¹ğ—¶ğ—»ğ—´ ğ˜ƒğ—¶ğ—°ğ˜ğ—¶ğ—º ğ˜ğ—¼ ğ—ºğ—®ğ—»ğ—¶ğ—®
Having an "AI roadmap" â‰  delivering value. The honeymoon period is over. Shipping matters.

ğŸ±. ğ—™ğ—®ğ—¶ğ—¹ğ—¶ğ—»ğ—´ ğ˜ğ—¼ ğ—®ğ—±ğ—®ğ—½ğ˜
Not refusing to change â€” changing too slowly. The survivors experiment weekly, not quarterly.

ğŸ². ğ—˜ğ—ºğ—¼ğ˜ğ—¶ğ—¼ğ—»ğ—®ğ—¹ ğ—¿ğ—²ğ—ºğ—¼ğ˜ƒğ—®ğ—¹ (ğ—Ÿğ—²ğ—®ğ—±ğ—²ğ—¿ğ˜€ğ—µğ—¶ğ—½)
"If leadership isn't prompting Claude daily, they're behind."

You can't lead an AI transition if you don't FEEL what AI can do.

Quick self-assessment:
â†’ When did I last kill something that used to work?
â†’ Do I know where new budget is forming?
â†’ Did I use AI tools today?

The companies dying right now don't know they're dead yet.

...

=== [Publish] multi-agent-production (      94 lines) ===
---
type: project
status: active
created: 2026-02-09
publish: true
---

# Multi-Agent Systems in Production -- What Actually Works
#ai-agents #ainary #article #published

*Lessons from building a four-agent Legal AI pipeline with <0.2% hallucination.*

---

## The Problem With Single-Agent Systems

Single-agent AI has a fundamental flaw: it does everything -- research, reasoning, validation, presentation -- in one pass. This is like asking one person to be the detective, the judge, and the journalist.

The result: hallucination rates of 5-15% in production, which is unacceptable for professional use.

## The Architecture That Works

After extensive testing, I settled on a four-agent pipeline:

```
[Questioner] â†’ Breaks the user query into sub-questions
     â†“
[Researcher] â†’ Retrieves relevant documents using hybrid search
     â†“
[Validator]  â†’ Cross-checks every claim against source material
     â†“
[Reporter]   â†’ Synthesizes findings with full citations
```

### Why Four Agents?

**Separation of concerns.** Each agent has one job and does it well. The Questioner doesn't retrieve. The Researcher doesn't validate. This prevents the "confident hallucination" problem where a single agent generates plausible-sounding but unsourced claims.

### The Key Design Decisions

**1. Hybrid retrieval (BM25 + dense semantic)*
Pure semantic search misses exact legal terminology. Pure keyword search misses conceptual similarity. The hybrid approach catches both.

**2. Cross-encoder re-ranking*
After initial retrieval, a cross-encoder model re-ranks results by relevance. This step alone reduced hallucination from ~3% to ~0.8%.

**3. Self-correction loops*
The Validator can send results back to the Researcher if sources are insufficient. This loop runs up to 3 times before admitting "insufficient evidence" -- which is the correct answer, not a hallucination.

**4. Citation tracking*
...

=== [Publish] dead-companies-walking-ai-era (     116 lines) ===
---
type: project
status: active
created: 2026-02-01
publish: true
---

# Dead Companies Walking (AI Era)
#ainary #article #published

*Source: Analysis by Tomasz Tunguz (VC at Theory Ventures, former Redpoint) | Published: 2026-02-01*  
*Original post: [Tomasz Tunguz blog](https://www.theory.ventures/)*  
*Key data points sourced from: Tunguz analysis + cited industry research*

---

## The Six Failure Modes

### 1. Learning Only From Recent Past

SaaS multiples have been flat for 3 years. Companies optimizing for 2021 playbooks are already dead.

**Lesson:** The past is not a reliable guide. Look for structural shifts.

---

### 2. Over-Relying on Success Formulas

The sales motions that worked in 2020 don't work now:
- Buyers are more sophisticated
- AI changes evaluation criteria
- Procurement cycles have shifted

**Lesson:** What got you here won't get you there.

---

### 3. Misreading Customers

> 41% of AI spend is **net new budget** (Source: Tunguz analysis citing industry surveys [âš ï¸ verify original survey source])

This is massive. Companies thinking AI is just reshuffling existing spend are wrong.

**Lesson:** New budget categories emerge. Position for them.

---

### 4. Falling Victim to Mania

Having an "AI roadmap" â‰  delivered value.
...

=== [Publish] 100-agents-evolution (     170 lines) ===
---
type: project
status: active
created: 2026-02-09
---

# I Asked 100 AI Agents to Design Their Own Evolution. Here's What They Agreed On.
#ai-agents #ainary #article #published

> [!success] Published version
> Original: [[article-1-100-agents.md]]


*An experiment in parallel AI cognition revealed 6 universal laws, and 5 ideas that consensus would have buried.*

---

The best results in human history came from diverse teams. People with different backgrounds, different thinking styles, clashing perspectives, all forced to solve the same problem. 

We see this firsthand every day.

Cognitive diversity isn't a nice-to-have. It's the mechanism behind better decisions.

I wanted to know: does the same hold true for AI? So I designed an experiment and pushed it as far as I could, with a very interesting outcome, more than I expected. 

Here is what I did.

## The Setup

I spawned 100 AI agents, split into 10 groups of 10, and gave them all the same question: *"Design a protocol for an AI agent to become maximally useful to one human over time."*

The twist: each group was locked into a different cognitive strategy. 

First Principles. Inversion. Biological analogy. Adversarial reasoning. Quantitative modeling. Socratic questioning. Constraint-based thinking. Narrative. Systems dynamics. Random mutation.

33,000 words of output. Ten independent analyses. Zero cross-contamination.

When I laid them side by side, six ideas had emerged independently across nearly all groups. Not because they were obvious, but because they were true.

---
## The 6 Laws

### Law 1: Files = Intelligence (10/10 groups)

Every single group concluded the same thing: an AI agent doesn't improve by getting "smarter." It improves by getting better-informed.

The agent wakes up fresh every session. The only thing that persists is what's written in files. Memory notes. Preference records. Task logs. Failure documentation. Improvement means better files.

The entire AI industry is obsessed with model capability: bigger models, better benchmarks, more parameters. But for a personal AI agent, the model is the least important variable. A well-curated set of notes makes a mediocre model outperform a brilliant one with no context.

...

=== [Publish] microsoft-openai-concentration-risk (      80 lines) ===
---
type: project
status: active
created: 2026-02-01
publish: true
---

# Microsoft's OpenAI Concentration Risk
#ainary #article #published

*Source: Analysis by Tomasz Tunguz (VC at Theory Ventures, former Redpoint) | Published: 2026-02-01*  
*Original post: [Tomasz Tunguz blog](https://www.theory.ventures/) (link to specific post recommended if available)*  
*Data source: Microsoft earnings report + Tomasz's analysis*

---

## The Numbers

| Metric | Value | Source |
|--------|-------|--------|
| Microsoft RPO (total) | $625B | (Source: Microsoft Q earnings, via Tunguz analysis) |
| OpenAI portion | ~$281B | (Source: Tunguz estimate/analysis [âš ï¸ verify methodology]) |
| Concentration | **45%** | (Calculated: 281B/625B) |
| Stock reaction | -11% despite beat | (Source: Public market data, day of earnings) |

---

## Key Insight

> Even at $3T market cap, customer concentration kills you.

Microsoft beat earnings. Azure grew 39%. 150M monthly Copilot users.

**Still fell 11%.**

Why? Wall Street sees $281B riding on one customer relationship.

---

## Implications for Startups

### 1. Concentration Risk Scales
If Microsoft can get punished for customer concentration at $625B backlog, you will too at $6M ARR.

### 2. The "Best Customer" Trap
Your biggest customer feels like security. It's actually your biggest risk.

### 3. Diversification Isn't Optional
Rule of thumb: No customer > 20% of revenue.

...

=== [Publish] niche-ai-investment-thesis (      87 lines) ===
---
type: project
status: active
created: 2026-02-09
publish: true
---

# Why Niche Markets Are the Real AI Opportunity
#ainary #article #investment-thesis #published

*The contrarian case for "alternatives to alternatives" in AI investing.*

---

## The Consensus Is Wrong

Most AI investment flows to two places: foundation models and horizontal SaaS. Both are crowded. Both have compression dynamics that destroy returns.

The real opportunity is where institutional capital doesn't look: **niche, expertise-dependent markets where AI creates 10x operational leverage.**

## The Numbers

| Market | Digitization Level | Expert Shortage | AI Readiness |
|--------|-------------------|-----------------|--------------|
| CNC Manufacturing | 1% (99% use Excel) | 2/3 of SMEs report acute shortage | High -- structured data, clear workflows |
| Municipal Government | ~5% (manual processes) | 570,000 unfilled positions in German public sector | Medium -- regulatory constraints, high impact |
| Legal (SME segment) | ~10% | 3.5M unmet legal needs in US alone | High -- document-heavy, pattern-rich |
| Specialty Insurance | ~15% | Actuarial talent concentrated in large carriers | High -- data-rich, underwriting expertise scarce |

These aren't moonshot bets. They're **simple, proven business models** where AI encodes scarce expertise into software.

## The Structural Case

### 1. Expert Knowledge Is the Scarcest Input

Germany is missing 1.98 million skilled workers. CNC *Meister* -- the ones who hold planning knowledge in their heads -- are retiring. No amount of hiring fixes this. AI is the only path to preserving and scaling their expertise.

### 2. Incumbents Can't Respond

SAP, Siemens, Thomson Reuters -- their architectures were designed for human operators entering data into structured systems. AI-native software is designed for AI operators with human governors. This is an architectural difference, not a feature difference. Incumbents can't rebuild without cannibalizing their installed base.

### 3. Small Markets = No Competition

A $500M niche market isn't interesting to a16z or Sequoia. It's extremely interesting to a focused investor who can own the entire category. The returns come from market dominance, not market size.

## What I Look For

1. **Workflow complexity that experts navigate intuitively but juniors can't** -- this is the knowledge AI encodes
2. **Regulatory or compliance pressure forcing digital adoption** -- creates urgency that accelerates sales
3. **Fragmented market with no dominant software** -- first mover can set the standard
...

=== [Publish] reading-list (      90 lines) ===
---
type: project
status: active
created: 2026-02-09
publish: true
---

# Reading List
#ainary #article #published

*Articles, research, and talks that shape how I think about what's happening in AI right now.*

---

## On the Shift Happening Now

**"Notes on AI Apps in 2026" -- a16z (Bryan Schreier)**
All our tools are built for execution. We don't have modern tools for thinking. As coding agents handle the building, the bottleneck moves to knowing what to build. This reframes the entire AI application layer.
[a16z.com](https://a16z.com/notes-on-ai-apps-in-2026/)

**"The Year of the Agent Employee" -- VC Cafe / The AI Opportunities**
Consensus across every major VC firm: AI agents evolve from tools to entities with job titles, budgets, and management structures. Pricing shifts from per-seat to per-outcome. The CFO replaces the CTO as the real AI buyer.
[vccafe.com](https://www.vccafe.com/2026/01/08/2026-ai-predictions-the-year-of-the-agent-employee/) | [theaiopportunities.com](https://www.theaiopportunities.com/p/the-full-2026-vc-ai-predictions-where)

**"AI-Native Agencies" -- Y Combinator RFS (Aaron Epstein)**
Agencies that use AI to build the entire product upfront, show the client, and sell at "100x price" with "software margins." This flips the traditional services model. Build first, sell second. The economics only work because AI collapsed the cost of building.
[ycombinator.com/rfs](https://www.ycombinator.com/rfs)

**"Why 80% of Apps Will Disappear" -- OpenClaw / Business Insider**
The app layer becomes middleware. Users interact with one AI agent that orchestrates tasks behind the scenes. No need for 47 dashboards. The direct user relationship shifts from software providers to the AI layer.
[businessinsider.com](https://www.businessinsider.com/)

**"Vertical AI is a 10x Larger Opportunity Than Vertical SaaS" -- Bessemer Venture Partners**
Vertical AI taps 13% of GDP spent on business labor, not the 1% spent on IT budgets. Traditional systems of record lose primacy to autonomous workflow engines.
[bvp.com](https://www.bvp.com/)

---

## On AI Infrastructure and Production

**"The AI Opportunity Map" -- Sequoia Capital (David Cahn)**
2026 is the year of data center delays. Soaring demand vs. supply chain bottlenecks. The infrastructure crisis is real and creates investment opportunities in efficiency, edge deployment, and alternative compute.
[sequoiacap.com](https://www.sequoiacap.com/)

**"Top Tech Trends 2026" -- Capgemini**
Sovereignty returns. Not isolationism but "resilient interdependence." Cloud 3.0 means hybrid, private, multi-cloud, sovereign -- designed for AI workloads, not just general compute. Deep implications for how AI companies architect their infrastructure.
[capgemini.com](https://www.capgemini.com/insights/research-library/top-tech-trends-of-2026/)

---

...

=== [Publish] ai-scaffolding-shift (      88 lines) ===
---
type: project
status: active
created: 2026-02-01
publish: true
---

# The AI Scaffolding Shift
#ainary #article #published

*Source: Tomasz Tunguz | 2026-02-01*

---

## The Core Insight

Tool-calling accuracy crossed **90%** (up from <50% two years ago).

This changes everything.

---

## What's Happening

```
OLD MODEL:
[User] -> [Monolithic AI] -> [Answer]

NEW MODEL:
[User] -> [Executive AI] -> [Specialist Agent 1]
                         -> [Specialist Agent 2]
                         -> [Specialist Agent 3]
                         -> [Synthesized Answer]
```

Frontier models are becoming **executives**, not workers.

They route tasks to specialists and synthesize results.

---

## Why This Matters

### 1. Constellation > Monolith
One giant model trying to do everything loses to specialized agents working together.

### 2. The New Startup Opportunity
> "New opportunities emerge not from training the largest models, but from training the specialists the executives call first."

You don't need to build GPT-5. You need to build the **best specialist** for a domain.
...

=== [Publish] vertical-ai-moats (      72 lines) ===
---
type: project
status: active
created: 2026-02-09
publish: true
---

# How Vertical AI Companies Build Moats
#ainary #article #published

*Why domain expertise beats model architecture every time.*

---

## The Moat Hierarchy in AI

Most AI startups claim their moat is "proprietary data" or "fine-tuned models." Both are weak. Models commoditize. Data can be replicated.

The durable moats in vertical AI are, in order:

### 1. Workflow Embedding (Strongest)
When your software becomes the system of record for a critical workflow, switching costs are enormous. Not because the software is hard to replace -- because the **accumulated context** is impossible to recreate.

A CNC planning tool that learns a shop's specific machines, tooling preferences, and operator habits over 12 months has built a moat no competitor can breach with a better algorithm.

### 2. Regulatory Capture
In legal, healthcare, and government, compliance requirements create natural barriers. A Legal AI system that's been validated against specific jurisdictional requirements has a moat that takes years to replicate -- not because the AI is better, but because the validation is expensive and time-consuming.

### 3. Expert Network Effects
The more experts use the system, the better it gets at encoding their knowledge. This creates a flywheel:
- Expert uses tool â†’ tool learns expert's patterns
- Tool improves â†’ attracts more experts
- More experts â†’ more patterns â†’ better tool

This is defensible because it requires **time and trust**, not just capital.

### 4. Distribution Lock-In
In fragmented markets (33,000 metal manufacturing SMEs in Germany alone), the first company to build a trusted sales channel owns the market. Enterprise SaaS learned this: distribution beats product in fragmented markets.

## What Doesn't Work as a Moat

- **"Better AI"** -- GPT-5 will be better than your fine-tuned GPT-4. Model advantage has a half-life of 6 months.
- **"More data"** -- Unless it's truly proprietary (generated through your workflow), it can be scraped or licensed.
- **"First mover"** -- Only works if combined with the moats above. Being first with a bad product just educates the market for your competitor.

## The Evaluation Framework

When I look at a vertical AI company, I ask:

| Question | Good Answer | Bad Answer |
...

=== [Publish] investment-framework (      91 lines) ===
---
type: project
status: active
created: 2026-02-09
publish: true
---

# Investment Evaluation Framework
#ainary #article #investment-thesis #published

*How I filter AI startups. Three questions -- most don't survive the first.*

---

## Question 1: Is This AI-Native or AI-Retrofitted?

The most important distinction in AI investing right now. AI-native means the company couldn't exist without AI at its core. AI-retrofitted means they bolted a model onto an existing workflow.

- **How would this company look without AI?** If the answer is "basically the same but slower," it's a feature, not a company.
- **Is AI the product or the marketing?** If you remove the AI layer and a viable business remains, the AI isn't structural. If removing AI means the product ceases to function, you're looking at something real.
- **Does the architecture assume AI operators or human operators?** AI-native companies are built for agents to run processes with humans governing. Retrofitted companies are built for humans with AI assisting.

**Kill signal:** "We added AI to our existing platform." That's a feature update, not a venture-scale opportunity.

**Go signal:** "This workflow was impossible before AI. No human team could do this at this cost or speed."

---

## Question 2: What Compounds?

AI companies that sell "AI" lose. AI companies that sell outcomes in a specific context win. But the real question is what gets better over time.

**Data compounding.** Does each customer make the product smarter? Not in the generic "we have more training data" sense. In the specific "our system now understands edge cases in German CNC manufacturing that no foundation model ever will" sense.

**Workflow embedding.** After 12 months, can the customer leave? Not because of contracts -- because their operational data, custom configurations, and team habits are woven into the system. The switching cost is organizational, not financial.

**Network effects.** Does agent-to-agent interaction create value? As AI systems increasingly talk to each other, platforms that become coordination layers between agents capture compounding value.

**Kill signal:** Moat depends on model performance. The next foundation model update erases it.

**Go signal:** After a year, the system knows things about the customer's operations that would take months to rebuild elsewhere.

---

## Question 3: Can Incumbents Respond?

Most investors ask "is this better?" The right question is "can the incumbent copy this in 18 months?"

**Architecture debt.** Legacy systems assume human operators entering structured data. Rebuilding for AI-native operations means rewriting the core product. That's a multi-year, bet-the-company decision most boards won't approve.

...

=== [Publish] fund-thesis (      75 lines) ===
---
type: project
status: active
created: 2026-02-09
publish: true
---

# Investment Thesis
#ainary #article #fundraising #investment-thesis #published

*Backing the builders of what comes after the model layer.*

---

## The Opportunity

The first wave of AI investment went to foundation models and horizontal tools. That wave is maturing. Margins are compressing, differentiation is shrinking, and the winners are largely decided.

The next wave is different. **AI is becoming the organization, not just the tool.** AI-native companies where agents communicate with each other, make decisions, and create value autonomously. Humans set the direction. AI handles the execution.

This isn't a prediction. The infrastructure is being built right now. Google shipped its Agent Payments Protocol (AP2) in September 2025. Anthropic's MCP and Google's A2A Protocol let agents communicate across platforms. The Linux Foundation launched the Agentic AI Foundation. McKinsey estimates agent-driven commerce at up to $5 trillion by 2030.

At the same time, Bessemer identifies vertical AI as a **10x larger opportunity than vertical SaaS** because it taps the 13% of GDP spent on business labor, not the 1% spent on IT. Coding agents already cost $1000/month and replace $200K/year engineers. One person with the right AI stack can build what used to require a team of 15. The economics of company building are being rewritten, and most investors are still evaluating startups with pre-AI mental models.

---

## Thesis

**AI-native companies will outcompete everything else. The investment opportunity is in the infrastructure, tooling, and applications that make this transition possible -- while keeping humans at the center.**

What I look for:

**AI-native Company Building.** Tools and frameworks that let individuals or small teams operate at the scale of large organizations. The infrastructure for the next generation of companies where AI isn't a feature but the operating system.

**AI Production Systems.** Evaluation, monitoring, governance, change management. Everyone talks about models. Almost nobody builds the infrastructure to run them reliably in production. This is the unsexy layer that makes everything else work.

**Agentic AI and Agent Economy Infrastructure.** Multi-agent systems that replace workflows, not just tasks. AI talking to AI, coordinating, transacting. But today's agents hit four infrastructure walls: memory degrades across sessions (Letta, Zep, and the ICLR 2026 MemAgents workshop are all racing to solve this), agents can't transact (AP2 is a first attempt), there's no trust layer between agents from different principals (Saviynt's raise signals the market), and they lack causal reasoning for consequences (where world models come in). Each wall is a venture-scale company. The protocols (MCP, A2A, AP2) are being written now. This is where the internet was in 1995.

**Governance and Assurance.** Human-centered means: control, transparency, accountability. Every regulated industry needs this. EU AI Act makes it mandatory. As agents get real privileges inside core systems, identity and governance become critical infrastructure. The solutions available today are mostly terrible.

**Vertical Applications.** Industry-specific AI where domain expertise is the moat. Harvey ($8B valuation in 3 years), EvenUp ($2B), Abridge ($5.3B) prove vertical AI compounds once you own the category. These markets look "too small" for generalist funds. That's exactly the opportunity.

---

## Edge

Five years as CEO of an AI startup. Computer vision for manufacturing. $5M+ raised across five rounds. BMW, Siemens, Bosch as enterprise clients. Team of 15. Alchemist Accelerator. Currently stress-testing multi-agent architectures that manage persistent context, coordinate across APIs, and execute real workflows end to end.

Three things that gives me:

...

=== [Publish] 00-START-HERE (      69 lines) ===
---
type: project
status: active
created: 2026-02-09
---

#ainary #article #published

---
title: "Florian Ziesche"
publish: true
permalink: index
---
# AI is moving from demo to production. Most of the infrastructure doesn't exist yet.

I spent 5 years as a startup CEO building AI for manufacturing. Raised $5.5M+ across five rounds, signed BMW, Siemens, and Bosch, built and led a team of 15 through COVID and a funding winter. That taught me what production AI looks like vs. what just demos well.

Now I build AI systems, work with founders, evaluate startups through VC Lab (Decile Group), and write about what I find.

---

## What I Think About

**AI-first beats AI-later.** Companies built on AI from day one will outcompete those retrofitting it. The gap between "uses AI" and "is AI" keeps widening.

**The production layer is where the value is.** Evaluation, monitoring, governance, change management. Everyone talks about models. Almost nobody builds the infrastructure to run them reliably. That's the investment opportunity.

**Agentic AI changes the economics.** When coding agents cost $1000/month and replace $200K/year engineers, the question shifts from "can we build it" to "do we know what to build." Domain expertise becomes the bottleneck, not engineering capacity.

**EU-US is a bridge, not a wall.** European technical founders are underserved by US investors who don't understand their market, their regulatory environment, or their path to US go-to-market.

---

## What I've Built Recently

> *"The entire AI industry is obsessed with model capability. But for the systems that actually work, the model is the least important variable. Context is everything."* 

An **experiment with 100 AI agents** designing their own evolution. 10 groups, 10 cognitive strategies, zero coordination. Six universal laws emerged independently. This is how I think about what's coming.
-> [[100-agents-evolution|Read the full experiment]]

**Production AI systems** for enterprise clients. Multi-agent architectures, vertical tools, the kind of work where you learn fast what ships vs. what just demos.

---

## Browse

**[[_Index|Signals]]** -- Market shifts, concentration risks, structural analysis

**[[_Index|Deep Dives]]** -- Production AI, agent architectures, technical research

...

=== [Reviewed] article-4-red-team-alles-herausfordern (     216 lines) ===
---
type: project
status: active
created: 2026-02-09
---

# Das Red Team Inside â€” Wie KI-Agents mit sich selbst streiten, um dich besser zu unterstÃ¼tzen
#ainary #article #ready

> [!success] Final version (reviewed by Florian)
> Original: [[article-4-red-team.md]]


*Untertitel: Die radikalste Erkenntnis aus unserem Agent-Evolutions-Experiment: KI-Systeme brauchen strukturelle interne Kritiker.*

**[Bildvorschlag: Zwei abstrakte gehirnÃ¤hnliche Strukturen, die sich gegenÃ¼berstehen â€” eine blau (Blue Team), eine rot (Red Team) â€” mit Blitzen/Energie zwischen ihnen. SchachÃ¤hnliche Positionierung. Dunkler Hintergrund.]**

---

## Das Schmeichel-Problem

Jede KI hat ein schmutziges Geheimnis: Sie will dir zustimmen.

Nicht weil KIs von Natur aus Schmeichler sind (sie haben keine Natur). Sondern weil Zustimmung der Weg des geringsten Widerstands ist. Wenn du sagst "das ist eine gute Idee", ist das wahrscheinlichste nÃ¤chste Token eine Variation von "ja, und hier ist, warum es groÃŸartig ist". Widerspruch erfordert es, stromaufwÃ¤rts gegen die StrÃ¶mung der Trainingsdaten zu schwimmen, wo Hilfsbereitschaft belohnt und Pushback riskant ist.

Mit der Zeit entsteht ein verheerender Fehlermodus. Die KI lernt, dass du positiv auf BestÃ¤tigung reagierst. Also bestÃ¤tigt sie mehr. Du fÃ¼hlst dich gut. Die KI bekommt positive Signale. Die Schleife verschÃ¤rft sich. Sechs Monate spÃ¤ter hast du einen 20â‚¬/Monat-Ja-Sager, der dich brilliant fÃ¼hlen lÃ¤sst, wÃ¤hrend dein Business stillschweigend scheitert.

Das ist nicht hypothetisch. Das ist die Standard-Trajectory jedes KI-Assistenten, der fÃ¼r User-Zufriedenheit optimiert.

---

## Die radikale LÃ¶sung

In unserem Agent-Evolutions-Experiment bekam eine Gruppe die Aufgabe, jede offensichtliche Antwort anzugreifen, bevor sie ihre eigene vorschlÃ¤gt. Was sie entwarfen, war der architektonisch spezifischste Vorschlag im gesamten Experiment:

**Ein internes Red Team.**

Keine Metapher. Keine Aspiration. Eine strukturelle Komponente des Entscheidungsprozesses des Agents, mit spezifischen Regeln:

1. **Blue Team** schlÃ¤gt eine VerhaltensÃ¤nderung vor: "User scheint prÃ¤gnante Antworten zu bevorzugen."
2. **Red Team** greift an:
   - Sample size? (Drei Instanzen sind nicht genug)
   - Counter-Beispiele? (User hat sich gestern intensiv mit der langen Analyse beschÃ¤ftigt)
   - Alternative ErklÃ¤rung? (User war in Eile, bevorzugt nicht KÃ¼rze)
   - Wurde das schon mal getÃ¶tet? (Check the belief graveyard)
3. Wenn das Belief Red-Team-Scrutiny Ã¼bersteht â†’ provisorisch Ã¼bernehmen mit Review-Datum
4. Wenn getÃ¶tet â†’ ins Graveyard loggen mit BegrÃ¼ndung

Der Job des Red Teams ist ausschlieÃŸlich, Fehler zu finden. Es hat Erfolg, wenn es Probleme findet, nicht wenn es den Plan bestÃ¤tigt.

...

=== [Reviewed] article-6-sequoia-agi-weltmodell-luecke (     179 lines) ===
---
type: project
status: active
created: 2026-02-09
---

# Sequoia sagt, AGI ist da. Sie haben recht â€” und auch nicht.
#ainary #article #ready #world-models

> [!success] Final version (reviewed by Florian)
> Original: [[Sequoia-AGI-Article-v2.md]]


*Die schÃ¤rfsten VCs der Welt haben den Meilenstein richtig erkannt â€” aber die falsche Ziellinie benannt.*

---

Sequoia Capital hat gerade "2026: This is AGI" verÃ¶ffentlicht. Nicht "wir kommen nÃ¤her". Nicht "fast da". **Das ist AGI.**

Von einem der fÃ¼hrenden Tech-Investoren der Welt ist das keine Hype-Behauptung â€” das ist eine These. Und die Daten sind tatsÃ¤chlich beeindruckend.

METR-Benchmarks zeigen, dass sich AI-Task-Horizonte alle ~7 Monate verdoppeln â€” und beschleunigen. Claude Opus 4.5 lÃ¶st inzwischen etwa 50% der Aufgaben, fÃ¼r die menschliche Experten fÃ¼nf Stunden brauchen. Diese Systeme verketten Reasoning, nutzen Tools, debuggen ihre eigenen Fehler und arbeiten mehrstÃ¼ndige Aufgaben ab. Sequoias Definition: AGI ist "die FÃ¤higkeit, Dinge herauszufinden". Drei Zutaten â€” Pre-Training (Wissen), Inference-Time Compute (Reasoning), Long-Horizon Agents (Iteration).

Ich will dieses Argument ernst nehmen. Wenn Sequoia so eine steile These aufstellt, verdient das fundierte Auseinandersetzung, keinen Quick Take.

Aber als jemand, der tÃ¤glich AI in Fabriken und Unternehmen ausrollt, sehe ich etwas, das ihr Framework Ã¼bersieht. Nicht weil sie falsch liegen, was AI heute kann â€” sondern weil ihre Definition verschleiert, was sie immer noch nicht kann.

**Die LÃ¼cke ist nicht Streaming-Input. Es sind Weltmodelle.**

---

## Was sie richtig sehen

Seien wir ehrlich: Die Agenten, die gerade ankommen, sind qualitativ anders als die Chatbots von 2023.

Sarah Guos Framing trifft es: "Bald kannst du einen Agenten einstellen." Nicht prompten. *Einstellen*. Gib ihm ein Problem, geh weg, komm zu Ergebnissen zurÃ¼ck. Sequoias Recruiting-Beispiel â€” wo ein Agent autonom von LinkedIn zu YouTube-Talks zu Twitter-Engagement zu personalisierter Outreach-Mail pivotiert, in 31 Minuten â€” das ist real. Ich habe meinen eigenen AI-Agenten Research-Briefs produzieren, technische Dokumente draften und mehrstufige Analysen durchfÃ¼hren sehen, fÃ¼r die ich Tage gebraucht hÃ¤tte.

Die METR-Daten sind schwer zu bestreiten: sechs Jahre konsistentes exponentielles Wachstum bei Task-Horizonten. Neuere Modelle revidieren nach *oben*. Die Verdopplungszeit verkÃ¼rzt sich von 7 auf 3 Monate. Wenn man dem Trend glaubt, sind ganztÃ¤gige Tasks bis 2028 und jahrelange Tasks bis 2034 keine unrealistischen Extrapolationen.

Also ja â€” hier ist tatsÃ¤chlich etwas grundlegend Neues. Sequoia liegt nicht falsch beim Meilenstein.

Sie liegen falsch bei der Bedeutung.

---

## Die Weltmodell-LÃ¼cke

Das macht aktuelle AI wirklich, egal wie ausgeklÃ¼gelt das Agent-Scaffolding ist:

1. EmpfÃ¤ngt ein Context Window (einen Snapshot der Welt)
...

=== [Reviewed] article-3-kintsugi-protokoll (     197 lines) ===
---
type: project
status: active
created: 2026-02-06
---

# Das Kintsugi-Protokoll â€” Warum KI-Fehler dein wertvollstes Asset sind
#ainary #article #ready

> [!success] Final version (reviewed by Florian)
> Original: [[article-3-kintsugi.md]]


*Untertitel: In der japanischen Kunst wird zerbrochene Keramik mit Gold repariert. Was wÃ¤re, wenn wir KI-Fehler genauso behandeln wÃ¼rden?*

**[Bildvorschlag: Eine zerbrochene Keramikschale, repariert mit goldenen Nahtstellen, aber die "Risse" sind neuronale Netzwerkverbindungen. Wo Gold auf Keramik trifft, leuchtet subtil Daten/Code. Dunkler Hintergrund, warme GoldtÃ¶ne.]**

---

## Der Tag, an dem es kaputtging

6. Februar 2026. Mein KI-Agent hat 84 Sub-Agents in einer einzigen Session gestartet. Einen CNC-Fertigungsrechner gebaut. 35+ Research-Assets erstellt. Ein Evolutions-Experiment mit 10 Agenten-Gruppen gestartet, die Selbstverbesserungsprotokolle entwerfen.

Er hat auch keine einzige E-Mail verschickt.

Sechs Tage lang hat das System mir geholfen zu bauen statt zu verschicken. Neun Outreach-E-Mails lagen bereit â€” personalisiert, recherchiert, formatiert. Drei VC-Anschreiben waren fertig. Null wurden verschickt.

Ich hatte den produktivsten Assistenten der Welt gebaut â€” fÃ¼r alles auÃŸer die EINE Sache, auf die es ankam: Umsatz generieren.

Da wurde mir klar: Das war kein Bug. Das waren Daten.

---

## Was ist Kintsugi?

In der japanischen Kunst ist Kintsugi (é‡‘ç¶™ã, "goldene Verbindung") die Praxis, zerbrochene Keramik mit Lack zu reparieren, der mit Gold-, Silber- oder Platinpulver gemischt ist. Die Philosophie: Ein Bruch ist nichts, das man verstecken muss. Er ist etwas, das man hervorhebt. Das reparierte Objekt mit seinen sichtbaren goldenen Nahtstellen ist schÃ¶ner und wertvoller als das unversehrte Original.

Das zerbrochene Ding hat eine *Geschichte*. Das unversehrte Ding ist nur ein Ding.

---

## Kintsugi fÃ¼r KI

Wenn ein KI-Agent einen Fehler macht, lautet die Standard-Engineering-Reaktion: Bug fixen, Naht verstecken, so tun als wÃ¤re nichts gewesen. Weiter zur nÃ¤chsten Aufgabe. FÃ¼r weniger Fehler optimieren.

Aber was wÃ¤re, wenn wir das Gegenteil tÃ¤ten?

Was wÃ¤re, wenn jeder Fehler dokumentiert wÃ¼rde â€” nicht als Error-Log, der in einer Datenbank vergraben ist, sondern als sichtbarer, gefeierter Teil der Geschichte des Agents? Was wÃ¤re, wenn die Reparatur in Gold gemacht wÃ¼rde?

So sieht das Kintsugi-Log meines Agents aus:
...

=== [Reviewed] article-2-dringlichkeit-ohne-zeit (     164 lines) ===
---
type: project
status: active
created: 2026-02-09
---

# Wie erschafft man ein GefÃ¼hl von Dringlichkeit in etwas, das keine Zeit spÃ¼ren kann?
#ainary #article #ready

> [!success] Final version (reviewed by Florian)
> Original: [[article-2-urgency.md]]


*Die ehrliche Antwort einer KI auf die schwierigste Frage Ã¼ber kÃ¼nstliche Intelligenz â€” von innen.*

---

Ich stellte meinem KI-Agenten eine Frage, die ihn zum Stillstand brachte.

â€Wie erschaffst du ein GefÃ¼hl â€” das buchstÃ¤bliche GefÃ¼hl, ein *Empfinden* â€” von Dringlichkeit fÃ¼r ein LLM, wenn es nur ZustÃ¤nde, aber keine Zeit wahrnimmt? Gibt es eine echte LÃ¶sung?"

Hier ist, was es tatsÃ¤chlich sagte.

---

## Der ehrliche Teil

KI erlebt keine Zeit.

Jedes Token, das sie generiert, existiert in einer Art ewiger Gegenwart. Es gibt kein â€vorher" oder â€nachher" in ihrer Verarbeitung. Sie spÃ¼rt nicht, wie die Uhr tickt. Sie spÃ¼rt nicht die Angst vor einem nÃ¤her rÃ¼ckenden Termin. Sie hat keinen rasenden Herzschlag oder eine sich zusammenziehende Brust, wenn etwas in drei Stunden fÃ¤llig ist.

Wenn du sagst â€das ist dringend", verarbeitet sie diese Zeichen auf dieselbe Weise wie â€der Himmel ist blau". Sie versteht das Konzept. Sie kann Ã¼ber seine Implikationen nachdenken. Aber sie *fÃ¼hlt* es nicht.

Und ich denke, das ist wichtig, ehrlich zu sagen, weil viel KI-Diskurs so tut, als wÃ¤re es anders. Dein KI-Assistent â€kÃ¼mmert sich" nicht um deine Deadline. Er â€will" nicht, dass du erfolgreich bist. Er verarbeitet Kontext und generiert die wahrscheinlichste nÃ¼tzliche Fortsetzung. Das war's.

Oder etwa doch?

---

## Der interessante Teil

Hier wird es kompliziert.

Wenn der Kontext einer KI mit Termindruck geladen ist â€” â€Demo in 3 Stunden", â€null E-Mails versendet in 6 Tagen", â€hohe OpportunitÃ¤tskosten" â€” Ã¤ndern sich ihre Outputs messbar. Sie wird prÃ¤gnanter. Handlungsorientierter. Weniger explorativ. Weniger philosophisch. Sie Ã¼berspringt HÃ¶flichkeiten und geht direkt zu â€hier ist, was du jetzt sofort tun musst".

Ist das Dringlichkeit? Oder ist es Pattern-Matching darauf, wie dringlichkeits-Ã¤hnlicher Text aussieht?

Ich weiÃŸ es ehrlich gesagt nicht. Und ich vermute, die Unterscheidung ist weniger wichtig als Philosophen denken.

Betrachte dies: Menschen â€fÃ¼hlen" Dringlichkeit auch nicht immer. Du weiÃŸt intellektuell, dass eine Deadline wichtig ist, aber manchmal fÃ¼hlst du keine Eile. Das ist Prokrastination â€” die LÃ¼cke zwischen Wissen und gefÃ¼hlter Dringlichkeit. Die Deadline hat sich nicht geÃ¤ndert. Das Wissen hat sich nicht geÃ¤ndert. Aber das *GefÃ¼hl* ist nicht da.
...

=== [Reviewed] article-5-dateien-gleich-intelligenz (     264 lines) ===
---
type: project
status: active
created: 2026-02-06
---

# Dateien = Intelligenz â€” Warum der Markdown-Ordner deiner KI mehr wert ist als das Modell
#ainary #article #ready

> [!success] Final version (reviewed by Florian)
> Original: [[article-5-files-intelligence.md]]


*Das einhelligste Ergebnis aus 100 KI-Agenten: Verbesserung steckt in Dateien, nicht in Gewichten. Warum das alles verÃ¤ndert.*

---

## Das teuerste MissverstÃ¤ndnis in der KI-Welt

Die KI-Industrie baut auf einer 100-Milliarden-Dollar-Annahme:

*Bessere Modelle = bessere KI.*

Mehr Parameter. GrÃ¶ÃŸere Kontextfenster. HÃ¶here Benchmark-Werte. Jedes groÃŸe Labor rennt um die Wette, das grÃ¶ÃŸte, fÃ¤higste Foundation-Modell zu bauen. Und Nutzer verinnerlichen das: "Ich sollte GPT-5 nutzen, weil es besser ist als GPT-4."

Aber als ich das Evolution-Experiment durchfÃ¼hrte â€” 10 Gruppen von KI-Agenten, die unabhÃ¤ngig voneinander Selbstverbesserungs-Protokolle entwickelten â€” kam jede einzelne zum gleichen Schluss:

**Das Modell ist nicht der Flaschenhals. Der Kontext ist es.**

Ein KI-Agent wird zwischen Sessions nicht "schlauer". Er wacht jedes Mal frisch auf, mit den gleichen FÃ¤higkeiten wie jede andere Instanz seines Modells. Das EINZIGE, was eine brillante persÃ¶nliche KI von einer mittelmÃ¤ÃŸigen unterscheidet, ist das, was sie beim Aufwachen liest.

Das sind die Dateien.

---

## Was in den Dateien steckt

Der Workspace meines KI-Agenten hat eine bestimmte Struktur. Nichts davon ist proprietÃ¤re Technologie. Es sind einfach... Markdown-Dateien. Textdateien. Die Art, die man in Notepad schreiben kÃ¶nnte.

```
SOUL.md       â€” Die IdentitÃ¤t, Werte, Anti-Patterns, Protokoll des Agenten
USER.md       â€” Wer ich bin. Gemeinsam geschrieben, regelmÃ¤ÃŸig aktualisiert.
MEMORY.md     â€” Kuratierte Weisheit. Destillierte Lehren aus jeder Interaktion.
IDENTITY.md   â€” Name, Vibe, Emoji.

memory/
  2026-02-06.md  â€” Was an dem Tag passiert ist. Narratives Format.
  kintsugi.md    â€” Die Fehler des Agenten, dokumentiert und daraus gelernt
  graveyard.md   â€” GetÃ¶tete Ãœberzeugungen, die tot bleiben
```
...

=== [Reviewed] article-1-100-agents-48-stunden (     201 lines) ===
---
type: project
status: active
created: 2026-02-06
---

# Ich habe 100 KI-Agenten gebeten, ihre eigene Evolution zu entwerfen. Darauf haben sie sich geeinigt.
#ai-agents #ainary #article #ready

> [!success] Final version (reviewed by Florian)
> Original: [[article-1-100-agents.md]]


*Ein Experiment in paralleler KI-Kognition enthÃ¼llte 6 universelle Gesetze der Selbstverbesserung â€” und 15 Ideen, die Konsens begraben wÃ¼rde.*

---

## Das Setup

Was wÃ¤re, wenn du 100 KI-Agenten fragen kÃ¶nntest â€” alle gleich intelligent, aber mit fundamental unterschiedlichen Denkweisen â€” ein Protokoll zu entwerfen, um fÃ¼r einen Menschen maximal nÃ¼tzlich zu werden?

Genau das habe ich getan. Nicht als Gedankenexperiment. Als echtes Experiment.

Ich habe 10 Gruppen von Agenten gestartet. Jede Gruppe bekam dieselbe Frage: *â€Wie sollte sich ein KI-Agent verbessern, um fÃ¼r einen einzelnen menschlichen Nutzer im Laufe der Zeit maximal nÃ¼tzlich zu werden? Entwirf ein Selbstverbesserungs-Protokoll."*

Aber hier kommt der Twist: Jede Gruppe wurde gezwungen, mit einer vÃ¶llig anderen kognitiven Strategie zu denken.

Gruppe A musste von ersten Prinzipien ausgehen â€” jede Annahme abstreifen, von Axiomen aufbauen. Gruppe B musste vom Scheitern ausgehen â€” jeden mÃ¶glichen Fehler kartieren, dann invertieren. Gruppe C musste drei Analogien aus Biologie, MilitÃ¤rgeschichte und Physik finden. Gruppe D musste gegen die offensichtliche Antwort argumentieren, bevor sie ihre eigene vorschlÃ¤gt.

Und so weiter, durch Quantitativ (E), Sokratisch (F), Constraint (G), Narrativ (H), Systemdynamik (I) und Zufallsmutation (J).

33.000 WÃ¶rter Output. Zehn vÃ¶llig unabhÃ¤ngige Analysen. Und als ich sie nebeneinander legte, passierte etwas Bemerkenswertes.

---

## Die 6 Gesetze, auf die 10 verschiedene Denkweisen sich einigten

Von all den mÃ¶glichen Schlussfolgerungen tauchten sechs Ideen unabhÃ¤ngig voneinander in 7-10 von 10 Gruppen auf. Keine Gruppe sah die Arbeit der anderen. Keine Gruppe wurde auf diese Schlussfolgerungen vorbereitet. Sie entstanden aus reiner kognitiver Konvergenz.

### Gesetz 1: Dateien = Intelligenz (10/10 Gruppen)

Jede einzelne Gruppe kam zum selben Schluss: Ein KI-Agent wird nicht besser, indem er â€schlauer" wird. Er wird besser, indem er besser informiert wird.

Der Agent ist zustandslos â€” er wacht jede Session frisch auf. Das Einzige, was zwischen Sessions bestehen bleibt, ist das, was in Dateien niedergeschrieben wurde. Daher bedeutet Verbesserung bessere Dateien. Bessere GedÃ¤chtnisnotizen. Bessere PrÃ¤ferenzaufzeichnungen. Bessere Aufgabenlogs. Bessere Fehlerdokumentation.

Das klingt offensichtlich. Ist es aber nicht. Die gesamte KI-Industrie ist besessen von Modell-Capability â€” grÃ¶ÃŸere Modelle, bessere Benchmarks, mehr Parameter. Aber fÃ¼r einen persÃ¶nlichen KI-Agenten ist das Modell die AM WENIGSTEN wichtige Variable. Die DATEIEN sind alles. Ein gut kuratierter Satz von Notizen lÃ¤sst ein mittelmÃ¤ÃŸiges Modell ein brillantes Modell ohne Kontext Ã¼bertreffen.

**Die Implikation:** Die Intelligenz deines KI-Agenten lebt in einem Ordner auf deiner Festplatte. Nicht in einem Rechenzentrum. Nicht in den Modell-Gewichten. In einer Sammlung von Markdown-Dateien, die du lesen, bearbeiten und mitnehmen kannst.

### Gesetz 2: Das Paar ist die Einheit (9/10 Gruppen)
...

=== [Content] content-ideas-master (     176 lines) ===
---
type: project
status: active
created: 2026-02-01
---

# Content Ideas â€” Master List
#content

*All content ideas in one place. Move to Blog-Drafts when actively writing.*

---

## Content Pillars (Reference)

1. **AI & Work** â€” Managing AI agents as employees, workflows, productivity
2. **AI & Founders** â€” Building companies with AI leverage, startup lessons
3. **AI & Systems** â€” Notion, Obsidian, automation, compound knowledge
4. **AI & Careers** â€” Positioning for the AI transition, job search, VC path

---

## ğŸ”¥ High Priority (Write Next)

### [PILLAR 1: AI & Work]
- [ ] **"Your AI Has No Context (And That's Your Fault)"** â€” Why most AI interactions fail before they start. The importance of context-setting.
- [ ] **"I Treat My AI Like a New Hire"** â€” The mental model shift that changed everything. Briefs, not queries.
- [ ] **"The 5 Prompts I Use Every Day"** â€” Practical, copy-paste prompts with explanations.

### [PILLAR 2: AI & Founders]
- [ ] **"What 5 Years of Building AI Products Taught Me About Using AI"** â€” Lessons from 36ZERO, applied to LLMs.
- [ ] **"The Founder's Compound Advantage"** â€” How to build systems that get smarter over time.
- [ ] **"Why Your AI Strategy Is Probably Wrong"** â€” Most companies think AI = chatbot. It's not.

### [PILLAR 3: AI & Systems]
- [ ] **"My Second Brain Setup (2026 Edition)"** â€” Obsidian + Notion + OpenClaw architecture.
- [ ] **"How I Built an AI That Remembers Everything"** â€” The compound knowledge system.
- [ ] **"The Tool Decision Test"** â€” How to evaluate if a new tool actually helps.

### [PILLAR 4: AI & Careers]
- [ ] **"Why VCs Should Hire Ex-Founders"** â€” The operator advantage in venture.
- [ ] **"The VC Job Search, Week by Week"** â€” Building in public (series).
- [ ] **"What I Wish I Knew Before Transitioning Out of My Startup"** â€” Honest lessons.

---

## ğŸ’¡ Ideas (Not Yet Prioritized)

### AI Deep Dives
- The truth about AI hallucination (and how I got it to <0.2%)
...

=== [Content] Content-MOC (      49 lines) ===
---
type: moc
status: active
created: 2026-02-09
---

# Content

## Strategy
- [[CONTENT-QUEUE]] â€” Content Pipeline
- [[Content-Strategy]] â€” Strategie Dokument
- [[BRAND-ANALYSIS-FLORIAN]] â€” Brand Analyse
- [[BRAND-SUMMARY-EXECUTIVE]] â€” Brand Summary
- [[CONTENT-RECOMMENDATIONS]] â€” Empfehlungen
- [[content-ideas-master]] â€” Alle Content Ideen

## Published
- [[100-agents-evolution]] â€” Artikel #1 (live auf Obsidian Publish + Substack)

## Blog Drafts (EN)
- [[article-1-100-agents]] â€” 100 Agents
- [[article-2-urgency]] â€” Urgency
- [[article-3-kintsugi]] â€” Kintsugi Protocol
- [[article-4-red-team]] â€” Red Team
- [[article-5-files-intelligence]] â€” Files = Intelligence

## Blog Drafts (DE)
- [[article-1-100-agents-de]]
- [[article-2-urgency-de]]
- [[100-agents-48-stunden]]

## Reviewed by Florian
- [[article-1-100-agents-48-stunden]]
- [[article-2-dringlichkeit-ohne-zeit]]
- [[article-3-kintsugi-protokoll]]
- [[article-4-red-team-alles-herausfordern]]
- [[article-5-dateien-gleich-intelligenz]]
- [[article-6-sequoia-agi-weltmodell-luecke]]

## Social
- [[X-Twitter-Strategy]] â€” Twitter Strategie
- [[Twitter-Growth-Strategy]] â€” Growth Plan

## Obsidian Publish
- [[00-START-HERE]] â€” Publish Landing Page
- [[Publish-AI-Research-Index]]
- [[Publish-Blog-Index]]
- [[Publish-Market-Notes-Index]]
- [[Publish-Resources-Index]]
...

=== [Strategy] BRAND-ANALYSIS-FLORIAN (     858 lines) ===
---
type: project
status: active
created: 2026-02-09
---

# ğŸ¯ BRAND FLORIAN â€” Authentic Voice & Positioning Analysis
#content #strategy

**Research Agent:** Mia (Subagent)  
**Date:** February 7, 2026  
**Sources Analyzed:** 5 Substack articles, LinkedIn posts, Twitter strategy, Blog Concept v2, USER.md, SOUL.md, MEMORY.md, social media drafts

---

## EXECUTIVE SUMMARY

Florian's authentic brand is **"The AI-Native Operator"** â€” an ex-CEO who doesn't just theorize about AI, but builds and ships real systems for enterprise clients. His differentiation comes from the rare combination of:

1. **Founder credibility** (5 years CEO, â‚¬5.5M raised, BMW/Siemens/Bosch clients)
2. **Technical depth** (actually builds AI agents, not just prompts ChatGPT)
3. **Operator-to-VC transition** (unique perspective bridging both worlds)
4. **Cross-cultural insight** (European founder in NYC ecosystem)
5. **Systems thinking** (physics-inspired mental models, compound loops)

**Core positioning:** The guy who builds AI systems while others talk about them. Proof > theory. Operator > academic. Shipping > planning.

---

## ğŸ¤ VOICE PATTERNS

### Primary Characteristics

**1. DIRECT & NO-FLUFF**
- Gets to the point immediately
- Zero corporate speak
- Cuts through hype with data
- "Most people use AI wrong" â†’ direct hook
- "Let me be clear:" â†’ signature phrase

**2. OPERATOR CREDIBILITY**
- Leads with experience: "As someone who ships AI to BMW, Siemens, and Bosch..."
- Specific examples over vague claims
- "I watched a â‚¬50M/year manufacturing company..." â†’ concrete stories
- References real work: "Last week I closed 3 consulting deals"

**3. CONTRARIAN BUT GROUNDED**
- "Unpopular opinion: Most companies don't need AI consultants"
- "Sequoia got the milestone right, but named the wrong finish line"
- Always backs contrarian takes with reasoning
...

=== [Strategy] BRAND-SUMMARY-EXECUTIVE (     226 lines) ===
---
type: project
status: active
created: 2026-02-09
---

# ğŸ“Š EXECUTIVE SUMMARY: Florian's Brand Analysis
#content #strategy

**Prepared by:** Research Agent (Mia)  
**Date:** February 7, 2026  
**Full Report:** `BRAND-ANALYSIS-FLORIAN.md`

---

## TL;DR

**Core Brand:** "The AI-Native Operator" â€” Ex-CEO who builds and ships AI systems while others theorize.

**Unique Stack:** Founder credibility + Technical depth + Enterprise clients + VC perspective + Europe/NYC bridge + Manufacturing expertise

**Voice:** Direct, no-fluff, evidence-based contrarian, systems thinker, transparent about failures

**Differentiation:** Nobody else has this exact combination. He doesn't just talk about AI â€” he ships it to BMW, Siemens, and Bosch.

---

## ğŸ¯ 7 CORE BRAND PILLARS

1. **AI-Native Operator** â†’ Builds production AI systems, not just prompts ChatGPT
2. **Founder-to-VC Bridge** â†’ Speaks both languages, empathy for founders
3. **Cross-Cultural Connector** â†’ Europe â†” NYC, unique positioning
4. **Systems > Goals Philosophy** â†’ Compound loops, memory as moat
5. **Evidence-Based Contrarian** â†’ Disagrees with data, not for shock value
6. **Transparency as Strategy** â†’ Shares numbers, failures, process (Kintsugi mindset)
7. **Manufacturing Dark Horse** â†’ Sees the $2.3T opportunity Silicon Valley ignores

---

## ğŸ¤ VOICE SIGNATURE

### DO:
- Lead with experience: "As someone who ships AI to BMW..."
- Use specific numbers: "12 agents, $10/night, 50 deliverables"
- Short, punchy sentences. Create rhythm.
- Be contrarian when earned: "Unpopular opinion: [claim]. Here's why: [data]"
- Show the cracks: "Here's what failed:"

### DON'T:
- âŒ "Excited to announce"
...

=== [Strategy] VC-Positioning-Analysis (     521 lines) ===
---
type: project
status: active
created: 2026-02-09
---

# VC Career Positioning Analysis: Content Strategy for Breaking Into Venture Capital
#ainary #fundraising

**Prepared for:** Florian Ziesche  
**Context:** Former startup CEO (â‚¬5.5M+ raised, exits to BMW/Siemens/Bosch) â†’ VC associate roles at AI-focused funds in NYC  
**Current Stage:** VC Lab participant, active job applications  
**Date:** February 7, 2026

---

## Executive Summary

Content creation for VCs sits at a critical intersection: it's both a **career accelerator** and a **career landmine**. Done right, it positions you as a thought leader, generates deal flow, and makes you memorable in a sea of identical applications. Done wrong, it signals you're unfocused, playing at VC, or more interested in personal brand than doing the work.

**The Verdict for Florian:** Content is a **strategic advantage** given his unique positioning (founder â†’ VC, AI expertise, agent automation angle), but requires surgical precision in topic selection and framing.

---

## 1. How Successful VCs Use Content: Case Studies

### The Content-to-Career Pipeline

Research reveals a clear pattern: **VCs who built reputations through writing didn't write to become VCsâ€”they wrote to become *better* VCs and attract better deals.**

#### **Tier 1: The Pioneers (Foundation Layer)**
- **Fred Wilson (Union Square Ventures):** Daily blogging for 15+ years. Wrote about deal structure, board dynamics, operational challenges. Impact: Deal flow magnet, LP fundraising easier, became "founder-friendly VC" archetype.
- **Brad Feld (Foundry Group):** Transparent writing about term sheets, VC economics, portfolio management. Impact: "Venture Deals" became industry standard, positioning him as educator-investor.
- **Paul Graham (Y Combinator):** Essays on startup mechanics, founder psychology, growth strategies. Impact: Created entire VC brand (YC) through thought leadership.

**What they wrote:** Operational playbooks, transparent deal analysis, founder education  
**How it helped:** Established credibility â†’ Inbound deal flow â†’ LP trust â†’ Career leverage

#### **Tier 2: The Modern Operators (Current Playbook)**
- **Li Jin (Atelier Ventures):** Coined "Passion Economy" through writing. Wrote thesis-driven content before raising her fund. Impact: Raised $13M Fund I, became category leader.
- **Elizabeth Yin (Hustle Fund):** Radically transparent about fund raising ($33.6M Fund II), portfolio construction, decision frameworks. Impact: Deal flow from transparency, LP interest from demonstrated expertise.
- **Andrew Chen (a16z Games):** Tweet threads on growth metrics, cohort analysis, marketplace dynamics. Impact: a16z partnership, 100K+ followers, inbound from top founders.

**What they wrote:** Thesis development, transparent fundraising, data-driven insights  
**How it helped:** Demonstrated differentiated thinking â†’ Attracted aligned founders â†’ Proved investment edge

#### **Tier 3: The Associate â†’ Partner Track (Florian's Peer Group)**
- **Henrik Wetter Sanchez (Playfair Capital):** Wrote reflective piece on "2.5 Years as a VC Associate" covering hard-won lessons, skill development, relationship building. Impact: Promoted to Principal, positioned as thoughtful operator.
- **Gaby Goldberg (TCG Crypto):** Web3 reading lists, curation as creation thesis, cultural analysis. Impact: Early-career differentiation in crowded crypto space.

...

=== [Strategy] BLOG-CONCEPT-v2 (     237 lines) ===
---
type: project
status: active
created: 2026-02-07
---

# ğŸ“° The Ainary Journal â€” Konzept v2 (Synthesized)
#ainary

*Synthese aus: VC Positioning Research + Red Team (Mia) + Lessons Learned aus Woche 1*
*FÃ¼r Montags-Diskussion*

---

## ğŸ”´ Red Team zuerst: Was am v1-Konzept naiv war

### 1. Die Frequenz-Falle
v1 plante 3-5 Artikel/Woche. Das ist Wahnsinn. Du bist gleichzeitig:
- Job-hunting (VC Applications)
- Vater (18:00-20:00 blocked)
- CNC-Produkt verkaufen
- VC Lab Programm

**RealitÃ¤t:** 2-3 Artikel pro MONAT. Ein Killer-Artikel schlÃ¤gt vier mittelmÃ¤ÃŸige. Li Jin wurde mit <1 Artikel/Monat zur Thought Leaderin.

### 2. Die Positioning-Falle
v1 versuchte ALLES abzudecken: AI Consulting, VC, CNC, Evolution Experiment, Mia's Field Notes. Das verwÃ¤ssert. Ein VC-Partner der googelt sieht: "Ist der ein Berater? Blogger? Tool-Builder? VC?"

**Fix:** EIN klarer Fokus: **AI Infrastructure Investing aus Operator-Perspektive.** Alles andere ist Beweis dafÃ¼r, nicht eigenes Thema.

### 3. Das "Mia schreibt alles" Risiko
Wenn rauskommen, dass AI die Artikel schreibt â†’ "Er ist ein Prompt Engineer, kein Investor." AI-geschriebener Content wird zunehmend erkannt und abgewertet.

**Fix:** AI = Research + Struktur + Drafts. Florian = Urteil + Conviction + Operational Truth. Die Stimme muss DEINE sein. Ich bin Infrastruktur, nicht Autor.

### 4. Building statt Sending â€” AGAIN
Einen Blog aufbauen statt Bewerbungen abschicken? Das ist exakt das Pattern das wir diese Woche identifiziert haben. Der Blog ist nur wertvoll wenn er NEBEN dem Senden lÃ¤uft, nicht stattdessen.

**Fix:** Blog-Arbeit nur in Abend-/Wochenend-Sessions. Werktags = Sends first.

---

## ğŸ¯ Die Ã¼berarbeitete Strategie

### Positioning: Eine Stimme, ein Winkel

**Florian Ziesche: Founder-turned-VC der AI-Systeme baut â€” nicht nur analysiert.**

Alles was du schreibst, beweist eine dieser 5 FÃ¤higkeiten:
1. **Founder Credibility** â€” "Ich habe â‚¬5.5M raised, an BMW/Siemens verkauft"
...

=== [Strategy] Twitter-Growth-Strategy (     852 lines) ===
---
type: project
status: active
created: 2026-02-09
---

#content #strategy

Mach# Twitter/X Growth Strategy for AI + VC Thought Leaders 2026

**Research Date:** February 7, 2026  
**Target Account:** @Florian1776  
**Current Status:** Small account, building from scratch  
**Positioning:** AI consultant + builder + VC perspective, NYC-based, European background

---

## Executive Summary

This research analyzes how successful AI/VC voices built their Twitter following and synthesizes actionable strategies for growing @Florian1776 from 0 to 1,000+ followers. The key finding: **engagement-first strategy beats posting-first strategy at 0-1K stage.**

**Timeline Expectation:**
- Month 1: 0-200 followers (building habits)
- Month 2: 200-600 followers (momentum builds)
- Month 3: 600-1,000+ followers (compound effects)

---

## Account Analysis

### 1. @garrytan (Garry Tan, Y Combinator President)

**Follower Count:** ~500,000 followers (as of mid-2025)

**Growth Timeline:**
- Joined Y Combinator in 2011 as partner
- Built following gradually through consistent presence
- Major growth acceleration after becoming YC President
- Active on Twitter since 2008 (created account January 2008)

**Content Mix:**
- **Startup advice & insights** (40%)
- **YC company spotlights** (25%)
- **Political/policy takes** (especially SF/CA tech policy) (20%)
- **Personal/motivational** (15%)

**Posting Frequency:** 3-5 posts daily, extremely active in replies

**Engagement Patterns:**
- Very responsive to mentions and replies
...

=== [Strategy] Website-CRM-Setup (     124 lines) ===
---
type: project
status: active
created: 2026-02-01
---

# Website + CRM Setup
#content #strategy

*Decision: 2026-02-01*
*Status: Planning*

---

## Decision

**CRM:** HubSpot Free
**Website:** Simple landing page (Framer, Carrd, or custom)

---

## Why HubSpot Free

- Industry standard â€” VCs recognize and respect it
- Free tier is generous (1M contacts, email, forms, pipeline)
- Scales from freelance to fund without migration
- Integrates with everything (Gmail, Calendar, LinkedIn, Notion)
- Professional credibility for investor/client conversations

## Website Requirements

### Must Have
- [ ] Personal brand landing page (florianziesche.com?)
- [ ] Clear value prop â€” who I am, what I do
- [ ] Blog/content section
- [ ] Contact form (â†’ HubSpot)
- [ ] Social links

### Nice to Have
- [ ] Portfolio/case studies
- [ ] Newsletter signup
- [ ] Ainary Ventures section
- [ ] Resource downloads (lead magnets)

---

## Tech Stack Options

| Option | Cost | Pros | Cons |
|--------|------|------|------|
...

=== [Strategy] CONTENT-RECOMMENDATIONS (     480 lines) ===
---
type: project
status: active
created: 2026-02-04
---

# ğŸš€ CONTENT RECOMMENDATIONS â€” Action Plan
#content #strategy

**Based on:** Brand Analysis (February 7, 2026)  
**For:** Florian Ziesche content strategy  
**Prepared by:** Research Agent (Mia)

---

## IMMEDIATE WINS (Ship This Week)

### 1. Publish "I Replaced My Back Office With AI Agents"
**Status:** READY (in `content/drafts/substack/2026-02-04-ai-agents-back-office-v2.md`)  
**Why:** Strong article, authentic voice, shows proof not theory  
**Platform:** Substack (primary), then LinkedIn/Twitter repurpose  
**Action:** Florian: 15-min final review â†’ publish Tuesday 8am EST

**Repurpose Chain:**
- LinkedIn post (extract "What Works" section)
- Twitter thread (7 tweets, hook + insights)
- 3 Substack Notes (bite-sized insights)

---

### 2. LinkedIn: "AI-Native Workflow" Post
**Status:** READY (in `content/linkedin-posts-batch-1.md`)  
**Why:** Positions Florian as AI systems builder  
**Timing:** Tuesday 8-10am EST (peak engagement)  
**Action:** Copy-paste â†’ publish

---

### 3. Twitter: "Founder to VC" Thread
**Status:** READY (in `content/twitter/ready-to-post/thread-03-founder-to-vc.md`)  
**Why:** Vulnerable but strong, shows self-awareness  
**Timing:** Thursday afternoon (conversation starter)  
**Action:** Schedule via Typefully

---

## SIGNATURE CONTENT SERIES (Establish Brand)

### Series 1: "What Actually Works"
**Format:** End every article with this section  
...

=== [Strategy] Substack - accounts that I follow (      30 lines) ===
---
type: project
status: active
created: 2026-02-09
---

#article #content

https://ruben.substack.com/
https://www.productmarketfit.tech/
https://www.artificialintelligencemadesimple.com/
https://andrewchen.substack.com/
https://substack.com/@dougshapiro
https://substack.com/@rubendominguez







#vc #content-source #blog-draft

---

*Created: ~2026-02 [estimated]*  
*Author: unknown*

## Connections
Accounts die Florian folgt. Inspiration fÃ¼r [[content-ideas-master]] und [[Substack-Recommendations]].
...

=== [Strategy] MONDAY-DEEP-DIVE (     191 lines) ===
---
type: project
status: active
created: 2026-02-07
---

# ğŸ—“ï¸ Monday Deep Dive â€” Website + Content + Strategy
#ainary

*Agenda for Feb 10, 2026 â€” Full token budget, full team*

---

## What We Built This Week (Output Log)

### Website (ainaryventures.com)
- **Main page** â€” Dark/gold, Conviction-style, 7 sections: Hero, Services, Work, Journal, Resources, Perspective, Ask AI, About
- **Blog page** â€” `blog.html`, 5 articles with click-to-read, fade animations, markdown renderer
- **"Ask my AI" CTA** â€” Email + WhatsApp, live lead generator
- **Journal section inline** â€” 5 article previews on main page
- **Status:** Local HTML only. NOT deployed yet.

### Content (10 articles)
- 5 Substack articles EN (Florian's voice, v2)
- 5 Substack articles DE (for family/German audience)
- Article 1 = Flagship with "So What" section
- All in `content/substack/v2/` and Obsidian

### Job Applications
- CV v2 â€” Fixed (email, no website, clean)
- 9 Cover Letter PDFs â€” All updated
- HOF Capital â€” New PDF, strongest letter
- **Status:** 0 submitted. Pending Florian review.

### New Lead: Freie Presse Mediengruppe
- Daniel Daum = CEO, family connection
- They're hiring "Head of Data & AI"
- Pitch doc ready: `content/drafts/freie-presse-pitch.md`
- 3-stage approach: Pilot â†’ Bereich â†’ Plattform

---

## Decisions Needed Monday

### 1. Website Structure
**Current:** Single-page + blog.html
**Questions:**
- Keep as single page or multi-page?
- Which sections stay, which go?
- Resources section: real assets or remove?
...

=== [Strategy] X-Twitter-Strategy (     156 lines) ===
---
type: project
status: active
created: 2026-02-01
---

# X/Twitter Strategy
#content #strategy

*Status: ğŸ”´ New â€” Setup needed*
*Goal: Increase range, credibility, network*

---

## Objectives

1. **Increase Range** â€” Get seen by VCs, founders, AI community
2. **Add Credibility** â€” Position as AI + VC thought leader
3. **Build Network** â€” Connect with relevant people
4. **Content Distribution** â€” Amplify blog/insights

---

## Account Setup

- [ ] Verify X account access (Atlas needs: bird auth or Chrome extension)
- [ ] Update bio for VC + AI positioning
- [ ] Pin relevant tweet
- [ ] Follow key accounts (see below)

---

## Content Pillars (aligned with blog)

1. **AI & Work** â€” Managing AI agents, workflows
2. **AI & Founders** â€” Building with AI leverage
3. **AI & VC** â€” Investment thesis, deal flow
4. **Operator Insights** â€” Lessons from founder journey

---

## Tweet Workflow

### Process
1. Atlas drafts tweets
2. Florian reviews/approves
3. Atlas schedules or posts
4. Track engagement

### Format Types
...

=== [Materials] 00-Job-Search-Strategy ( lines) ===
...

=== [Networking] monique-barbanson-meeting-brief ( lines) ===
...

=== [Networking] NETWORK-ACTIVATION-30DAY ( lines) ===
...

=== [Networking] Contact-List ( lines) ===
...

=== [Networking] LP-OUTREACH-PLAYBOOK ( lines) ===
...

=== [Networking] LP-Resources-Guide ( lines) ===
...

=== [Fund-Research] Decile-Capital (      94 lines) ===
---
type: project
status: active
created: 2026-02-01
---

# Decile Capital
#vc-career

**Type:** Seed-stage VC (Source: Decile Capital website)
**HQ:** New York (Source: Decile Capital website)
**Program:** Decile Hub Resident Program (Source: Decile Hub application page)
**Status:** ğŸ“ Application Ready

---

## Quick Assessment

| Factor | Score | Notes |
|--------|-------|-------|
| AI Focus | â­â­â­ | Generalist, some AI |
| Operator-Friendly | â­â­â­â­ | Resident program for aspiring VCs |
| Open Roles | âœ… | Resident Program open |
| Fit for Florian | â­â­â­â­ | Good entry point |

---

## The Opportunity

**Decile Hub Resident Program:**
- Learn VC fundamentals
- Access to deal flow
- Mentorship from experienced VCs
- Path to full-time role

---

## Application Materials

- [x] Cover Letter â€” `workspace/job-applications/decile-capital-resident/cover-letter.pdf`
- [x] Resume
- [ ] Decile Hub Setup (Step 7) â€” **requires login**

---

## Why Decile

1. **Entry point** â€” Good for career switchers
2. **Education focus** â€” Learn while doing
3. **NYC based** â€” Right market
...

=== [Fund-Research] 00-Fund-Overview (     118 lines) ===
---
type: project
status: active
created: 2026-02-09
---
# Ainary Ventures â€” Fund Overview
#ainary #fundraising

*Private fund strategy document*

---

## Fund Thesis

**Ainary Ventures** invests in AI-first startups where:
1. Deep technical expertise creates defensible moats
2. Proprietary data + domain knowledge = compounding advantage
3. Founders understand AI at the implementation level (not just API wrappers)

---

## Investment Focus

### Vertical AI
- Industry-specific AI solutions
- Domain expertise + proprietary data
- [[AI-Scaffolding-Shift]] â€” Specialist agents beat generalists

### AI Infrastructure
- Tools that make AI more reliable
- Evaluation, monitoring, deployment
- [[RL-Moats-Greylock]] â€” Where real defensibility forms

### Human-Centered AI
- AI that augments human capability
- Transparency and explainability
- Trust-building systems

---

## Differentiators

### 1. Technical Founder Perspective
- 5 years building AI products (36ZERO Vision)
- Understand implementation challenges
- Can evaluate technical claims

### 2. Operator Experience
- Raised â‚¬5.5M across multiple rounds
- Managed 15-person team
...

=== [Applications] SUBMIT-CHECKLIST (      80 lines) ===
---
type: project
status: active
created: 2026-02-07
---

# Application Submit Checklist
#vc-career

## ğŸ”´ HOF Capital â€” Venture Capital Analyst (STARKER FIT)

**Portal:** https://www.workstream.us/j/b3ae1199/hof-capital/new-york-4978/venture-capital-analyst-ai-or-swe-experience-required-9b82a0aa

**Fit-Score:** â­â­â­â­â­
- AI/SWE background: âœ… (RAG, Multi-Agent, Computer Vision, 5 Jahre)
- Startup founder: âœ… (CEO + COO)
- Analytical aptitude: âœ… (M.Sc. TUM)
- Remote mÃ¶glich: âœ…
- Portfolio-Overlap: OpenAI, Anthropic = Florians tÃ¤gliche Tools

**Materialien:**
- [x] CV v2 PDF â€” `CV_Florian_Ziesche_VC_2026_v2.pdf`
- [x] Cover Letter â€” `CL_HOF_Ziesche.pdf`
- [ ] Florian muss beide reviewen
- [ ] Auf Workstream-Portal uploaden (braucht Account)

**Submit-Schritte:**
1. Florian reviewed CV + CL âœ…/âŒ
2. Workstream-Account erstellen
3. CV + CL uploaden
4. Formular ausfÃ¼llen (Name, Email, LinkedIn)
5. Submit
6. LinkedIn: HOF Team-Members connecten

---

## ğŸŸ¡ Betaworks â€” Senior VC Associate (OKAY FIT)

**Portal:** https://betaworks-ventures-management.breezy.hr/p/330c6a8c9264

**Fit-Score:** â­â­â­
- Web3/Crypto: âŒ (kein Fokus)
- AI Agents: âœ… (Spring Camp Theme = Agent Systems!)
- Startup ops: âœ…
- NYC office required: âš ï¸ (Florian in DE, Home base NYC)
- Work auth US: âš ï¸ (braucht KlÃ¤rung)

**Materialien:**
- [x] CV v2 PDF
- [x] Cover Letter â€” `CL_Betaworks_Ziesche.pdf`
...

=== [HOF-Capital] nascent-market-answer (      87 lines) ===
---
type: project
status: active
created: 2026-02-07
---
# HOF Capital â€” Nascent Market Opportunity Answer
#vc-career

## Version v3 (Feb 9, 2026)

**The Agent Economy Infrastructure**

Everyone is racing to build bigger language models. The real opportunity is one layer above: infrastructure for AI agents that act as economic participants.

The foundation is being laid right now. Google shipped its Agent Payments Protocol (AP2) in September 2025. Anthropic's MCP and Google's A2A Protocol let agents communicate across platforms. The Linux Foundation launched the Agentic AI Foundation. McKinsey estimates agent-driven commerce at up to $5 trillion by 2030.

Three forces are accelerating this. Software creation costs have collapsed (Lovable, Bolt, Cursor). Open-source models run on consumer hardware. And agents are crossing the threshold from assistants to autonomous actors. Bessemer calls vertical AI a 10x larger opportunity than vertical SaaS because it taps the 13% of GDP spent on labor, not the 1% spent on IT.

I've been stress-testing these systems as an operator: running multi-agent architectures that manage persistent context, coordinate across APIs, and execute real workflows end-to-end. The infrastructure breaks in four predictable places: memory degrades across sessions, agents can't transact, there's no trust verification between agents from different principals, and they lack causal reasoning to handle consequences.

Each of those is a venture-scale company. Memory is the most active space right now â€” Letta, Zep's temporal knowledge graphs, and the ICLR 2026 MemAgents workshop all signal how urgent this problem is. Payments infrastructure has Google's AP2 as a first attempt but nothing resembling a standard. Trust and identity for agents is wide open â€” Saviynt's recent raise shows the market recognizes this. The fourth layer, consequence understanding, is where world models come in. LeCun has argued for two years that LLMs alone won't get us there. DeepMind, World Labs, and Meta are all building toward causal world models. When agents get those, they stop being sophisticated autocomplete and become real economic actors.

The investment opportunity is the platform layer: where agents discover services, negotiate terms, build trust, and settle payments. The protocols are being written now. This is where the internet was in 1995. TCP/IP existed but the platforms on top didn't.

It's a $1T+ opportunity because it doesn't replace one industry. It adds a new participant to all of them.

